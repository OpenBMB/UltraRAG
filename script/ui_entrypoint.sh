#!/usr/bin/env sh
set -u

# UltraRAG UI entrypoint with optional pipeline prebuild.
#
# Env vars:
# - ULTRARAG_PREBUILD_DISABLE=1 to skip all prebuild
# - ULTRARAG_PREBUILD_FORCE=1 to rebuild even if artifacts exist
# - ULTRARAG_PREBUILD_PIPELINES="examples/a.yaml ui/pipelines/b.yaml" to build a specific list
# - ULTRARAG_PREBUILD_SKIP_HIDDEN=1 to skip internal pipelines (NOT recommended for UI KB features)
#
# Artifacts generated by `ultrarag build`:
# - <dir>/parameter/<pipeline>_parameter.yaml
# - <dir>/server/<pipeline>_server.yaml

mode="${1:-ui}" # ui | admin | prebuild

PREBUILD_DISABLE="${ULTRARAG_PREBUILD_DISABLE:-0}"
PREBUILD_FORCE="${ULTRARAG_PREBUILD_FORCE:-0}"
PREBUILD_PIPELINES="${ULTRARAG_PREBUILD_PIPELINES:-}"
PREBUILD_SKIP_HIDDEN="${ULTRARAG_PREBUILD_SKIP_HIDDEN:-0}"
AUTO_INSTALL_KB_DEPS="${ULTRARAG_AUTO_INSTALL_KB_DEPS:-0}"
# Auto-install embedding backend deps when running in restricted environments without rebuilding the image.
AUTO_INSTALL_EMBED_DEPS="${ULTRARAG_AUTO_INSTALL_EMBED_DEPS:-1}"
hidden_re='^(build_text_corpus|corpus_chunk|milvus_index|multiturn_chat)$'

ensure_kb_deps() {
  # KB-related pipelines may require these deps.
  python -c 'import chonkie, tiktoken' >/dev/null 2>&1 && return 0
  if [ "$AUTO_INSTALL_KB_DEPS" != "1" ]; then
    echo "[ui prebuild] WARN: chonkie/tiktoken missing and ULTRARAG_AUTO_INSTALL_KB_DEPS!=1" >&2
    return 0
  fi
  echo "[ui prebuild] installing missing deps: chonkie tiktoken"
  if ! pip install --no-cache-dir "chonkie>=1.5.2" "tiktoken>=0.7.0"; then
    echo "[ui prebuild] WARN: failed to install chonkie/tiktoken (will continue)" >&2
  fi
}

ensure_embed_deps() {
  # If the retriever is configured to use in-process infinity-emb backend, ensure the package exists.
  # This avoids failing with: "infinity_emb is not installed" when images were built without it.
  if [ "${_ULTRARAG_EMBED_DEPS_OK:-0}" = "1" ]; then
    return 0
  fi
  if [ "${RETRIEVER_BACKEND:-}" != "infinity" ]; then
    _ULTRARAG_EMBED_DEPS_OK=1
    return 0
  fi
  if python -c 'import infinity_emb' >/dev/null 2>&1; then
    _ULTRARAG_EMBED_DEPS_OK=1
    return 0
  fi
  if [ "$AUTO_INSTALL_EMBED_DEPS" != "1" ]; then
    echo "[ui] WARN: infinity-emb missing but ULTRARAG_AUTO_INSTALL_EMBED_DEPS!=1" >&2
    return 0
  fi
  echo "[ui] fixing/ensuring embedding deps: infinity-emb[torch] (and compatible huggingface_hub)"
  # infinity-emb currently expects huggingface_hub.HfFolder; pin a compatible version.
  if ! pip install --no-cache-dir -U "huggingface_hub==0.24.7"; then
    echo "[ui] ERROR: failed to install/upgrade huggingface_hub==0.24.7" >&2
    return 1
  fi

  # NOTE:
  # Some recent transformers versions interpret `tokenizer.model` as a tiktoken BPE file, but
  # models like openbmb/MiniCPM-Embedding-Light ship a SentencePiece `tokenizer.model` (binary).
  # Pin a compatible transformers version to avoid "Converting from Tiktoken failed" errors.
  if ! pip install --no-cache-dir -U "transformers==4.37.2" "sentencepiece"; then
    echo "[ui] ERROR: failed to install/upgrade transformers==4.37.2 and/or sentencepiece" >&2
    return 1
  fi
  # infinity backend requires torch; install via extras.
  if ! pip install --no-cache-dir -U "infinity-emb[torch]"; then
    echo "[ui] ERROR: failed to install/upgrade infinity-emb[torch] (PyTorch install may be blocked by network/mirror)" >&2
    return 1
  fi

  # Ensure real PyTorch is present (the infinity-emb extras may not always pull torch wheels).
  if ! python -c 'import torch; import torch.nn' >/dev/null 2>&1; then
    torch_index="${TORCH_INDEX_URL:-https://download.pytorch.org/whl/${TORCH_CUDA_TAG:-cu121}}"
    echo "[ui] installing PyTorch from: $torch_index"
    # Install minimal set; add torchvision/torchaudio if needed later.
    if ! pip install --no-cache-dir -U --index-url "$torch_index" torch; then
      echo "[ui] ERROR: failed to install torch from $torch_index. If download.pytorch.org is blocked, set TORCH_INDEX_URL to an accessible mirror." >&2
      return 1
    fi
  fi

  if ! python -c 'import torch; import torch.nn; import infinity_emb' >/dev/null 2>&1; then
    echo "[ui] ERROR: torch/infinity_emb still cannot be imported after install; check logs for the underlying ImportError." >&2
    return 1
  fi
  _ULTRARAG_EMBED_DEPS_OK=1
}

prebuild_one() {
  p="$1"
  [ -f "$p" ] || return 0

  ensure_kb_deps
  ensure_embed_deps

  base="$(basename "$p" .yaml)"
  if [ "$PREBUILD_SKIP_HIDDEN" = "1" ] && echo "$base" | grep -Eq "$hidden_re"; then
    echo "[ui prebuild] skip (hidden): $p"
    return 0
  fi

  dir="$(dirname "$p")"
  param="$dir/parameter/${base}_parameter.yaml"
  srv="$dir/server/${base}_server.yaml"

  if [ "$PREBUILD_FORCE" != "1" ] && [ -f "$param" ] && [ -f "$srv" ]; then
    echo "[ui prebuild] skip (exists): $p"
    return 0
  fi

  echo "[ui prebuild] build: $p"
  if ! ultrarag build "$p"; then
    echo "[ui prebuild] WARN: build failed (will continue): $p" >&2
  fi
}

if [ "$PREBUILD_DISABLE" != "1" ]; then
  ensure_embed_deps
  if [ -n "$PREBUILD_PIPELINES" ]; then
    # shellcheck disable=SC2086
    for p in $PREBUILD_PIPELINES; do
      prebuild_one "$p"
    done
  else
    # Prefer building the smallest demo first, then the rest.
    if [ -f "examples/sayhello.yaml" ]; then
      prebuild_one "examples/sayhello.yaml"
    fi
    for p in examples/*.yaml ui/pipelines/*.yaml; do
      [ "$p" = "examples/sayhello.yaml" ] && continue
      prebuild_one "$p"
    done
  fi
fi

if [ "$mode" = "prebuild" ]; then
  exit 0
fi

# Ensure runtime deps are present before starting the UI server.
ensure_embed_deps

if [ "$mode" = "admin" ]; then
  exec ultrarag show ui --host 0.0.0.0 --port 5050 --admin
else
  exec ultrarag show ui --host 0.0.0.0 --port 5050
fi


