# ğŸ“š RAG Paper Daily

### ğŸ“… 2025-10-06
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2510.04905v1">Retrieval-Augmented Code Generation: A Survey with Focus on Repository-Level Approaches</a></td><td><details><summary>å±•å¼€</summary>Recent advancements in large language models (LLMs) have substantially
improved automated code generation. While function-level and file-level
generation have achieved promising results, real-world software development
typically requires reasoning across entire repositories. This gives rise to the
challenging task of Repository-Level Code Generation (RLCG), where models must
capture long-range dependencies, ensure global semantic consistency, and
generate coherent code spanning multiple files or modules. To address these
challenges, Retrieval-Augmented Generation (RAG) has emerged as a powerful
paradigm that integrates external retrieval mechanisms with LLMs, enhancing
context-awareness and scalability. In this survey, we provide a comprehensive
review of research on Retrieval-Augmented Code Generation (RACG), with an
emphasis on repository-level approaches. We categorize existing work along
several dimensions, including generation strategies, retrieval modalities,
model architectures, training paradigms, and evaluation protocols. Furthermore,
we summarize widely used datasets and benchmarks, analyze current limitations,
and outline key challenges and opportunities for future research. Our goal is
to establish a unified analytical framework for understanding this rapidly
evolving field and to inspire continued progress in AI-powered software
engineering.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒŒæ™¯ä¸‹ï¼Œåˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯è§£å†³**ä»“åº“çº§ä»£ç ç”Ÿæˆï¼ˆRLCGï¼‰**æŒ‘æˆ˜çš„ç ”ç©¶è¿›å±•ï¼Œç³»ç»Ÿç»¼è¿°äº†æ£€ç´¢å¢å¼ºä»£ç ç”Ÿæˆï¼ˆRACGï¼‰çš„æ–¹æ³•ã€åˆ†ç±»ï¼ˆå¦‚ç”Ÿæˆç­–ç•¥ã€æ£€ç´¢æ¨¡æ€ç­‰ï¼‰ã€æ•°æ®é›†åŠæœªæ¥æ–¹å‘ï¼Œæ—¨åœ¨æ„å»ºç»Ÿä¸€çš„åˆ†ææ¡†æ¶å¹¶æ¨åŠ¨AIé©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹å‘å±•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.04757v1">ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced re-ranking retriever</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) is a powerful technique for enriching
Large Language Models (LLMs) with external knowledge, allowing for factually
grounded responses, a critical requirement in high-stakes domains such as
healthcare. However, the efficacy of RAG systems is fundamentally restricted by
the performance of their retrieval module, since irrelevant or semantically
misaligned documents directly compromise the accuracy of the final generated
response. General-purpose dense retrievers can struggle with the nuanced
language of specialised domains, while the high accuracy of in-domain models is
often achieved at prohibitive computational costs. In this work, we aim to
address this trade-off by developing and evaluating a two-stage retrieval
architecture that combines a lightweight ModernBERT bidirectional encoder for
efficient initial candidate retrieval with a ColBERTv2 late-interaction model
for fine-grained re-ranking. We conduct comprehensive evaluations of our
retriever module performance and RAG system performance in the biomedical
context, fine-tuning the IR module using 10k question-passage pairs from
PubMedQA. Our analysis of the retriever module confirmed the positive impact of
the ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points
compared to its retrieve-only counterpart. When integrated into the biomedical
RAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on
the five tasks of the MIRAGE question-answering benchmark, outperforming strong
baselines such as MedCPT (0.4436). Our ablation studies reveal that this
performance is critically dependent on a joint fine-tuning process that aligns
the retriever and re-ranker; otherwise, the re-ranker might degrade the
performance.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆè½»é‡çº§ModernBERTå’ŒColBERTv2çš„ä¸¤é˜¶æ®µæ£€ç´¢æ¶æ„ï¼Œä»¥æå‡ç”Ÿç‰©åŒ»å­¦é¢†åŸŸRAGç³»ç»Ÿçš„æ£€ç´¢æ€§èƒ½ï¼Œé€šè¿‡åœ¨PubMedQAæ•°æ®é›†ä¸Šçš„å¾®è°ƒå’Œå®éªŒéªŒè¯ï¼Œæ˜¾è‘—æé«˜äº†å¬å›ç‡å’Œé—®ç­”å‡†ç¡®æ€§ï¼Œå¹¶åœ¨MIRAGEåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æœ€ä¼˜æ°´å¹³ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.04536v1">3Dify: a Framework for Procedural 3D-CG Generation Assisted by LLMs Using MCP and RAG</a></td><td><details><summary>å±•å¼€</summary>This paper proposes "3Dify," a procedural 3D computer graphics (3D-CG)
generation framework utilizing Large Language Models (LLMs). The framework
enables users to generate 3D-CG content solely through natural language
instructions. 3Dify is built upon Dify, an open-source platform for AI
application development, and incorporates several state-of-the-art LLM-related
technologies such as the Model Context Protocol (MCP) and Retrieval-Augmented
Generation (RAG). For 3D-CG generation support, 3Dify automates the operation
of various Digital Content Creation (DCC) tools via MCP. When DCC tools do not
support MCP-based interaction, the framework employs the Computer-Using Agent
(CUA) method to automate Graphical User Interface (GUI) operations. Moreover,
to enhance image generation quality, 3Dify allows users to provide feedback by
selecting preferred images from multiple candidates. The LLM then learns
variable patterns from these selections and applies them to subsequent
generations. Furthermore, 3Dify supports the integration of locally deployed
LLMs, enabling users to utilize custom-developed models and to reduce both time
and monetary costs associated with external API calls by leveraging their own
computational resources.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†â€œ3Difyâ€ï¼Œä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç¨‹åºåŒ–3Dè®¡ç®—æœºå›¾å½¢ç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç”Ÿæˆ3Då†…å®¹ã€‚å®ƒæ•´åˆäº†åŒ…æ‹¬æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨å†…çš„å…ˆè¿›LLMæŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨Model Context Protocolï¼ˆMCPï¼‰å’ŒComputer-Using Agentï¼ˆCUAï¼‰æ–¹æ³•è‡ªåŠ¨åŒ–æ•°å­—å†…å®¹åˆ›å»ºå·¥å…·çš„æ“ä½œï¼ŒåŒæ—¶æ”¯æŒç”¨æˆ·åé¦ˆå’Œæœ¬åœ°LLMéƒ¨ç½²ä»¥ä¼˜åŒ–ç”Ÿæˆè´¨é‡å’Œé™ä½æˆæœ¬ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.04488v1">Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning</a></td><td><details><summary>å±•å¼€</summary>Multi-agent debate often wastes compute by using a fixed adversarial stance,
aggregating without deliberation, or stopping on heuristics. We introduce MACI,
an active controller with two independent dials that decouple information from
behavior: an information dial that gates evidence by quality, and a behavior
dial that schedules contentiousness from exploration to consolidation. A
moderator tracks disagreement, overlap, evidence quality, and argument quality,
and halts when gains plateau. We provide theory-lite guarantees for
nonincreasing dispersion and provable termination, with a budget-feasible
scheduler. Across clinical diagnosis and news-bias tasks, MACI improves
accuracy and calibration while reducing tokens, and converts residual
uncertainty into precision RAG plans that specify what to retrieve next. We use
a cross-family LLM judge (CRIT) as a conservative soft weight and stop signal,
validated for order invariance and judge-swap stability; stability depends on
using high-capability judges. MACI turns debate into a budget-aware,
measurable, and provably terminating controller.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†MACIï¼Œä¸€ç§å¤šæ™ºèƒ½ä½“è¾©è®ºæ§åˆ¶å™¨ï¼Œé€šè¿‡ä¿¡æ¯è´¨é‡ç­›é€‰å’Œè¡Œä¸ºè°ƒåº¦ä¼˜åŒ–è¾©è®ºè¿‡ç¨‹ï¼Œå¹¶åœ¨æ®‹ä½™ä¸ç¡®å®šæ€§æ—¶ç”Ÿæˆç²¾ç¡®çš„RAGè®¡åˆ’ä»¥æŒ‡å¯¼åç»­æ£€ç´¢ï¼Œä»è€Œæå‡ä»»åŠ¡å‡†ç¡®æ€§å’Œæ ¡å‡†åº¦ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-10-05
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody></tbody></table>

### ğŸ“… 2025-10-04
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody></tbody></table>

### ğŸ“… 2025-10-03
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody></tbody></table>

### ğŸ“… 2025-10-02
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2510.02243v1">AccurateRAG: A Framework for Building Accurate Retrieval-Augmented Question-Answering Applications</a></td><td><details><summary>å±•å¼€</summary>We introduce AccurateRAG -- a novel framework for constructing
high-performance question-answering applications based on retrieval-augmented
generation (RAG). Our framework offers a pipeline for development efficiency
with tools for raw dataset processing, fine-tuning data generation, text
embedding & LLM fine-tuning, output evaluation, and building RAG systems
locally. Experimental results show that our framework outperforms previous
strong baselines and obtains new state-of-the-art question-answering
performance on benchmark datasets.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†åä¸ºAccurateRAGçš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ„å»ºé«˜æ€§èƒ½é—®ç­”åº”ç”¨ã€‚è¯¥æ¡†æ¶æä¾›äº†ä¸€å¥—å¼€å‘æµç¨‹å·¥å…·ï¼ŒåŒ…æ‹¬åŸå§‹æ•°æ®é›†å¤„ç†ã€å¾®è°ƒæ•°æ®ç”Ÿæˆã€æ–‡æœ¬åµŒå…¥ä¸å¤§æ¨¡å‹å¾®è°ƒã€è¾“å‡ºè¯„ä¼°åŠæœ¬åœ°RAGç³»ç»Ÿæ„å»ºï¼Œå¹¶åœ¨å®éªŒä¸­è¶…è¶Šç°æœ‰åŸºçº¿ï¼Œå®ç°äº†åŸºå‡†æ•°æ®é›†ä¸Šçš„æœ€æ–°æœ€å…ˆè¿›é—®ç­”æ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.02044v1">Stream RAG: Instant and Accurate Spoken Dialogue Systems with Streaming Tool Usage</a></td><td><details><summary>å±•å¼€</summary>End-to-end speech-in speech-out dialogue systems are emerging as a powerful
alternative to traditional ASR-LLM-TTS pipelines, generating more natural,
expressive responses with significantly lower latency. However, these systems
remain prone to hallucinations due to limited factual grounding. While
text-based dialogue systems address this challenge by integrating tools such as
web search and knowledge graph APIs, we introduce the first approach to extend
tool use directly into speech-in speech-out systems. A key challenge is that
tool integration substantially increases response latency, disrupting
conversational flow. To mitigate this, we propose Streaming Retrieval-Augmented
Generation (Streaming RAG), a novel framework that reduces user-perceived
latency by predicting tool queries in parallel with user speech, even before
the user finishes speaking. Specifically, we develop a post-training pipeline
that teaches the model when to issue tool calls during ongoing speech and how
to generate spoken summaries that fuse audio queries with retrieved text
results, thereby improving both accuracy and responsiveness. To evaluate our
approach, we construct AudioCRAG, a benchmark created by converting queries
from the publicly available CRAG dataset into speech form. Experimental results
demonstrate that our streaming RAG approach increases QA accuracy by up to 200%
relative (from 11.1% to 34.2% absolute) and further enhances user experience by
reducing tool use latency by 20%. Importantly, our streaming RAG approach is
modality-agnostic and can be applied equally to typed input, paving the way for
more agentic, real-time AI assistants.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸º"Streaming Retrieval-Augmented Generation (Streaming RAG)"çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç«¯åˆ°ç«¯è¯­éŸ³å¯¹è¯ç³»ç»Ÿä¸­å­˜åœ¨çš„äº‹å®åŸºç¡€ä¸è¶³å’Œå»¶è¿Ÿé—®é¢˜ã€‚é€šè¿‡å¹¶è¡Œé¢„æµ‹å·¥å…·æŸ¥è¯¢å¹¶ä¸ç”¨æˆ·è¯­éŸ³åŒæ­¥å¤„ç†ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†é—®ç­”å‡†ç¡®æ€§ï¼ˆç›¸å¯¹æå‡200%ï¼‰å¹¶é™ä½20%çš„å·¥å…·ä½¿ç”¨å»¶è¿Ÿï¼ŒåŒæ—¶æ„å»ºäº†ä¸“é—¨çš„è¯­éŸ³è¯„æµ‹åŸºå‡†AudioCRAGã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.01910v1">Are LLMs Better GNN Helpers? Rethinking Robust Graph Learning under Deficiencies with Iterative Refinement</a></td><td><details><summary>å±•å¼€</summary>Graph Neural Networks (GNNs) are widely adopted in Web-related applications,
serving as a core technique for learning from graph-structured data, such as
text-attributed graphs. Yet in real-world scenarios, such graphs exhibit
deficiencies that substantially undermine GNN performance. While prior
GNN-based augmentation studies have explored robustness against individual
imperfections, a systematic understanding of how graph-native and Large
Language Models (LLMs) enhanced methods behave under compound deficiencies is
still missing. Specifically, there has been no comprehensive investigation
comparing conventional approaches and recent LLM-on-graph frameworks, leaving
their merits unclear. To fill this gap, we conduct the first empirical study
that benchmarks these two lines of methods across diverse graph deficiencies,
revealing overlooked vulnerabilities and challenging the assumption that LLM
augmentation is consistently superior. Building on empirical findings, we
propose Robust Graph Learning via Retrieval-Augmented Contrastive Refinement
(RoGRAD) framework. Unlike prior one-shot LLM-as-Enhancer designs, RoGRAD is
the first iterative paradigm that leverages Retrieval-Augmented Generation
(RAG) to inject retrieval-grounded augmentations by supplying class-consistent,
diverse augmentations and enforcing discriminative representations through
iterative graph contrastive learning. It transforms LLM augmentation for graphs
from static signal injection into dynamic refinement. Extensive experiments
demonstrate RoGRAD's superiority over both conventional GNN- and LLM-enhanced
baselines, achieving up to 82.43% average improvement.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºRoGRADçš„æ–°å‹å›¾å­¦ä¹ æ¡†æ¶ï¼Œé¦–æ¬¡å°†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯è¿­ä»£åº”ç”¨äºå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å¢å¼ºä»»åŠ¡ï¼Œé€šè¿‡åŠ¨æ€å¯¹æ¯”å­¦ä¹ æ³¨å…¥æ£€ç´¢åˆ°çš„ç±»åˆ«ä¸€è‡´æ€§æ•°æ®ï¼Œè§£å†³äº†ä¼ ç»ŸLLMé™æ€å¢å¼ºå’Œå¤åˆå›¾ç¼ºé™·ä¸‹çš„æ€§èƒ½ç“¶é¢ˆï¼Œå®éªŒæ˜¾ç¤ºå…¶æ•ˆæœæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.01800v1">REBot: From RAG to CatRAG with Semantic Enrichment and Graph Routing</a></td><td><details><summary>å±•å¼€</summary>Academic regulation advising is essential for helping students interpret and
comply with institutional policies, yet building effective systems requires
domain specific regulatory resources. To address this challenge, we propose
REBot, an LLM enhanced advisory chatbot powered by CatRAG, a hybrid retrieval
reasoning framework that integrates retrieval augmented generation with graph
based reasoning. CatRAG unifies dense retrieval and graph reasoning, supported
by a hierarchical, category labeled knowledge graph enriched with semantic
features for domain alignment. A lightweight intent classifier routes queries
to the appropriate retrieval modules, ensuring both factual accuracy and
contextual depth. We construct a regulation specific dataset and evaluate REBot
on classification and question answering tasks, achieving state of the art
performance with an F1 score of 98.89%. Finally, we implement a web application
that demonstrates the practical value of REBot in real world academic advising
scenarios.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†REBotï¼Œä¸€ç§åŸºäºCatRAGï¼ˆç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆä¸å›¾æ¨ç†çš„æ··åˆæ¡†æ¶ï¼‰çš„å­¦æœ¯æ³•è§„å’¨è¯¢èŠå¤©æœºå™¨äººã€‚CatRAGé€šè¿‡åˆ†å±‚æ ‡è®°çš„çŸ¥è¯†å›¾è°±å’Œè¯­ä¹‰ç‰¹å¾æ•´åˆå¯†é›†æ£€ç´¢ä¸å›¾æ¨ç†ï¼Œè½»é‡çº§æ„å›¾åˆ†ç±»å™¨ç¡®ä¿æŸ¥è¯¢çš„å‡†ç¡®æ€§å’Œä¸Šä¸‹æ–‡æ·±åº¦ã€‚å®éªŒè¡¨æ˜REBotåœ¨åˆ†ç±»å’Œé—®ç­”ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼ˆF1åˆ†æ•°98.89%ï¼‰ï¼Œå¹¶é€šè¿‡ç½‘é¡µåº”ç”¨éªŒè¯äº†å…¶å®é™…åº”ç”¨ä»·å€¼ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.01622v1">LLM4Rec: Large Language Models for Multimodal Generative Recommendation with Causal Debiasing</a></td><td><details><summary>å±•å¼€</summary>Contemporary generative recommendation systems face significant challenges in
handling multimodal data, eliminating algorithmic biases, and providing
transparent decision-making processes. This paper introduces an enhanced
generative recommendation framework that addresses these limitations through
five key innovations: multimodal fusion architecture, retrieval-augmented
generation mechanisms, causal inference-based debiasing, explainable
recommendation generation, and real-time adaptive learning capabilities. Our
framework leverages advanced large language models as the backbone while
incorporating specialized modules for cross-modal understanding, contextual
knowledge integration, bias mitigation, explanation synthesis, and continuous
model adaptation. Extensive experiments on three benchmark datasets
(MovieLens-25M, Amazon-Electronics, Yelp-2023) demonstrate consistent
improvements in recommendation accuracy, fairness, and diversity compared to
existing approaches. The proposed framework achieves up to 2.3% improvement in
NDCG@10 and 1.4% enhancement in diversity metrics while maintaining
computational efficiency through optimized inference strategies.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ”¹è¿›çš„ç”Ÿæˆå¼æ¨èæ¡†æ¶ï¼Œé€šè¿‡äº”é¡¹å…³é”®åˆ›æ–°è§£å†³å¤šæ¨¡æ€æ•°æ®å¤„ç†ã€ç®—æ³•åå·®æ¶ˆé™¤å’Œå†³ç­–é€æ˜åº¦ç­‰é—®é¢˜ï¼Œå…¶ä¸­åŒ…æ‹¬æ£€ç´¢å¢å¼ºç”Ÿæˆæœºåˆ¶ï¼ˆRAGï¼‰ã€‚è¯¥æ¡†æ¶ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ä¸å¤šæ¨¡æ€èåˆã€å»åå› æœæ¨ç†ç­‰æŠ€æœ¯ï¼Œåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶åœ¨æ¨èå‡†ç¡®æ€§ã€å…¬å¹³æ€§å’Œå¤šæ ·æ€§æ–¹é¢çš„æå‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.01612v1">RAG-BioQA Retrieval-Augmented Generation for Long-Form Biomedical Question Answering</a></td><td><details><summary>å±•å¼€</summary>The exponential growth of biomedical literature creates significant
challenges for accessing precise medical information. Current biomedical
question-answering systems primarily focus on short-form answers, failing to
provide the comprehensive explanations necessary for clinical decision-making.
We present RAG-BioQA, a novel framework combining retrieval-augmented
generation with domain-specific fine-tuning to produce evidence-based,
long-form biomedical answers. Our approach integrates BioBERT embeddings with
FAISS indexing and compares various re-ranking strategies (BM25, ColBERT,
MonoT5) to optimize context selection before synthesizing evidence through a
fine-tuned T5 model. Experimental results on the PubMedQA dataset show
significant improvements over baselines, with our best model achieving
substantial gains across BLEU, ROUGE, and METEOR metrics, advancing the state
of accessible, evidence-based biomedical knowledge retrieval.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†RAG-BioQAæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œé¢†åŸŸç‰¹å®šå¾®è°ƒï¼Œç”ŸæˆåŸºäºè¯æ®çš„é•¿ç¯‡ç”Ÿç‰©åŒ»å­¦ç­”æ¡ˆï¼Œä¼˜åŒ–äº†ä¸Šä¸‹æ–‡æ£€ç´¢ä¸åˆæˆï¼Œå¹¶åœ¨PubMedQAæ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—ä¼˜äºåŸºçº¿çš„æ€§èƒ½æå‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.01600v1">A Comparison of Independent and Joint Fine-tuning Strategies for Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>A Comparison of Independent and Joint Fine-tuning Strategies for
Retrieval-Augmented Generation Download PDF Neal Gregory Lawton, Alfy Samuel,
Anoop Kumar, Daben Liu Published: 20 Aug 2025, Last Modified: 17 Sept 2025EMNLP
2025 FindingsConference, Publication Chairs, AuthorsRevisionsBibTeXCC BY 4.0
Keywords: Retrieval-Augmented Generation (RAG), Large Language Models (LLMs),
Fine-tuning, Question Answering, Joint fine-tuning TL;DR: We evaluate and
compare strategies for fine-tuning Retrieval Augmented Generation (RAG)
pipelines, including independent fine-tuning, joint fine-tuning, and two-phase
fine-tuning. Abstract: Retrieval augmented generation (RAG) is a popular
framework for question answering that is powered by two large language models
(LLMs): an embedding model that retrieves context documents from a database
that are relevant to a given question, and a generator model that uses the
retrieved context to generate an answer to the question. Both the embedding and
generator models can be fine-tuned to increase performance of a RAG pipeline on
a new task, but multiple fine-tuning strategies exist with different costs and
benefits. In this paper, we evaluate and compare several RAG fine-tuning
strategies, including independent, joint, and two-phase fine-tuning. In our
experiments, we observe that all of these strategies achieve about equal
improvement in EM and F1 generation quality metrics, although they have
significantly different computational costs. We conclude the optimal
fine-tuning strategy to use depends on whether the training dataset includes
context labels and whether a grid search over the learning rates for the
embedding and generator models is required.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¯”è¾ƒäº†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä¸­ä¸åŒå¾®è°ƒç­–ç•¥ï¼ˆç‹¬ç«‹ã€è”åˆå’Œä¸¤é˜¶æ®µå¾®è°ƒï¼‰çš„æ€§èƒ½å’Œè®¡ç®—æˆæœ¬ï¼Œå‘ç°åœ¨ç”Ÿæˆè´¨é‡ä¸Šè¡¨ç°ç›¸è¿‘ä½†è®¡ç®—ä»£ä»·å·®å¼‚æ˜¾è‘—ï¼Œå¹¶æŒ‡å‡ºæœ€ä¼˜ç­–ç•¥å–å†³äºè®­ç»ƒæ•°æ®æ˜¯å¦åŒ…å«ä¸Šä¸‹æ–‡æ ‡ç­¾åŠæ˜¯å¦éœ€è¦å­¦ä¹ ç‡è°ƒä¼˜ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.01558v1">CardioRAG: A Retrieval-Augmented Generation Framework for Multimodal Chagas Disease Detection</a></td><td><details><summary>å±•å¼€</summary>Chagas disease affects nearly 6 million people worldwide, with Chagas
cardiomyopathy representing its most severe complication. In regions where
serological testing capacity is limited, AI-enhanced electrocardiogram (ECG)
screening provides a critical diagnostic alternative. However, existing machine
learning approaches face challenges such as limited accuracy, reliance on large
labeled datasets, and more importantly, weak integration with evidence-based
clinical diagnostic indicators. We propose a retrieval-augmented generation
framework, CardioRAG, integrating large language models with interpretable
ECG-based clinical features, including right bundle branch block, left anterior
fascicular block, and heart rate variability metrics. The framework uses
variational autoencoder-learned representations for semantic case retrieval,
providing contextual cases to guide clinical reasoning. Evaluation demonstrated
high recall performance of 89.80%, with a maximum F1 score of 0.68 for
effective identification of positive cases requiring prioritized serological
testing. CardioRAG provides an interpretable, clinical evidence-based approach
particularly valuable for resource-limited settings, demonstrating a pathway
for embedding clinical indicators into trustworthy medical AI systems.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºCardioRAGçš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹å’Œå¯è§£é‡Šçš„å¿ƒç”µå›¾ä¸´åºŠç‰¹å¾ï¼ˆå¦‚å³æŸæ”¯ä¼ å¯¼é˜»æ»ç­‰ï¼‰ï¼Œé€šè¿‡æ£€ç´¢ç›¸å…³ç—…ä¾‹æä¾›ä¸´åºŠæ¨ç†æŒ‡å¯¼ï¼Œæ˜¾è‘—æå‡äº†æ°åŠ æ–¯ç—…å¿ƒè‚Œç—…ç­›æŸ¥çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ï¼Œé€‚ç”¨äºèµ„æºæœ‰é™åœ°åŒºã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2510.01553v1">IoDResearch: Deep Research on Private Heterogeneous Data via the Internet of Data</a></td><td><details><summary>å±•å¼€</summary>The rapid growth of multi-source, heterogeneous, and multimodal scientific
data has increasingly exposed the limitations of traditional data management.
Most existing DeepResearch (DR) efforts focus primarily on web search while
overlooking local private data. Consequently, these frameworks exhibit low
retrieval efficiency for private data and fail to comply with the FAIR
principles, ultimately resulting in inefficiency and limited reusability. To
this end, we propose IoDResearch (Internet of Data Research), a private
data-centric Deep Research framework that operationalizes the Internet of Data
paradigm. IoDResearch encapsulates heterogeneous resources as FAIR-compliant
digital objects, and further refines them into atomic knowledge units and
knowledge graphs, forming a heterogeneous graph index for multi-granularity
retrieval. On top of this representation, a multi-agent system supports both
reliable question answering and structured scientific report generation.
Furthermore, we establish the IoD DeepResearch Benchmark to systematically
evaluate both data representation and Deep Research capabilities in IoD
scenarios. Experimental results on retrieval, QA, and report-writing tasks show
that IoDResearch consistently surpasses representative RAG and Deep Research
baselines. Overall, IoDResearch demonstrates the feasibility of
private-data-centric Deep Research under the IoD paradigm, paving the way
toward more trustworthy, reusable, and automated scientific discovery.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºIoDResearchæ¡†æ¶ï¼Œé€šè¿‡å°†å¼‚æ„æ•°æ®å°è£…ä¸ºFAIRåˆè§„çš„æ•°å­—å¯¹è±¡å¹¶æ„å»ºå¤šç²’åº¦æ£€ç´¢çš„å¼‚æ„å›¾ç´¢å¼•ï¼Œç»“åˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå®ç°å¯é é—®ç­”å’Œç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆï¼Œå®éªŒè¡¨æ˜å…¶åœ¨æ£€ç´¢å’Œç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºRAGåŸºçº¿ï¼Œå±äºRAGæŠ€æœ¯åœ¨ç§æœ‰æ•°æ®åœºæ™¯ä¸‹çš„ä¼˜åŒ–åº”ç”¨ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-10-01
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody></tbody></table>

### ğŸ“… 2025-09-30
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.26584v1">Fairness Testing in Retrieval-Augmented Generation: How Small Perturbations Reveal Bias in Small Language Models</a></td><td><details><summary>å±•å¼€</summary>Large Language Models (LLMs) are widely used across multiple domains but
continue to raise concerns regarding security and fairness. Beyond known attack
vectors such as data poisoning and prompt injection, LLMs are also vulnerable
to fairness bugs. These refer to unintended behaviors influenced by sensitive
demographic cues (e.g., race or sexual orientation) that should not affect
outcomes. Another key issue is hallucination, where models generate plausible
yet false information. Retrieval-Augmented Generation (RAG) has emerged as a
strategy to mitigate hallucinations by combining external retrieval with text
generation. However, its adoption raises new fairness concerns, as the
retrieved content itself may surface or amplify bias. This study conducts
fairness testing through metamorphic testing (MT), introducing controlled
demographic perturbations in prompts to assess fairness in sentiment analysis
performed by three Small Language Models (SLMs) hosted on HuggingFace
(Llama-3.2-3B-Instruct, Mistral-7B-Instruct-v0.3, and Llama-3.1-Nemotron-8B),
each integrated into a RAG pipeline. Results show that minor demographic
variations can break up to one third of metamorphic relations (MRs). A detailed
analysis of these failures reveals a consistent bias hierarchy, with
perturbations involving racial cues being the predominant cause of the
violations. In addition to offering a comparative evaluation, this work
reinforces that the retrieval component in RAG must be carefully curated to
prevent bias amplification. The findings serve as a practical alert for
developers, testers and small organizations aiming to adopt accessible SLMs
without compromising fairness or reliability.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†RAGæŠ€æœ¯ä¸­çš„å…¬å¹³æ€§é—®é¢˜ï¼Œé€šè¿‡èœ•å˜æµ‹è¯•è¯„ä¼°å°å‹è¯­è¨€æ¨¡å‹åœ¨RAGæµç¨‹ä¸­å¯¹æ•æ„Ÿäººå£ç»Ÿè®¡çº¿ç´¢çš„åå·®è¡¨ç°ï¼Œå¹¶æ­ç¤ºæ£€ç´¢å†…å®¹å¯èƒ½åŠ å‰§åè§çš„ç°è±¡ï¼Œæå‡ºéœ€è°¨æ…å¤„ç†æ£€ç´¢ç»„ä»¶ä»¥é¿å…åè§æ”¾å¤§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.26383v1">Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement Learning</a></td><td><details><summary>å±•å¼€</summary>Knowledge-graph retrieval-augmented generation (KG-RAG) couples large
language models (LLMs) with structured, verifiable knowledge graphs (KGs) to
reduce hallucinations and expose reasoning traces. However, many KG-RAG systems
compose multiple LLM modules (e.g planning, reasoning, and responding),
inflating inference cost and binding behavior to a specific target KG. To
address this, we introduce KG-R1, an agentic KG retrieval-augmented generation
(KG-RAG) framework through reinforcement learning (RL). KG-R1 utilizes a single
agent that interacts with KGs as its environment, learning to retrieve at each
step and incorporating the retrieved information into its reasoning and
generation. The process is optimized through end-to-end RL. In controlled
experiments across Knowledge-Graph Question Answering (KGQA) benchmarks, our
method demonstrates both efficiency and transferability: Using Qwen-2.5-3B,
KG-R1 improves answer accuracy with fewer generation tokens than prior
multi-module workflow methods that use larger foundation or fine-tuned models.
Furthermore, KG-R1 enables plug and play: after training, it maintains strong
accuracy on new KGs without modification. These properties make KG-R1 a
promising KG-RAG framework for real-world deployment. Our code is publicly
available at https://github.com/Jinyeop3110/KG-R1.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶KG-R1ï¼Œé€šè¿‡å•æ™ºèƒ½ä½“ä¸çŸ¥è¯†å›¾è°±äº¤äº’ï¼Œä¼˜åŒ–æ£€ç´¢å’Œç”Ÿæˆè¿‡ç¨‹ï¼Œåœ¨é™ä½æ¨ç†æˆæœ¬çš„åŒæ—¶æé«˜å‡†ç¡®æ€§å’Œå¯è¿ç§»æ€§ï¼Œå¹¶åœ¨KGQAåŸºå‡†æµ‹è¯•ä¸­éªŒè¯äº†å…¶é«˜æ•ˆæ€§å’Œå³æ’å³ç”¨èƒ½åŠ›ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.26205v1">Human-Centered Evaluation of RAG outputs: a framework and questionnaire for human-AI collaboration</a></td><td><details><summary>å±•å¼€</summary>Retrieval-augmented generation (RAG) systems are increasingly deployed in
user-facing applications, yet systematic, human-centered evaluation of their
outputs remains underexplored. Building on Gienapp's utility-dimension
framework, we designed a human-centred questionnaire that assesses RAG outputs
across 12 dimensions. We iteratively refined the questionnaire through several
rounds of ratings on a set of query-output pairs and semantic discussions.
Ultimately, we incorporated feedback from both a human rater and a human-LLM
pair. Results indicate that while large language models (LLMs) reliably focus
on metric descriptions and scale labels, they exhibit weaknesses in detecting
textual format variations. Humans struggled to focus strictly on metric
descriptions and labels. LLM ratings and explanations were viewed as a helpful
support, but numeric LLM and human ratings lacked agreement. The final
questionnaire extends the initial framework by focusing on user intent, text
structuring, and information verifiability.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æ¢è®¨äº†ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„RAGç³»ç»Ÿè¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡è®¾è®¡åŒ…å«12ä¸ªç»´åº¦çš„é—®å·ï¼Œç»“åˆäººç±»ä¸LLMçš„åé¦ˆè¿­ä»£ä¼˜åŒ–ï¼Œå‘ç°LLMåœ¨æ–‡æœ¬æ ¼å¼è¯†åˆ«ä¸Šçš„ä¸è¶³åŠäººæœºè¯„åˆ†å·®å¼‚ï¼Œæœ€ç»ˆæ‰©å±•äº†è¯„ä¼°æ¡†æ¶ä»¥é‡ç‚¹å…³æ³¨ç”¨æˆ·æ„å›¾ã€æ–‡æœ¬ç»“æ„å’Œä¿¡æ¯å¯éªŒè¯æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.26184v1">Auto-ARGUE: LLM-Based Report Generation Evaluation</a></td><td><details><summary>å±•å¼€</summary>Generation of long-form, citation-backed reports is a primary use case for
retrieval augmented generation (RAG) systems. While open-source evaluation
tools exist for various RAG tasks, ones tailored to report generation are
lacking. Accordingly, we introduce Auto-ARGUE, a robust LLM-based
implementation of the recent ARGUE framework for report generation evaluation.
We present analysis of Auto-ARGUE on the report generation pilot task from the
TREC 2024 NeuCLIR track, showing good system-level correlations with human
judgments. We further release a web app for visualization of Auto-ARGUE
outputs.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†Auto-ARGUEï¼Œä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å·¥å…·ï¼Œç”¨äºè¯„ä¼°æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿåœ¨ç”Ÿæˆå¸¦å¼•ç”¨çš„é•¿ç¯‡æŠ¥å‘Šä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨TREC 2024 NeuCLIRä»»åŠ¡ä¸Šä¸äººç±»è¯„ä»·çš„è‰¯å¥½ç›¸å…³æ€§ï¼ŒåŒæ—¶å‘å¸ƒäº†å¯è§†åŒ–è¾“å‡ºçš„ç½‘é¡µåº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.26136v1">CliniBench: A Clinical Outcome Prediction Benchmark for Generative and Encoder-Based Language Models</a></td><td><details><summary>å±•å¼€</summary>With their growing capabilities, generative large language models (LLMs) are
being increasingly investigated for complex medical tasks. However, their
effectiveness in real-world clinical applications remains underexplored. To
address this, we present CliniBench, the first benchmark that enables
comparability of well-studied encoder-based classifiers and generative LLMs for
discharge diagnosis prediction from admission notes in MIMIC-IV dataset. Our
extensive study compares 12 generative LLMs and 3 encoder-based classifiers and
demonstrates that encoder-based classifiers consistently outperform generative
models in diagnosis prediction. We assess several retrieval augmentation
strategies for in-context learning from similar patients and find that they
provide notable performance improvements for generative LLMs.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« ä»‹ç»äº†CliniBenchï¼Œä¸€ä¸ªç”¨äºæ¯”è¾ƒåŸºäºç¼–ç å™¨çš„åˆ†ç±»å™¨å’Œç”Ÿæˆå¼å¤§è¯­è¨€æ¨¡å‹åœ¨MIMIC-IVæ•°æ®é›†å‡ºé™¢è¯Šæ–­é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°çš„åŸºå‡†æµ‹è¯•ï¼Œç ”ç©¶å‘ç°ç¼–ç å™¨æ¨¡å‹è¡¨ç°æ›´ä¼˜ï¼Œå¹¶é€šè¿‡æ£€ç´¢å¢å¼ºç­–ç•¥æå‡äº†ç”Ÿæˆæ¨¡å‹çš„æ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.26011v1">RAGferee: Building Contextual Reward Models for Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>Existing Reward Models (RMs), typically trained on general preference data,
struggle in Retrieval Augmented Generation (RAG) settings, which require
judging responses for faithfulness to retrieved context, relevance to the user
query, appropriate refusals when context is insufficient, completeness and
conciseness of information. To address the lack of publicly available
RAG-centric preference datasets and specialised RMs, we introduce RAGferee, a
methodology that repurposes question-answering (QA) datasets into preference
pairs that prioritise groundedness over stylistic features, enabling the
training of contextual RMs better suited to judging RAG responses. Using
RAGferee, we curate a small preference dataset of 4K samples and fine-tune RMs
ranging from 7B to 24B parameters. Our RAG-centric RMs achieve state-of-the-art
performance on ContextualJudgeBench, surpassing existing 70B+ RMs trained on
much larger (up to 2.4M samples) general corpora, with an absolute improvement
of +15.5%.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡é’ˆå¯¹ç°æœ‰å¥–åŠ±æ¨¡å‹ï¼ˆRMsï¼‰åœ¨RAGåœºæ™¯ä¸­çš„ä¸è¶³ï¼ˆå¦‚å¯¹æ£€ç´¢å†…å®¹å¿ å®åº¦ã€æŸ¥è¯¢ç›¸å…³æ€§ã€ä¿¡æ¯å®Œæ•´æ€§çš„è¯„ä¼°ï¼‰ï¼Œæå‡ºRAGfereeæ–¹æ³•ï¼Œå°†é—®ç­”æ•°æ®é›†è½¬æ¢ä¸ºä¼˜å…ˆè€ƒè™‘äº‹å®å‡†ç¡®æ€§çš„åå¥½æ•°æ®ï¼Œå¹¶è®­ç»ƒå‡ºä¸“ç”¨äºRAGå“åº”çš„RMï¼Œå…¶æ€§èƒ½åœ¨ContextualJudgeBenchä¸Šè¶…è¶Šé€šç”¨å¤§å‹RMï¼ˆ+15.5%ï¼‰ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.25973v1">Scalable and Robust LLM Unlearning by Correcting Responses with Retrieved Exclusions</a></td><td><details><summary>å±•å¼€</summary>Language models trained on web-scale corpora risk memorizing and exposing
sensitive information, prompting the need for effective machine unlearning.
Prior methods mainly focus on input queries to suppress sensitive outputs, yet
this often fails to eliminate the underlying knowledge and limits scalability.
To address this, we propose Corrective Unlearning with Retrieved Exclusions
(CURE), a novel unlearning framework that verifies model outputs for leakage
and revises them into safe responses. Specifically, CURE employs a lightweight
corrector that is applied to the original model to verify whether outputs
contain target knowledge and to rewrite them if any leakage is detected. To
efficiently handle large-scale unlearning requests, CURE retrieves unlearning
targets that are relevant to the initial response and provides them as
in-context references to the corrector for detection and conditional revision.
By leveraging this retrieval augmentation, the corrector can adapt to new
unlearning requests without additional training. Extensive evaluations
demonstrate that CURE substantially reduces information leakage, even from
indirect queries where prior works fall short, while maintaining response
quality and general utility. Moreover, it demonstrates robustness under
continual unlearning scenarios, making it practical for real-world
applications.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºCUREçš„æœºå™¨é—å¿˜æ¡†æ¶ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯æ£€æµ‹å’Œä¿®æ­£æ¨¡å‹è¾“å‡ºä¸­çš„æ•æ„Ÿä¿¡æ¯æ³„æ¼ã€‚å®ƒåˆ©ç”¨è½»é‡çº§æ ¡æ­£å™¨ç»“åˆæ£€ç´¢åˆ°çš„ç›¸å…³é—å¿˜ç›®æ ‡ï¼ŒåŠ¨æ€è°ƒæ•´è¾“å‡ºä»¥ç¡®ä¿å®‰å…¨ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½å’Œæ‰©å±•æ€§ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æŒç»­é—å¿˜åœºæ™¯ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.25839v1">RAE: A Neural Network Dimensionality Reduction Method for Nearest Neighbors Preservation in Vector Search</a></td><td><details><summary>å±•å¼€</summary>While high-dimensional embedding vectors are being increasingly employed in
various tasks like Retrieval-Augmented Generation and Recommendation Systems,
popular dimensionality reduction (DR) methods such as PCA and UMAP have rarely
been adopted for accelerating the retrieval process due to their inability of
preserving the nearest neighbor (NN) relationship among vectors. Empowered by
neural networks' optimization capability and the bounding effect of Rayleigh
quotient, we propose a Regularized Auto-Encoder (RAE) for k-NN preserving
dimensionality reduction. RAE constrains the network parameter variation
through regularization terms, adjusting singular values to control embedding
magnitude changes during reduction, thus preserving k-NN relationships. We
provide a rigorous mathematical analysis demonstrating that regularization
establishes an upper bound on the norm distortion rate of transformed vectors,
thereby offering provable guarantees for k-NN preservation. With modest
training overhead, RAE achieves superior k-NN recall compared to existing DR
approaches while maintaining fast retrieval efficiency.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§ç”¨äºä¿æŒkæœ€è¿‘é‚»ï¼ˆk-NNï¼‰å…³ç³»çš„æ­£åˆ™åŒ–è‡ªåŠ¨ç¼–ç å™¨ï¼ˆRAEï¼‰ï¼Œæ—¨åœ¨è§£å†³é«˜ç»´åµŒå…¥å‘é‡åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­‰ä»»åŠ¡ä¸­å› ç»´åº¦ç¼©å‡å¯¼è‡´çš„æœ€è¿‘é‚»å…³ç³»ç ´åé—®é¢˜ï¼Œä»è€Œæå‡æ£€ç´¢æ•ˆç‡å¹¶ä¿è¯å‡†ç¡®æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.25736v1">Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications</a></td><td><details><summary>å±•å¼€</summary>The success of large language models (LLMs) depends heavily on large-scale,
high-quality instruction-following and reinforcement datasets. However,
generating such data through human annotation is prohibitively time-consuming
particularly for domain-specific tasks like telecom network troubleshooting,
where accurate responses require deep technical expertise and contextual
understanding. In this paper, we present a fully automated, retrieval-augmented
pipeline for generating synthetic question-answer (QA) pairs grounded in
structured domain knowledge. Our multi-stage framework integrates a retriever,
base generator, and refinement model to synthesize and enhance QA pairs using
documents retrieved from a domain-specific knowledge graph. To ensure data
quality, we employ customized RAGAS-based scoring to filter low-quality
samples, producing a high-quality dataset suitable for reinforcement
fine-tuning (RFT). We demonstrate our approach in a real-world telecom scenario
focused on radio access network (RAN) troubleshooting. The resulting pipeline
generates complex, context-rich troubleshooting solution plans without human
intervention. This work offers a scalable solution for building instruction and
reinforcement datasets in specialized domains, significantly reducing
dependence on manual labeling while maintaining high technical fidelity.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨è‡ªåŠ¨ã€æ£€ç´¢å¢å¼ºçš„æµç¨‹ï¼Œç”¨äºç”ŸæˆåŸºäºç»“æ„åŒ–é¢†åŸŸçŸ¥è¯†çš„åˆæˆé—®ç­”å¯¹ï¼ˆQAï¼‰ï¼Œé€šè¿‡ç»“åˆæ£€ç´¢å™¨ã€åŸºç¡€ç”Ÿæˆå™¨å’Œç²¾ç‚¼æ¨¡å‹çš„å¤šé˜¶æ®µæ¡†æ¶ï¼Œä»é¢†åŸŸç‰¹å®šçŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢æ–‡æ¡£å¹¶ç”Ÿæˆé«˜è´¨é‡QAæ•°æ®é›†ï¼Œåº”ç”¨äºç”µä¿¡ç½‘ç»œæ•…éšœæ’é™¤ç­‰ä¸“ä¸šé¢†åŸŸã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.25716v1">DeepCodeSeek: Real-Time API Retrieval for Context-Aware Code Generation</a></td><td><details><summary>å±•å¼€</summary>Current search techniques are limited to standard RAG query-document
applications. In this paper, we propose a novel technique to expand the code
and index for predicting the required APIs, directly enabling high-quality,
end-to-end code generation for auto-completion and agentic AI applications. We
address the problem of API leaks in current code-to-code benchmark datasets by
introducing a new dataset built from real-world ServiceNow Script Includes that
capture the challenge of unclear API usage intent in the code. Our evaluation
metrics show that this method achieves 87.86% top-40 retrieval accuracy,
allowing the critical context with APIs needed for successful downstream code
generation. To enable real-time predictions, we develop a comprehensive
post-training pipeline that optimizes a compact 0.6B reranker through synthetic
dataset generation, supervised fine-tuning, and reinforcement learning. This
approach enables our compact reranker to outperform a much larger 8B model
while maintaining 2.5x reduced latency, effectively addressing the nuances of
enterprise-specific code without the computational overhead of larger models.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ‰©å±•RAGæŠ€æœ¯å’Œç´¢å¼•çš„æ–°æ–¹æ³•ï¼Œä¸“æ³¨äºé€šè¿‡æ£€ç´¢é¢„æµ‹æ‰€éœ€APIä»¥å®ç°é«˜è´¨é‡çš„ç«¯åˆ°ç«¯ä»£ç ç”Ÿæˆï¼Œè§£å†³äº†å½“å‰ä»£ç åŸºå‡†æ•°æ®é›†ä¸­APIæ³„éœ²é—®é¢˜ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–çš„åè®­ç»ƒæµç¨‹æå‡å®æ—¶é¢„æµ‹æ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.25669v1">GroundSight: Augmenting Vision-Language Models with Grounding Information and De-hallucination</a></td><td><details><summary>å±•å¼€</summary>We propose a method to improve Visual Question Answering (VQA) with
Retrieval-Augmented Generation (RAG) by introducing text-grounded object
localization. Rather than retrieving information based on the entire image, our
approach enables the model to generate a bounding box around the object most
relevant to the question, allowing for targeted image cropping and focused
retrieval. This reduces background noise, improves alignment between visual and
textual cues, and helps mitigate hallucinations. Our RAG method enhances
context-aware VQA responses increased the accuracy from 22.19% to 25.64%, with
an absolute increase of 3.45 percentage points, compared to the baseline
Llama-3.2-Vision-11B agent. We also proposed a de-hallucination method based on
question type which can effectively reduce the hallucination rate from 65.79%
to 13.88% and improves the truthfulness score.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›è§†è§‰é—®ç­”ï¼ˆVQAï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆRAGæŠ€æœ¯å’ŒåŸºäºæ–‡æœ¬çš„ç‰©ä½“å®šä½ï¼Œæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆä¸é—®é¢˜æœ€ç›¸å…³ç‰©ä½“çš„è¾¹ç•Œæ¡†ï¼Œä»è€Œè¿›è¡Œé’ˆå¯¹æ€§å›¾åƒè£å‰ªå’Œèšç„¦æ£€ç´¢ã€‚æ­¤æ–¹æ³•å‡å°‘äº†èƒŒæ™¯å™ªå£°ï¼Œæå‡äº†è§†è§‰ä¸æ–‡æœ¬çº¿ç´¢çš„å¯¹é½ï¼Œå¹¶é™ä½äº†å¹»è§‰ç°è±¡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥RAGæ–¹æ³•å°†VQAå‡†ç¡®ç‡ä»22.19%æå‡è‡³25.64%ï¼Œå¹¶æå‡ºäº†åŸºäºé—®é¢˜ç±»å‹çš„å»å¹»è§‰æ–¹æ³•ï¼Œå°†å¹»è§‰ç‡ä»65.79%é™ä½è‡³13.88%ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-29
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.25143v1">TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models</a></td><td><details><summary>å±•å¼€</summary>Existing medical reasoning benchmarks for vision-language models primarily
focus on analyzing a patient's condition based on an image from a single visit.
However, this setting deviates significantly from real-world clinical practice,
where doctors typically refer to a patient's historical conditions to provide a
comprehensive assessment by tracking their changes over time. In this paper, we
introduce TemMed-Bench, the first benchmark designed for analyzing changes in
patients' conditions between different clinical visits, which challenges large
vision-language models (LVLMs) to reason over temporal medical images.
TemMed-Bench consists of a test set comprising three tasks - visual
question-answering (VQA), report generation, and image-pair selection - and a
supplementary knowledge corpus of over 17,000 instances. With TemMed-Bench, we
conduct an evaluation of six proprietary and six open-source LVLMs. Our results
show that most LVLMs lack the ability to analyze patients' condition changes
over temporal medical images, and a large proportion perform only at a
random-guessing level in the closed-book setting. In contrast, GPT o3, o4-mini
and Claude 3.5 Sonnet demonstrate comparatively decent performance, though they
have yet to reach the desired level. Furthermore, we explore augmenting the
input with both retrieved visual and textual modalities in the medical domain.
We also show that multi-modal retrieval augmentation yields notably higher
performance gains than no retrieval and textual retrieval alone across most
models on our benchmark, with the VQA task showing an average improvement of
2.59%. Overall, we compose a benchmark grounded on real-world clinical
practice, and it reveals LVLMs' limitations in temporal medical image
reasoning, as well as highlighting the use of multi-modal retrieval
augmentation as a potentially promising direction worth exploring to address
this challenge.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†TemMed-Benchï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°å¤§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨æ—¶é—´æ€§åŒ»å­¦å›¾åƒæ¨ç†ä¸­åˆ†ææ‚£è€…ç—…æƒ…å˜åŒ–èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨æ­¤ä»»åŠ¡ä¸Šçš„å±€é™æ€§ï¼Œå¹¶æ¢è®¨äº†é€šè¿‡å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºï¼ˆç»“åˆè§†è§‰å’Œæ–‡æœ¬æ£€ç´¢ï¼‰æå‡æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨è§†è§‰é—®ç­”ç­‰ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼ˆå¹³å‡æå‡2.59%ï¼‰ï¼Œè¡¨æ˜å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºæ˜¯è§£å†³è¿™ä¸€æŒ‘æˆ˜çš„æ½œåœ¨æ–¹å‘ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.24869v1">Retro*: Optimizing LLMs for Reasoning-Intensive Document Retrieval</a></td><td><details><summary>å±•å¼€</summary>With the growing popularity of LLM agents and RAG, it has become increasingly
important to retrieve documents that are essential for solving a task, even
when their connection to the task is indirect or implicit. Addressing this
problem requires fine-grained reasoning to accurately assess the relevance
between the task and each candidate document. This capability, however, poses a
significant challenge for existing IR techniques. Despite recent progress in
reasoning-enhanced IR, existing approaches still face significant challenges in
applicability, scalability, and efficiency. In this work, we propose Retro*, a
novel approach for reasoning-intensive document retrieval. Our method
introduces a rubric-based relevance scoring mechanism, enabling the model to
reason about the relationship between a task and a document based on explicitly
defined criteria, whereby producing a fine-grained, interpretable relevance
score. Retro* also supports test-time scaling by combining multiple reasoning
trajectories via score integration, which produces more reliable relevance
estimates. To optimize Retro*'s reasoning capabilities, we introduce a novel
reinforcement learning algorithm tailored for its relevance scoring mechanism,
which employs two composite rewards to fully exploit the trajectories of each
training sample. Our experiments show that Retro* outperforms existing document
retrieval methods with notable advantages, leading to state-of-the-art
performance on the BRIGHT benchmark.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†Retro*æ–¹æ³•ï¼Œé€šè¿‡ç»†ç²’åº¦æ¨ç†å’ŒåŸºäºæ ‡å‡†çš„è¯„åˆ†æœºåˆ¶æ¥æ”¹è¿›æ–‡æ¡£æ£€ç´¢ï¼Œè§£å†³RAGä¸­å› ä»»åŠ¡ä¸æ–‡æ¡£é—´æ¥å…³è”å¯¼è‡´çš„æ£€ç´¢éš¾é¢˜ï¼Œå¹¶åœ¨BRIGHTåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.24866v1">Metaphor identification using large language models: A comparison of RAG, prompt engineering, and fine-tuning</a></td><td><details><summary>å±•å¼€</summary>Metaphor is a pervasive feature of discourse and a powerful lens for
examining cognition, emotion, and ideology. Large-scale analysis, however, has
been constrained by the need for manual annotation due to the context-sensitive
nature of metaphor. This study investigates the potential of large language
models (LLMs) to automate metaphor identification in full texts. We compare
three methods: (i) retrieval-augmented generation (RAG), where the model is
provided with a codebook and instructed to annotate texts based on its rules
and examples; (ii) prompt engineering, where we design task-specific verbal
instructions; and (iii) fine-tuning, where the model is trained on hand-coded
texts to optimize performance. Within prompt engineering, we test zero-shot,
few-shot, and chain-of-thought strategies. Our results show that
state-of-the-art closed-source LLMs can achieve high accuracy, with fine-tuning
yielding a median F1 score of 0.79. A comparison of human and LLM outputs
reveals that most discrepancies are systematic, reflecting well-known grey
areas and conceptual challenges in metaphor theory. We propose that LLMs can be
used to at least partly automate metaphor identification and can serve as a
testbed for developing and refining metaphor identification protocols and the
theory that underpins them.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡ç ”ç©¶äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªåŠ¨åŒ–è¯†åˆ«æ–‡æœ¬ä¸­éšå–»çš„ä¸‰ç§æ–¹æ³•ï¼ŒåŒ…æ‹¬æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€æç¤ºå·¥ç¨‹å’Œå¾®è°ƒï¼Œå¹¶å‘ç°RAGç»“åˆä»£ç ä¹¦è§„åˆ™ä¸ç¤ºä¾‹çš„æ–¹æ³•èƒ½æœ‰æ•ˆæå‡éšå–»æ ‡æ³¨çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶æ­ç¤ºäº†æ¨¡å‹ä¸äººç±»æ ‡æ³¨å·®å¼‚çš„ç³»ç»Ÿæ€§ç†è®ºæ ¹æºã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.24276v1">G-reasoner: Foundation Models for Unified Reasoning over Graph-structured Knowledge</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) excel at complex reasoning but remain limited by
static and incomplete parametric knowledge. Retrieval-augmented generation
(RAG) mitigates this by incorporating external knowledge, yet existing RAGs
struggle with knowledge-intensive tasks due to fragmented information and weak
modeling of knowledge structure. Graphs offer a natural way to model
relationships within knowledge, but LLMs are inherently unstructured and cannot
effectively reason over graph-structured data. Recent graph-enhanced RAG
(GraphRAG) attempts to bridge this gap by constructing tailored graphs and
enabling LLMs to reason on them. However, these methods often depend on ad-hoc
graph designs, heuristic search, or costly agent pipelines, which hinder
scalability and generalization. To address these challenges, we present
G-reasoner, a unified framework that integrates graph and language foundation
models for reasoning over diverse graph-structured knowledge. Central to our
approach is QuadGraph, a standardized four-layer abstraction that unifies
heterogeneous knowledge sources into a common graph representation. Building on
this, we introduce a 34M-parameter graph foundation model (GFM) that jointly
captures graph topology and textual semantics, and is integrated with LLMs to
enhance reasoning in downstream applications. To ensure scalability and
efficiency, mixed-precision training and distributed message-passing are
implemented to scale GFM with more GPUs. Extensive experiments on six
benchmarks show that G-reasoner consistently outperforms state-of-the-art
baselines, significantly enhances LLM reasoning, and achieves strong efficiency
and cross-graph generalization.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºG-reasonerçš„ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆå›¾ç»“æ„å’Œè¯­è¨€åŸºç¡€æ¨¡å‹ï¼ˆå¦‚QuadGraphæ ‡å‡†åŒ–æŠ½è±¡å±‚å’Œå›¾åŸºç¡€æ¨¡å‹GFMï¼‰ï¼Œæ”¹è¿›ç°æœ‰RAGåœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼ˆå¦‚ä¿¡æ¯ç¢ç‰‡åŒ–å’ŒçŸ¥è¯†ç»“æ„å»ºæ¨¡è–„å¼±ï¼‰ï¼Œå¹¶å®éªŒè¯æ˜äº†å…¶åœ¨å¢å¼ºå¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›ã€æ•ˆç‡åŠè·¨å›¾æ³›åŒ–æ€§æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.24253v1">MRAG-Suite: A Diagnostic Evaluation Platform for Visual Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>Multimodal Retrieval-Augmented Generation (Visual RAG) significantly advances
question answering by integrating visual and textual evidence. Yet, current
evaluations fail to systematically account for query difficulty and ambiguity.
We propose MRAG-Suite, a diagnostic evaluation platform integrating diverse
multimodal benchmarks (WebQA, Chart-RAG, Visual-RAG, MRAG-Bench). We introduce
difficulty-based and ambiguity-aware filtering strategies, alongside
MM-RAGChecker, a claim-level diagnostic tool. Our results demonstrate
substantial accuracy reductions under difficult and ambiguous queries,
highlighting prevalent hallucinations. MM-RAGChecker effectively diagnoses
these issues, guiding future improvements in Visual RAG systems.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†MRAG-Suiteï¼Œä¸€ä¸ªé’ˆå¯¹å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆVisual RAGï¼‰çš„è¯Šæ–­è¯„ä¼°å¹³å°ï¼Œé€šè¿‡æ•´åˆå¤šç§å¤šæ¨¡æ€åŸºå‡†å’Œå¼•å…¥åŸºäºéš¾åº¦åŠæ¨¡ç³Šæ€§çš„è¿‡æ»¤ç­–ç•¥ï¼Œæ­ç¤ºäº†ç°æœ‰ç³»ç»Ÿåœ¨é¢å¯¹å›°éš¾å’Œæ¨¡ç³ŠæŸ¥è¯¢æ—¶çš„å‡†ç¡®ç‡ä¸‹é™é—®é¢˜ï¼Œå¹¶æä¾›äº†è¯Šæ–­å·¥å…·MM-RAGCheckerä»¥æŒ‡å¯¼æœªæ¥æ”¹è¿›ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.24212v1">ScenarioBench: Trace-Grounded Compliance Evaluation for Text-to-SQL and RAG</a></td><td><details><summary>å±•å¼€</summary>ScenarioBench is a policy-grounded, trace-aware benchmark for evaluating
Text-to-SQL and retrieval-augmented generation in compliance contexts. Each
YAML scenario includes a no-peek gold-standard package with the expected
decision, a minimal witness trace, the governing clause set, and the canonical
SQL, enabling end-to-end scoring of both what a system decides and why. Systems
must justify outputs using clause IDs from the same policy canon, making
explanations falsifiable and audit-ready. The evaluator reports decision
accuracy, trace quality (completeness, correctness, order), retrieval
effectiveness, SQL correctness via result-set equivalence, policy coverage,
latency, and an explanation-hallucination rate. A normalized Scenario
Difficulty Index (SDI) and a budgeted variant (SDI-R) aggregate results while
accounting for retrieval difficulty and time. Compared with prior Text-to-SQL
or KILT/RAG benchmarks, ScenarioBench ties each decision to clause-level
evidence under strict grounding and no-peek rules, shifting gains toward
justification quality under explicit time budgets.</details></td><td><details><summary>å±•å¼€</summary>ScenarioBenchæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°æ–‡æœ¬åˆ°SQLï¼ˆText-to-SQLï¼‰å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨åˆè§„åœºæ™¯ä¸‹çš„åŸºå‡†æµ‹è¯•å·¥å…·ï¼Œå®ƒé€šè¿‡YAMLåœºæ™¯æ•´åˆäº†å†³ç­–ä¾æ®ã€è¿½è¸ªä¿¡æ¯ã€æ¡æ¬¾é›†å’Œæ ‡å‡†SQLï¼Œæ”¯æŒç«¯åˆ°ç«¯è¯„åˆ†ï¼Œå¹¶å¼ºè°ƒè¾“å‡ºçš„å¯éªŒè¯æ€§ä¸å®¡è®¡å°±ç»ªæ€§ï¼ŒåŒæ—¶æä¾›å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡å’Œéš¾åº¦æŒ‡æ•°ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.24183v1">Retrieval-augmented GUI Agents with Generative Guidelines</a></td><td><details><summary>å±•å¼€</summary>GUI agents powered by vision-language models (VLMs) show promise in
automating complex digital tasks. However, their effectiveness in real-world
applications is often limited by scarce training data and the inherent
complexity of these tasks, which frequently require long-tailed knowledge
covering rare, unseen scenarios. We propose RAG-GUI , a lightweight VLM that
leverages web tutorials at inference time. RAG-GUI is first warm-started via
supervised finetuning (SFT) and further refined through self-guided rejection
sampling finetuning (RSF). Designed to be model-agnostic, RAG-GUI functions as
a generic plug-in that enhances any VLM-based agent. Evaluated across three
distinct tasks, it consistently outperforms baseline agents and surpasses other
inference baselines by 2.6% to 13.3% across two model sizes, demonstrating
strong generalization and practical plug-and-play capabilities in real-world
scenarios.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†RAG-GUIï¼Œä¸€ç§åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„è½»é‡çº§GUIä»£ç†ï¼Œé€šè¿‡åˆ©ç”¨ç½‘é¡µæ•™ç¨‹ä½œä¸ºæ£€ç´¢å¢å¼ºçš„æ¨ç†èµ„æºæ¥è§£å†³å¤æ‚æ•°å­—ä»»åŠ¡ä¸­è®­ç»ƒæ•°æ®ç¨€ç¼ºå’Œé•¿å°¾çŸ¥è¯†ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡ç›‘ç£å¾®è°ƒå’Œè‡ªå¼•å¯¼æ‹’ç»é‡‡æ ·å¾®è°ƒä¼˜åŒ–æ¨¡å‹ï¼Œå±•ç°å‡ºå¼ºæ³›åŒ–èƒ½åŠ›å’Œå³æ’å³ç”¨ç‰¹æ€§ï¼Œåœ¨å¤šé¡¹ä»»åŠ¡ä¸­ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-28
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.23874v1">Multi-Value-Product Retrieval-Augmented Generation for Industrial Product Attribute Value Identification</a></td><td><details><summary>å±•å¼€</summary>Identifying attribute values from product profiles is a key task for
improving product search, recommendation, and business analytics on e-commerce
platforms, which we called Product Attribute Value Identification (PAVI) .
However, existing PAVI methods face critical challenges, such as cascading
errors, inability to handle out-of-distribution (OOD) attribute values, and
lack of generalization capability. To address these limitations, we introduce
Multi-Value-Product Retrieval-Augmented Generation (MVP-RAG), combining the
strengths of retrieval, generation, and classification paradigms. MVP-RAG
defines PAVI as a retrieval-generation task, where the product title
description serves as the query, and products and attribute values act as the
corpus. It first retrieves similar products of the same category and candidate
attribute values, and then generates the standardized attribute values. The key
advantages of this work are: (1) the proposal of a multi-level retrieval
scheme, with products and attribute values as distinct hierarchical levels in
PAVI domain (2) attribute value generation of large language model to
significantly alleviate the OOD problem and (3) its successful deployment in a
real-world industrial environment. Extensive experimental results demonstrate
that MVP-RAG performs better than the state-of-the-art baselines.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç§°ä¸ºMVP-RAGï¼ˆMulti-Value-Product Retrieval-Augmented Generationï¼‰çš„æ–¹æ³•ï¼Œç”¨äºè§£å†³ç”µå­å•†åŠ¡å¹³å°ä¸­çš„äº§å“å±æ€§å€¼è¯†åˆ«ï¼ˆPAVIï¼‰é—®é¢˜ã€‚MVP-RAGç»“åˆäº†æ£€ç´¢ã€ç”Ÿæˆå’Œåˆ†ç±»èŒƒå¼ï¼Œé€šè¿‡å¤šçº§æ£€ç´¢æ–¹æ¡ˆï¼ˆäº§å“å±‚çº§å’Œå±æ€§å€¼å±‚çº§ï¼‰æ£€ç´¢ç›¸ä¼¼äº§å“å’Œå€™é€‰å±æ€§å€¼ï¼Œç„¶ååˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ ‡å‡†åŒ–çš„å±æ€§å€¼ï¼Œæ˜¾è‘—ç¼“è§£äº†åˆ†å¸ƒå¤–ï¼ˆOODï¼‰é—®é¢˜ï¼Œå¹¶å·²åœ¨å·¥ä¸šç¯å¢ƒä¸­æˆåŠŸéƒ¨ç½²ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå…¶æ€§èƒ½ä¼˜äºç°æœ‰æœ€ä¼˜åŸºçº¿æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.23793v1">Transformer Tafsir at QIAS 2025 Shared Task: Hybrid Retrieval-Augmented Generation for Islamic Knowledge Question Answering</a></td><td><details><summary>å±•å¼€</summary>This paper presents our submission to the QIAS 2025 shared task on Islamic
knowledge understanding and reasoning. We developed a hybrid
retrieval-augmented generation (RAG) system that combines sparse and dense
retrieval methods with cross-encoder reranking to improve large language model
(LLM) performance. Our three-stage pipeline incorporates BM25 for initial
retrieval, a dense embedding retrieval model for semantic matching, and
cross-encoder reranking for precise content retrieval. We evaluate our approach
on both subtasks using two LLMs, Fanar and Mistral, demonstrating that the
proposed RAG pipeline enhances performance across both, with accuracy
improvements up to 25%, depending on the task and model configuration. Our best
configuration is achieved with Fanar, yielding accuracy scores of 45% in
Subtask 1 and 80% in Subtask 2.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªç”¨äºä¼Šæ–¯å…°çŸ¥è¯†ç†è§£å’Œæ¨ç†çš„æ··åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿï¼Œç»“åˆäº†ç¨€ç–ä¸å¯†é›†æ£€ç´¢æ–¹æ³•åŠäº¤å‰ç¼–ç å™¨é‡æ’åºï¼Œé€šè¿‡ä¸‰é˜¶æ®µæµç¨‹ï¼ˆBM25åˆæ£€ã€å¯†é›†åµŒå…¥è¯­ä¹‰åŒ¹é…ã€äº¤å‰ç¼–ç å™¨ç²¾æ£€ï¼‰æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆFanarå’ŒMistralï¼‰æ€§èƒ½ï¼Œå®éªŒæ˜¾ç¤ºæœ€é«˜å¯å°†å‡†ç¡®ç‡æå‡25%ï¼Œå…¶ä¸­Fanaræ¨¡å‹åœ¨ä¸¤é¡¹å­ä»»åŠ¡ä¸­åˆ†åˆ«è¾¾åˆ°45%å’Œ80%çš„å‡†ç¡®ç‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.23659v1">Aligning LLMs for Multilingual Consistency in Enterprise Applications</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) remain unreliable for global enterprise
applications due to substantial performance gaps between high-resource and
mid/low-resource languages, driven by English-centric pretraining and internal
reasoning biases. This inconsistency undermines customer experience and
operational reliability in multilingual settings such as customer support,
content moderation, and information retrieval. Even with advanced
Retrieval-Augmented Generation (RAG) systems, we observe up to an 29% accuracy
drop in non-English languages compared to English.
  We propose a practical, batch-wise alignment strategy for fine-tuning LLMs,
leveraging semantically equivalent multilingual data in each training batch to
directly align model outputs across languages. This approach improves
non-English accuracy by up to 23.9\% without compromising English performance,
model reasoning, or retrieval quality. Our method is simple to implement,
scalable, and integrates seamlessly with existing LLM training \& deployment
pipelines, enabling more robust and equitable multilingual AI solutions in
industry.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹ï¼ˆå°¤å…¶æ˜¯ä¸­ä½èµ„æºè¯­è¨€ï¼‰æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼ŒæŒ‡å‡ºå³ä½¿é‡‡ç”¨RAGç³»ç»Ÿï¼Œéè‹±è¯­è¯­è¨€çš„å‡†ç¡®ç‡ä»æ˜¾è‘—ä½äºè‹±è¯­ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºæ‰¹é‡å¯¹é½çš„å¾®è°ƒç­–ç•¥ï¼Œåˆ©ç”¨å¤šè¯­è¨€è¯­ä¹‰ç­‰æ•ˆæ•°æ®ç›´æ¥å¯¹é½æ¨¡å‹è¾“å‡ºï¼Œä»è€Œæå‡éè‹±è¯­è¯­è¨€çš„å‡†ç¡®ç‡ï¼ˆæœ€é«˜23.9%ï¼‰ï¼ŒåŒæ—¶ä¸å½±å“è‹±è¯­æ€§èƒ½æˆ–æ£€ç´¢è´¨é‡ã€‚ç ”ç©¶æ—¨åœ¨å¢å¼ºRAGåœ¨å¤šè¯­è¨€å·¥ä¸šåœºæ™¯ï¼ˆå¦‚å®¢æœã€å†…å®¹å®¡æ ¸ç­‰ï¼‰ä¸­çš„å…¬å¹³æ€§å’Œå¯é æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.23630v1">Game-Oriented ASR Error Correction via RAG-Enhanced LLM</a></td><td><details><summary>å±•å¼€</summary>With the rise of multiplayer online games, real-time voice communication is
essential for team coordination. However, general ASR systems struggle with
gaming-specific challenges like short phrases, rapid speech, jargon, and noise,
leading to frequent errors. To address this, we propose the GO-AEC framework,
which integrates large language models, Retrieval-Augmented Generation (RAG),
and a data augmentation strategy using LLMs and TTS. GO-AEC includes data
augmentation, N-best hypothesis-based correction, and a dynamic game knowledge
base. Experiments show GO-AEC reduces character error rate by 6.22% and
sentence error rate by 29.71%, significantly improving ASR accuracy in gaming
scenarios.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†GO-AECæ¡†æ¶ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä»¥åŠæ•°æ®å¢å¼ºç­–ç•¥ï¼Œé’ˆå¯¹æ¸¸æˆåœºæ™¯ä¸­çš„å®æ—¶è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æŒ‘æˆ˜ï¼ˆå¦‚çŸ­çŸ­è¯­ã€å¿«é€Ÿè¯­éŸ³ã€æœ¯è¯­å’Œå™ªå£°ï¼‰è¿›è¡Œä¼˜åŒ–ï¼Œé€šè¿‡åŠ¨æ€æ¸¸æˆçŸ¥è¯†åº“å’ŒN-bestå‡è®¾æ ¡æ­£æ˜¾è‘—é™ä½äº†é”™è¯¯ç‡ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-27
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.23519v1">ReliabilityRAG: Effective and Provably Robust Defense for RAG-based Web-Search</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) enhances Large Language Models by
grounding their outputs in external documents. These systems, however, remain
vulnerable to attacks on the retrieval corpus, such as prompt injection.
RAG-based search systems (e.g., Google's Search AI Overview) present an
interesting setting for studying and protecting against such threats, as
defense algorithms can benefit from built-in reliability signals -- like
document ranking -- and represent a non-LLM challenge for the adversary due to
decades of work to thwart SEO.
  Motivated by, but not limited to, this scenario, this work introduces
ReliabilityRAG, a framework for adversarial robustness that explicitly
leverages reliability information of retrieved documents.
  Our first contribution adopts a graph-theoretic perspective to identify a
"consistent majority" among retrieved documents to filter out malicious ones.
We introduce a novel algorithm based on finding a Maximum Independent Set (MIS)
on a document graph where edges encode contradiction. Our MIS variant
explicitly prioritizes higher-reliability documents and provides provable
robustness guarantees against bounded adversarial corruption under natural
assumptions. Recognizing the computational cost of exact MIS for large
retrieval sets, our second contribution is a scalable weighted sample and
aggregate framework. It explicitly utilizes reliability information, preserving
some robustness guarantees while efficiently handling many documents.
  We present empirical results showing ReliabilityRAG provides superior
robustness against adversarial attacks compared to prior methods, maintains
high benign accuracy, and excels in long-form generation tasks where prior
robustness-focused methods struggled. Our work is a significant step towards
more effective, provably robust defenses against retrieved corpus corruption in
RAG.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« æå‡ºäº†ReliabilityRAGæ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºRAGç³»ç»Ÿå¯¹æŠ—æ£€ç´¢æ–‡æ¡£åº“ä¸­æ¶æ„æ”»å‡»ï¼ˆå¦‚æç¤ºæ³¨å…¥ï¼‰çš„é²æ£’æ€§ã€‚é€šè¿‡å›¾è®ºæ–¹æ³•è¯†åˆ«æ–‡æ¡£é—´çš„çŸ›ç›¾å…³ç³»å¹¶ä¼˜å…ˆé€‰æ‹©é«˜å¯é æ€§æ–‡æ¡£ï¼Œç»“åˆå¯æ‰©å±•çš„åŠ æƒé‡‡æ ·èšåˆæŠ€æœ¯ï¼Œè¯¥æ¡†æ¶åœ¨ä¿è¯é«˜æ•ˆå¤„ç†å¤§è§„æ¨¡æ£€ç´¢é›†çš„åŒæ—¶ï¼Œæä¾›äº†ç†è®ºä¸Šçš„å¯¹æŠ—æ”»å‡»é˜²å¾¡ä¿è¯ï¼Œå¹¶åœ¨å®éªŒä¸­å±•ç°å‡ºä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.23233v1">Detecting Corpus-Level Knowledge Inconsistencies in Wikipedia with Large Language Models</a></td><td><details><summary>å±•å¼€</summary>Wikipedia is the largest open knowledge corpus, widely used worldwide and
serving as a key resource for training large language models (LLMs) and
retrieval-augmented generation (RAG) systems. Ensuring its accuracy is
therefore critical. But how accurate is Wikipedia, and how can we improve it?
  We focus on inconsistencies, a specific type of factual inaccuracy, and
introduce the task of corpus-level inconsistency detection. We present CLAIRE,
an agentic system that combines LLM reasoning with retrieval to surface
potentially inconsistent claims along with contextual evidence for human
review. In a user study with experienced Wikipedia editors, 87.5% reported
higher confidence when using CLAIRE, and participants identified 64.7% more
inconsistencies in the same amount of time.
  Combining CLAIRE with human annotation, we contribute WIKICOLLIDE, the first
benchmark of real Wikipedia inconsistencies. Using random sampling with
CLAIRE-assisted analysis, we find that at least 3.3% of English Wikipedia facts
contradict another fact, with inconsistencies propagating into 7.3% of FEVEROUS
and 4.0% of AmbigQA examples. Benchmarking strong baselines on this dataset
reveals substantial headroom: the best fully automated system achieves an AUROC
of only 75.1%.
  Our results show that contradictions are a measurable component of Wikipedia
and that LLM-based systems like CLAIRE can provide a practical tool to help
editors improve knowledge consistency at scale.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡èšç„¦äºç»´åŸºç™¾ç§‘ä¸­çš„äº‹å®ä¸ä¸€è‡´æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸æ£€ç´¢æŠ€æœ¯çš„æ™ºèƒ½ç³»ç»ŸCLAIREï¼Œç”¨äºæ£€æµ‹è¯­æ–™åº“çº§åˆ«çš„ä¸ä¸€è‡´ä¸»å¼ å¹¶æä¾›ä¸Šä¸‹æ–‡è¯æ®ï¼Œæœ€ç»ˆæ„å»ºäº†é¦–ä¸ªçœŸå®ç»´åŸºç™¾ç§‘ä¸ä¸€è‡´æ€§åŸºå‡†WIKICOLLIDEã€‚ç ”ç©¶è¯å®LLMé©±åŠ¨çš„ç³»ç»Ÿï¼ˆå¦‚CLAIREï¼‰å¯è¾…åŠ©ç¼–è¾‘é«˜æ•ˆæå‡çŸ¥è¯†ä¸€è‡´æ€§ï¼ŒåŒæ—¶æ­ç¤ºäº†æ­¤ç±»ä¸ä¸€è‡´åœ¨ç°æœ‰æ•°æ®é›†ï¼ˆå¦‚FEVEROUSã€AmbigQAï¼‰ä¸­çš„æ¸—é€æƒ…å†µï¼Œå‡¸æ˜¾äº†è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„æ”¹è¿›ç©ºé—´ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.23071v1">From Evidence to Trajectory: Abductive Reasoning Path Synthesis for Training Retrieval-Augmented Generation Agents</a></td><td><details><summary>å±•å¼€</summary>Retrieval-augmented generation agents development is hindered by the lack of
process-level supervision to effectively guide agentic capabilities like task
decomposition, retriever invocation, and stepwise decision-making. While
reinforcement learning offers a potential solution, it suffers from sparse
rewards and the limited reasoning capabilities of large language models (LLMs).
Meanwhile, existing data synthesis methods only produce chain-of-thought
rationales and fail to model environmental interactions. In this paper, we
propose EviPath, an evidence-anchored reasoning path synthesis paradigm for RAG
agent development. EviPath comprises: (i) Abductive Subtask Planning, which
decomposes the problem into sub-questions and iteratively plans an optimal
solution path based on the dependencies between them; (ii) Faithful
Sub-question Answering, which uses supporting evidence to construct a proxy
environment to generate reasoning thoughts and answers for each sub-question;
and (iii) Conversational Fine-Tuning, which formats the complete
agent-environment interaction trajectory into a dialogue format suitable for
Supervised Fine-Tuning. EviPath allows LLMs to learn complex reasoning and
tool-use capabilities directly from synthesized data. Extensive experiments on
widely-used question-answering benchmarks show that an 8B parameter model
trained with EviPath-synthesized data significantly and consistently
outperforms state-of-the-art baselines with a double-digit absolute EM gain of
14.7% in open-domain question answering.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºEviPathçš„è¯æ®é”šå®šæ¨ç†è·¯å¾„åˆæˆèŒƒå¼ï¼Œç”¨äºè§£å†³RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ä»£ç†å¼€å‘ä¸­è¿‡ç¨‹çº§ç›‘ç£ä¸è¶³çš„é—®é¢˜ã€‚é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºå­ä»»åŠ¡ã€åˆ©ç”¨æ”¯æŒè¯æ®æ„å»ºä»£ç†ç¯å¢ƒç”Ÿæˆå­é—®é¢˜ç­”æ¡ˆï¼Œå¹¶å°†äº¤äº’è½¨è¿¹æ ¼å¼åŒ–ä¸ºå¯¹è¯æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒï¼ŒEviPathæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¼€æ”¾åŸŸé—®ç­”ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼ˆEMå¢ç›Šè¾¾14.7%ï¼‰ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-26
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.22565v1">Retrieval-Augmented Guardrails for AI-Drafted Patient-Portal Messages: Error Taxonomy Construction and Large-Scale Evaluation</a></td><td><details><summary>å±•å¼€</summary>Asynchronous patient-clinician messaging via EHR portals is a growing source
of clinician workload, prompting interest in large language models (LLMs) to
assist with draft responses. However, LLM outputs may contain clinical
inaccuracies, omissions, or tone mismatches, making robust evaluation
essential. Our contributions are threefold: (1) we introduce a clinically
grounded error ontology comprising 5 domains and 59 granular error codes,
developed through inductive coding and expert adjudication; (2) we develop a
retrieval-augmented evaluation pipeline (RAEC) that leverages semantically
similar historical message-response pairs to improve judgment quality; and (3)
we provide a two-stage prompting architecture using DSPy to enable scalable,
interpretable, and hierarchical error detection. Our approach assesses the
quality of drafts both in isolation and with reference to similar past
message-response pairs retrieved from institutional archives. Using a two-stage
DSPy pipeline, we compared baseline and reference-enhanced evaluations on over
1,500 patient messages. Retrieval context improved error identification in
domains such as clinical completeness and workflow appropriateness. Human
validation on 100 messages demonstrated superior agreement (concordance = 50%
vs. 33%) and performance (F1 = 0.500 vs. 0.256) of context-enhanced labels vs.
baseline, supporting the use of our RAEC pipeline as AI guardrails for patient
messaging.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ£€ç´¢å¢å¼ºçš„è¯„ä¼°ç®¡é“ï¼ˆRAECï¼‰ï¼Œåˆ©ç”¨è¯­ä¹‰ç›¸ä¼¼çš„å†å²æ¶ˆæ¯-å“åº”å¯¹æ¥æ”¹è¿›å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„ä¸´åºŠå›å¤è‰æ¡ˆçš„è´¨é‡è¯„ä¼°ï¼Œå¹¶é€šè¿‡ä¸¤é˜¶æ®µæç¤ºæ¶æ„å®ç°å¯æ‰©å±•å’Œåˆ†å±‚æ¬¡çš„é”™è¯¯æ£€æµ‹ï¼ŒéªŒè¯äº†æ£€ç´¢ä¸Šä¸‹æ–‡åœ¨æå‡ä¸´åºŠå®Œæ•´æ€§å’Œå·¥ä½œæµé€‚å½“æ€§ç­‰é¢†åŸŸçš„é”™è¯¯è¯†åˆ«æ•ˆæœã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.22516v1">TrueGradeAI: Retrieval-Augmented and Bias-Resistant AI for Transparent and Explainable Digital Assessments</a></td><td><details><summary>å±•å¼€</summary>This paper introduces TrueGradeAI, an AI-driven digital examination framework
designed to overcome the shortcomings of traditional paper-based assessments,
including excessive paper usage, logistical complexity, grading delays, and
evaluator bias. The system preserves natural handwriting by capturing stylus
input on secure tablets and applying transformer-based optical character
recognition for transcription. Evaluation is conducted through a
retrieval-augmented pipeline that integrates faculty solutions, cache layers,
and external references, enabling a large language model to assign scores with
explicit, evidence-linked reasoning. Unlike prior tablet-based exam systems
that primarily digitize responses, TrueGradeAI advances the field by
incorporating explainable automation, bias mitigation, and auditable grading
trails. By uniting handwriting preservation with scalable and transparent
evaluation, the framework reduces environmental costs, accelerates feedback
cycles, and progressively builds a reusable knowledge base, while actively
working to mitigate grading bias and ensure fairness in assessment.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºTrueGradeAIæ¡†æ¶ï¼Œé€šè¿‡åŸºäºè§¦æ§ç¬”è¾“å…¥çš„æ•°å­—åŒ–è€ƒè¯•ç³»ç»Ÿç»“åˆæ£€ç´¢å¢å¼ºæµç¨‹ï¼ˆé›†æˆæ•™å¸ˆç­”æ¡ˆã€ç¼“å­˜å±‚å’Œå¤–éƒ¨å‚è€ƒï¼‰ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå¯è§£é‡Šã€è¯æ®å…³è”çš„è¯„åˆ†ï¼Œè§£å†³ä¼ ç»Ÿè€ƒè¯•å¼Šç«¯å¹¶æå‡é€æ˜åº¦å’Œå…¬å¹³æ€§ï¼Œå±äºRAGåœ¨è‡ªåŠ¨åŒ–è¯„ä¼°é¢†åŸŸçš„åº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.22490v1">JGU Mainz's Submission to the WMT25 Shared Task on LLMs with Limited Resources for Slavic Languages: MT and QA</a></td><td><details><summary>å±•å¼€</summary>This paper presents the JGU Mainz submission to the WMT25 Shared Task on LLMs
with Limited Resources for Slavic Languages: Machine Translation and Question
Answering, focusing on Ukrainian, Upper Sorbian, and Lower Sorbian. For each
language, we jointly fine-tune a Qwen2.5-3B-Instruct model for both tasks with
parameter-efficient finetuning. Our pipeline integrates additional translation
and multiple-choice question answering (QA) data. For Ukrainian QA, we further
use retrieval-augmented generation. We also apply ensembling for QA in Upper
and Lower Sorbian. Experiments show that our models outperform the baseline on
both tasks.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡ä»‹ç»äº†JGU Mainzå›¢é˜Ÿé’ˆå¯¹ä½èµ„æºæ–¯æ‹‰å¤«è¯­ï¼ˆä¹Œå…‹å…°è¯­ã€ä¸Šç´¢å¸ƒè¯­å’Œä¸‹ç´¢å¸ƒè¯­ï¼‰çš„æœºå™¨ç¿»è¯‘å’Œé—®ç­”ä»»åŠ¡ï¼Œä½¿ç”¨Qwen2.5-3B-Instructæ¨¡å‹è¿›è¡Œè”åˆå¾®è°ƒï¼Œå¹¶åœ¨ä¹Œå…‹å…°è¯­é—®ç­”ä¸­é‡‡ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ï¼Œå®éªŒè¡¨æ˜æ¨¡å‹æ€§èƒ½ä¼˜äºåŸºçº¿ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.22486v1">Your RAG is Unfair: Exposing Fairness Vulnerabilities in Retrieval-Augmented Generation via Backdoor Attacks</a></td><td><details><summary>å±•å¼€</summary>Retrieval-augmented generation (RAG) enhances factual grounding by
integrating retrieval mechanisms with generative models but introduces new
attack surfaces, particularly through backdoor attacks. While prior research
has largely focused on disinformation threats, fairness vulnerabilities remain
underexplored. Unlike conventional backdoors that rely on direct
trigger-to-target mappings, fairness-driven attacks exploit the interaction
between retrieval and generation models, manipulating semantic relationships
between target groups and social biases to establish a persistent and covert
influence on content generation.
  This paper introduces BiasRAG, a systematic framework that exposes fairness
vulnerabilities in RAG through a two-phase backdoor attack. During the
pre-training phase, the query encoder is compromised to align the target group
with the intended social bias, ensuring long-term persistence. In the
post-deployment phase, adversarial documents are injected into knowledge bases
to reinforce the backdoor, subtly influencing retrieved content while remaining
undetectable under standard fairness evaluations. Together, BiasRAG ensures
precise target alignment over sensitive attributes, stealthy execution, and
resilience. Empirical evaluations demonstrate that BiasRAG achieves high attack
success rates while preserving contextual relevance and utility, establishing a
persistent and evolving threat to fairness in RAG.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†RAGæŠ€æœ¯åœ¨å…¬å¹³æ€§æ–¹é¢çš„æ½œåœ¨æ¼æ´ï¼Œæå‡ºäº†ä¸€ç§åä¸ºBiasRAGçš„ä¸¤é˜¶æ®µåé—¨æ”»å‡»æ¡†æ¶ã€‚è¯¥æ”»å‡»é€šè¿‡åœ¨é¢„è®­ç»ƒé˜¶æ®µæ“çºµæŸ¥è¯¢ç¼–ç å™¨ä½¿å…¶ä¸ç‰¹å®šç¤¾ä¼šåè§å¯¹é½ï¼Œå¹¶åœ¨éƒ¨ç½²åé˜¶æ®µå‘çŸ¥è¯†åº“æ³¨å…¥å¯¹æŠ—æ€§æ–‡æ¡£ï¼Œä»è€Œåœ¨ä¿æŒéšè”½æ€§çš„åŒæ—¶æŒç»­å½±å“ç”Ÿæˆå†…å®¹ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒBiasRAGä¸ä»…èƒ½é«˜æ•ˆå®æ–½æ”»å‡»ï¼Œè¿˜æ­ç¤ºäº†ç°æœ‰å…¬å¹³æ€§è¯„ä¼°çš„å±€é™æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.22378v1">Zero-Effort Image-to-Music Generation: An Interpretable RAG-based VLM Approach</a></td><td><details><summary>å±•å¼€</summary>Recently, Image-to-Music (I2M) generation has garnered significant attention,
with potential applications in fields such as gaming, advertising, and
multi-modal art creation. However, due to the ambiguous and subjective nature
of I2M tasks, most end-to-end methods lack interpretability, leaving users
puzzled about the generation results. Even methods based on emotion mapping
face controversy, as emotion represents only a singular aspect of art.
Additionally, most learning-based methods require substantial computational
resources and large datasets for training, hindering accessibility for common
users. To address these challenges, we propose the first Vision Language Model
(VLM)-based I2M framework that offers high interpretability and low
computational cost. Specifically, we utilize ABC notation to bridge the text
and music modalities, enabling the VLM to generate music using natural
language. We then apply multi-modal Retrieval-Augmented Generation (RAG) and
self-refinement techniques to allow the VLM to produce high-quality music
without external training. Furthermore, we leverage the generated motivations
in text and the attention maps from the VLM to provide explanations for the
generated results in both text and image modalities. To validate our method, we
conduct both human studies and machine evaluations, where our method
outperforms others in terms of music quality and music-image consistency,
indicating promising results. Our code is available at
https://github.com/RS2002/Image2Music .</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ç§åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„Image-to-Musicï¼ˆI2Mï¼‰ç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œè‡ªä¼˜åŒ–æŠ€æœ¯ï¼Œæ— éœ€å¤–éƒ¨è®­ç»ƒå³å¯ç”Ÿæˆé«˜è´¨é‡éŸ³ä¹ï¼Œå¹¶åˆ©ç”¨æ–‡æœ¬åŠ¨æœºå’Œæ³¨æ„åŠ›å›¾æä¾›è·¨æ¨¡æ€è§£é‡Šï¼Œåœ¨éŸ³ä¹è´¨é‡ä¸å›¾æ–‡ä¸€è‡´æ€§ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.22325v1">Can Synthetic Query Rewrites Capture User Intent Better than Humans in Retrieval-Augmented Generation?</a></td><td><details><summary>å±•å¼€</summary>Multi-turn RAG systems often face queries with colloquial omissions and
ambiguous references, posing significant challenges for effective retrieval and
generation. Traditional query rewriting relies on human annotators to clarify
queries, but due to limitations in annotators' expressive ability and depth of
understanding, manually rewritten queries often diverge from those needed in
real-world RAG systems, resulting in a gap between user intent and system
response. We observe that high-quality synthetic queries can better bridge this
gap, achieving superior performance in both retrieval and generation compared
to human rewrites. This raises an interesting question: Can rewriting models
trained on synthetic queries better capture user intent than human annotators?
In this paper, we propose SynRewrite, a synthetic data-driven query rewriting
model to generate high-quality synthetic rewrites more aligned with user
intent. To construct training data, we prompt GPT-4o with dialogue history,
current queries, positive documents, and answers to synthesize high-quality
rewrites. A Flan-T5 model is then finetuned on this dataset to map dialogue
history and queries to synthetic rewrites. Finally, we further enhance the
rewriter using the generator's feedback through the DPO algorithm to boost
end-task performance. Experiments on TopiOCQA and QRECC datasets show that
SynRewrite consistently outperforms human rewrites in both retrieval and
generation tasks. Our results demonstrate that synthetic rewrites can serve as
a scalable and effective alternative to human annotations.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†å¤šè½®RAGç³»ç»Ÿä¸­é¢å¯¹å£è¯­åŒ–çœç•¥å’Œæ¨¡ç³ŠæŒ‡ä»£æŸ¥è¯¢æ—¶çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåˆæˆæ•°æ®çš„æŸ¥è¯¢é‡å†™æ¨¡å‹SynRewriteã€‚è¯¥æ–¹æ³•åˆ©ç”¨GPT-4oç”Ÿæˆé«˜è´¨é‡çš„é‡å†™æŸ¥è¯¢è®­ç»ƒæ•°æ®ï¼Œå¹¶å¾®è°ƒFlan-T5æ¨¡å‹ï¼Œå†é€šè¿‡DPOç®—æ³•ç»“åˆç”Ÿæˆå™¨åé¦ˆä¼˜åŒ–æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒSynRewriteåœ¨æ£€ç´¢å’Œç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºäººå·¥é‡å†™ï¼Œè¯æ˜åˆæˆæ•°æ®èƒ½æœ‰æ•ˆæ›¿ä»£äººå·¥æ ‡æ³¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.22009v1">GraphSearch: An Agentic Deep Searching Workflow for Graph Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>Graph Retrieval-Augmented Generation (GraphRAG) enhances factual reasoning in
LLMs by structurally modeling knowledge through graph-based representations.
However, existing GraphRAG approaches face two core limitations: shallow
retrieval that fails to surface all critical evidence, and inefficient
utilization of pre-constructed structural graph data, which hinders effective
reasoning from complex queries. To address these challenges, we propose
\textsc{GraphSearch}, a novel agentic deep searching workflow with dual-channel
retrieval for GraphRAG. \textsc{GraphSearch} organizes the retrieval process
into a modular framework comprising six modules, enabling multi-turn
interactions and iterative reasoning. Furthermore, \textsc{GraphSearch} adopts
a dual-channel retrieval strategy that issues semantic queries over chunk-based
text data and relational queries over structural graph data, enabling
comprehensive utilization of both modalities and their complementary strengths.
Experimental results across six multi-hop RAG benchmarks demonstrate that
\textsc{GraphSearch} consistently improves answer accuracy and generation
quality over the traditional strategy, confirming \textsc{GraphSearch} as a
promising direction for advancing graph retrieval-augmented generation.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºGraphSearchçš„æ–°å‹å›¾æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆGraphRAGï¼‰æ–¹æ³•ï¼Œé€šè¿‡åŒé€šé“æ£€ç´¢ç­–ç•¥ï¼ˆè¯­ä¹‰æŸ¥è¯¢å’Œå…³ç³»æŸ¥è¯¢ï¼‰åŠæ¨¡å—åŒ–å·¥ä½œæµè§£å†³äº†ä¼ ç»ŸGraphRAGæ–¹æ³•ä¸­æ£€ç´¢æµ…å±‚åŒ–å’Œå›¾æ•°æ®åˆ©ç”¨æ•ˆç‡ä½çš„é—®é¢˜ï¼Œå®éªŒè¯æ˜å…¶åœ¨å¤šè·³RAGåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†ç­”æ¡ˆå‡†ç¡®æ€§å’Œç”Ÿæˆè´¨é‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21875v1">LUMINA: Detecting Hallucinations in RAG System with Context-Knowledge Signals</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) aims to mitigate hallucinations in large
language models (LLMs) by grounding responses in retrieved documents. Yet,
RAG-based LLMs still hallucinate even when provided with correct and sufficient
context. A growing line of work suggests that this stems from an imbalance
between how models use external context and their internal knowledge, and
several approaches have attempted to quantify these signals for hallucination
detection. However, existing methods require extensive hyperparameter tuning,
limiting their generalizability. We propose LUMINA, a novel framework that
detects hallucinations in RAG systems through context-knowledge signals:
external context utilization is quantified via distributional distance, while
internal knowledge utilization is measured by tracking how predicted tokens
evolve across transformer layers. We further introduce a framework for
statistically validating these measurements. Experiments on common RAG
hallucination benchmarks and four open-source LLMs show that LUMINA achieves
consistently high AUROC and AUPRC scores, outperforming prior utilization-based
methods by up to +13% AUROC on HalluRAG. Moreover, LUMINA remains robust under
relaxed assumptions about retrieval quality and model matching, offering both
effectiveness and practicality.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†LUMINAæ¡†æ¶ï¼Œä¸“é—¨ç”¨äºæ£€æµ‹RAGç³»ç»Ÿä¸­å› ä¸Šä¸‹æ–‡ä¸å†…éƒ¨çŸ¥è¯†åˆ©ç”¨ä¸å¹³è¡¡å¯¼è‡´çš„å¹»è§‰é—®é¢˜ã€‚é€šè¿‡é‡åŒ–å¤–éƒ¨ä¸Šä¸‹æ–‡åˆ†å¸ƒè·ç¦»å’Œå†…éƒ¨çŸ¥è¯†åœ¨Transformerå±‚ä¸­çš„æ¼”åŒ–ï¼Œç»“åˆç»Ÿè®¡éªŒè¯æ–¹æ³•ï¼ŒLUMINAåœ¨å¤šä¸ªRAGåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ˆå¦‚AUROCæå‡13%ï¼‰ï¼Œä¸”å¯¹æ£€ç´¢è´¨é‡å’Œæ¨¡å‹é€‚é…å…·æœ‰æ›´å¼ºé²æ£’æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21865v1">Beyond RAG vs. Long-Context: Learning Distraction-Aware Retrieval for Efficient Knowledge Grounding</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) is a framework for grounding Large
Language Models (LLMs) in external, up-to-date information. However, recent
advancements in context window size allow LLMs to process inputs of up to 128K
tokens or more, offering an alternative strategy: supplying the full document
context directly to the model, rather than relying on RAG to retrieve a subset
of contexts. Nevertheless, this emerging alternative strategy has notable
limitations: (i) it is token-inefficient to handle large and potentially
redundant contexts; (ii) it exacerbates the `lost in the middle' phenomenon;
and (iii) under limited model capacity, it amplifies distraction, ultimately
degrading LLM output quality. In this paper, we propose LDAR (Learning
Distraction-Aware Retrieval), an adaptive retriever that learns to retrieve
contexts in a way that mitigates interference from distracting passages,
thereby achieving significantly higher performance with reduced token usage
compared to long-context approaches. Extensive experiments across diverse LLM
architectures and six knowledge-intensive benchmarks demonstrate the
effectiveness and robustness of our approach, highlighting the importance of
balancing the trade-off between information coverage and distraction.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸Šä¸‹æ–‡çª—å£å¢å¤§çš„èƒŒæ™¯ä¸‹ï¼ŒRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰é¢ä¸´çš„æŒ‘æˆ˜ä¸æ”¹è¿›æ–¹æ³•ï¼Œæå‡ºäº†LDARï¼ˆLearning Distraction-Aware Retrievalï¼‰ç®—æ³•ï¼Œé€šè¿‡è‡ªé€‚åº”æ£€ç´¢å‡å°‘å¹²æ‰°æ€§æ®µè½çš„å½±å“ï¼Œä»¥æé«˜æ€§èƒ½å¹¶é™ä½tokenä½¿ç”¨é‡ï¼Œè¯æ˜äº†åœ¨ä¿¡æ¯è¦†ç›–ä¸å¹²æ‰°é—´å¹³è¡¡çš„é‡è¦æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21856v1">KnowMT-Bench: Benchmarking Knowledge-Intensive Long-Form Question Answering in Multi-Turn Dialogues</a></td><td><details><summary>å±•å¼€</summary>Multi-Turn Long-Form Question Answering (MT-LFQA) is a key application
paradigm of Large Language Models (LLMs) in knowledge-intensive domains.
However, existing benchmarks are limited to single-turn dialogue, while
multi-turn dialogue benchmarks typically assess other orthogonal capabilities
rather than knowledge-intensive factuality. To bridge this critical gap, we
introduce \textbf{KnowMT-Bench}, the \textit{first-ever} benchmark designed to
systematically evaluate MT-LFQA for LLMs across knowledge-intensive fields,
including medicine, finance, and law. To faithfully assess the model's
real-world performance, KnowMT-Bench employs a dynamic evaluation setting where
models generate their own multi-turn dialogue histories given logically
progressive question sequences. The factual capability and information delivery
efficiency of the \textit{final-turn} answer are then evaluated using a
human-validated automated pipeline. Our experiments reveal that multi-turn
contexts degrade performance: factual capability declines due to the contextual
noise from self-generated histories, while information efficiency drops as
models become more verbose with increasing dialogue length. We then investigate
mitigation strategies, demonstrating that retrieval-augmented generation (RAG)
can effectively alleviate and even reverse this factual degradation. These
findings underscore the importance of our benchmark in evaluating and enhancing
the conversational factual capabilities of LLMs in real-world
knowledge-intensive applications. Code is available at
\href{https://github.com/hardenyu21/KnowMT-Bench}{\textcolor{cyan}{\texttt{KnowMT-Bench}}}.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« ä»‹ç»äº†KnowMT-Benchï¼Œé¦–ä¸ªç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šè½®é•¿å½¢å¼é—®ç­”ï¼ˆMT-LFQAï¼‰ä¸­çŸ¥è¯†å¯†é›†å‹é¢†åŸŸæ€§èƒ½çš„åŸºå‡†æµ‹è¯•ï¼Œç ”ç©¶å‘ç°å¤šè½®å¯¹è¯ä¼šé™ä½æ¨¡å‹çš„äº‹å®æ€§è¡¨ç°ï¼Œä½†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰èƒ½æœ‰æ•ˆç¼“è§£è¿™ä¸€é€€åŒ–ï¼Œå¼ºè°ƒäº†RAGåœ¨æå‡æ¨¡å‹å¯¹è¯äº‹å®æ€§èƒ½åŠ›ä¸­çš„é‡è¦æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21848v1">Graph of Agents: Principled Long Context Modeling by Emergent Multi-Agent Collaboration</a></td><td><details><summary>å±•å¼€</summary>As a model-agnostic approach to long context modeling, multi-agent systems
can process inputs longer than a large language model's context window without
retraining or architectural modifications. However, their performance often
heavily relies on hand-crafted multi-agent collaboration strategies and prompt
engineering, which limit generalizability. In this work, we introduce a
principled framework that formalizes the model-agnostic long context modeling
problem as a compression problem, yielding an information-theoretic compression
objective. Building on this framework, we propose Graph of Agents (GoA), which
dynamically constructs an input-dependent collaboration structure that
maximizes this objective. For Llama 3.1 8B and Qwen3 8B across six document
question answering benchmarks, GoA improves the average $F_1$ score of
retrieval-augmented generation by 5.7\% and a strong multi-agent baseline using
a fixed collaboration structure by 16.35\%, respectively. Even with only a 2K
context window, GoA surpasses the 128K context window Llama 3.1 8B on
LongBench, showing a dramatic increase in effective context length. Our source
code is available at https://github.com/tjoo512/graph-of-agents.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º"Graph of Agents (GoA)"çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡å°†é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡é—®é¢˜å½¢å¼åŒ–ä¸ºå‹ç¼©é—®é¢˜ï¼Œå¹¶åŠ¨æ€æ„å»ºè¾“å…¥ç›¸å…³çš„åä½œç»“æ„æ¥ä¼˜åŒ–æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒGoAåœ¨å…­ä¸ªæ–‡æ¡£é—®ç­”åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†RAGçš„F1åˆ†æ•°ï¼ˆ5.7%ï¼‰å’Œå¤šæ™ºèƒ½ä½“åŸºçº¿æ€§èƒ½ï¼ˆ16.35%ï¼‰ï¼Œä¸”åœ¨ä»…æœ‰2Kä¸Šä¸‹æ–‡çª—å£æ—¶è¶…è¶Š128Kçª—å£çš„Llama 3.1æ¨¡å‹ï¼Œå¤§å¹…æå‡äº†æœ‰æ•ˆä¸Šä¸‹æ–‡é•¿åº¦ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21730v1">ProPerSim: Developing Proactive and Personalized AI Assistants through User-Assistant Simulation</a></td><td><details><summary>å±•å¼€</summary>As large language models (LLMs) become increasingly integrated into daily
life, there is growing demand for AI assistants that are not only reactive but
also proactive and personalized. While recent advances have pushed forward
proactivity and personalization individually, their combination remains
underexplored. To bridge this gap, we introduce ProPerSim, a new task and
simulation framework for developing assistants capable of making timely,
personalized recommendations in realistic home scenarios. In our simulation
environment, a user agent with a rich persona interacts with the assistant,
providing ratings on how well each suggestion aligns with its preferences and
context. The assistant's goal is to use these ratings to learn and adapt to
achieve higher scores over time. Built on ProPerSim, we propose
ProPerAssistant, a retrieval-augmented, preference-aligned assistant that
continually learns and adapts through user feedback. Experiments across 32
diverse personas show that ProPerAssistant adapts its strategy and steadily
improves user satisfaction, highlighting the promise of uniting proactivity and
personalization.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºProPerSimçš„ä»»åŠ¡å’Œä»¿çœŸæ¡†æ¶ï¼Œæ—¨åœ¨å¼€å‘èƒ½å¤Ÿåœ¨ç°å®å®¶åº­åœºæ™¯ä¸­æä¾›ä¸»åŠ¨ä¸”ä¸ªæ€§åŒ–æ¨èçš„AIåŠ©æ‰‹ã€‚è®ºæ–‡ä»‹ç»äº†ProPerAssistantï¼Œä¸€ç§åŸºäºæ£€ç´¢å¢å¼ºï¼ˆretrieval-augmentedï¼‰ã€åå¥½å¯¹é½çš„åŠ©æ‰‹ï¼Œé€šè¿‡ç”¨æˆ·åé¦ˆæŒç»­å­¦ä¹ å’Œé€‚åº”ï¼Œå®éªŒç»“æœè¡¨æ˜å…¶åœ¨32ç§ä¸åŒç”¨æˆ·è§’è‰²ä¸­èƒ½é€æ­¥æå‡ç”¨æˆ·æ»¡æ„åº¦ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21710v1">Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) and Graph-based RAG has become the
important paradigm for enhancing Large Language Models (LLMs) with external
knowledge. However, existing approaches face a fundamental trade-off. While
graph-based methods are inherently dependent on high-quality graph structures,
they face significant practical constraints: manually constructed knowledge
graphs are prohibitively expensive to scale, while automatically extracted
graphs from corpora are limited by the performance of the underlying LLM
extractors, especially when using smaller, local-deployed models. This paper
presents Think-on-Graph 3.0 (ToG-3), a novel framework that introduces
Multi-Agent Context Evolution and Retrieval (MACER) mechanism to overcome these
limitations. Our core innovation is the dynamic construction and refinement of
a Chunk-Triplets-Community heterogeneous graph index, which pioneeringly
incorporates a dual-evolution mechanism of Evolving Query and Evolving
Sub-Graph for precise evidence retrieval. This approach addresses a critical
limitation of prior Graph-based RAG methods, which typically construct a static
graph index in a single pass without adapting to the actual query. A
multi-agent system, comprising Constructor, Retriever, Reflector, and Responser
agents, collaboratively engages in an iterative process of evidence retrieval,
answer generation, sufficiency reflection, and, crucially, evolving query and
subgraph. This dual-evolving multi-agent system allows ToG-3 to adaptively
build a targeted graph index during reasoning, mitigating the inherent
drawbacks of static, one-time graph construction and enabling deep, precise
reasoning even with lightweight LLMs. Extensive experiments demonstrate that
ToG-3 outperforms compared baselines on both deep and broad reasoning
benchmarks, and ablation studies confirm the efficacy of the components of
MACER framework.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºThink-on-Graph 3.0ï¼ˆToG-3ï¼‰çš„æ–°å‹RAGæ¡†æ¶ï¼Œé€šè¿‡åˆ›æ–°çš„å¤šä»£ç†ä¸Šä¸‹æ–‡æ¼”åŒ–ä¸æ£€ç´¢ï¼ˆMACERï¼‰æœºåˆ¶å’ŒåŠ¨æ€æ„å»ºçš„Chunk-Triplets-Communityå¼‚æ„å›¾ç´¢å¼•ï¼Œæ”¹è¿›äº†ä¼ ç»ŸåŸºäºå›¾çš„RAGæ–¹æ³•ä¸­é™æ€å›¾ç´¢å¼•çš„å±€é™æ€§ï¼Œå®ç°äº†æŸ¥è¯¢å’Œå­å›¾çš„åŒé‡æ¼”åŒ–ï¼Œä»è€Œåœ¨è½»é‡çº§å¤§è¯­è¨€æ¨¡å‹ä¸Šå®ç°äº†æ›´æ·±æ›´ç²¾å‡†çš„æ¨ç†ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-25
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.21237v1">Query-Centric Graph Retrieval Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†QCG-RAGæ¡†æ¶ï¼Œé€šè¿‡æ„å»ºæŸ¥è¯¢ä¸ºä¸­å¿ƒçš„å›¾ç»“æ„è§£å†³ç°æœ‰åŸºäºå›¾çš„RAGæ–¹æ³•ä¸­ç²’åº¦å›°å¢ƒï¼ˆç»†ç²’åº¦å¯¼è‡´é«˜å¼€é”€ï¼Œç²—ç²’åº¦ä¸¢å¤±ç»†èŠ‚å…³ç³»ï¼‰ï¼Œç»“åˆå¯æ§ç²’åº¦ç´¢å¼•å’Œå¤šè·³åˆ†å—æ£€ç´¢æœºåˆ¶ï¼Œåœ¨é—®ç­”ä»»åŠ¡ä¸­è¶…è¶Šä¼ ç»Ÿåˆ†å—å’Œå›¾åŸºæ–¹æ³•ï¼Œæå‡äº†å¤šè·³æ¨ç†æ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21208v1">CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis</a></td><td><details><summary>å±•å¼€</summary>Large Language Models (LLMs) are increasingly tasked with analyzing legal
texts and citing relevant statutes, yet their reliability is often compromised
by general pre-training that ingests legal texts without specialized focus,
obscuring the true depth of their legal knowledge. This paper introduces CLaw,
a novel benchmark specifically engineered to meticulously evaluate LLMs on
Chinese legal knowledge and its application in reasoning. CLaw comprises two
key components: (1) a comprehensive, fine-grained corpus of all 306 Chinese
national statutes, segmented to the subparagraph level and incorporating
precise historical revision timesteps for rigorous recall evaluation (64,849
entries), and (2) a challenging set of 254 case-based reasoning instances
derived from China Supreme Court curated materials to assess the practical
application of legal knowledge. Our empirical evaluation reveals that most
contemporary LLMs significantly struggle to faithfully reproduce legal
provisions. As accurate retrieval and citation of legal provisions form the
basis of legal reasoning, this deficiency critically undermines the reliability
of their responses. We contend that achieving trustworthy legal reasoning in
LLMs requires a robust synergy of accurate knowledge retrieval--potentially
enhanced through supervised fine-tuning (SFT) or retrieval-augmented generation
(RAG)--and strong general reasoning capabilities. This work provides an
essential benchmark and critical insights for advancing domain-specific LLM
reasoning, particularly within the complex legal sphere.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†CLawåŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸­å›½æ³•å¾‹çŸ¥è¯†åŠå…¶æ¨ç†åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œå‘ç°ç°æœ‰æ¨¡å‹åœ¨å‡†ç¡®æ£€ç´¢å’Œå¼•ç”¨æ³•å¾‹æ¡æ–‡æ–¹é¢å­˜åœ¨é‡å¤§ç¼ºé™·ï¼Œå¹¶æŒ‡å‡ºé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æˆ–æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­‰æŠ€æœ¯æ”¹è¿›çŸ¥è¯†æ£€ç´¢èƒ½åŠ›æ˜¯å®ç°å¯é æ³•å¾‹æ¨ç†çš„å…³é”®ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21193v1">Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) have recently shown strong progress on
scientific reasoning, yet two major bottlenecks remain. First, explicit
retrieval fragments reasoning, imposing a hidden "tool tax" of extra tokens and
steps. Second, multi-agent pipelines often dilute strong solutions by averaging
across all candidates. We address these challenges with a unified framework
that combines implicit retrieval and structured collaboration. At its
foundation, a Monitor-based retrieval module operates at the token level,
integrating external knowledge with minimal disruption to reasoning. On top of
this substrate, Hierarchical Solution Refinement (HSR) iteratively designates
each candidate as an anchor to be repaired by its peers, while Quality-Aware
Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanity's
Last Exam (HLE) Bio/Chem Gold, our framework achieves 48.3\% accuracy -- the
highest reported to date, surpassing the strongest agent baseline by 13.4
points and leading frontier LLMs by up to 18.1 points, while simultaneously
reducing token usage by 53.5\% and agent steps by 43.7\%. Results on SuperGPQA
and TRQA confirm robustness across domains. Error analysis shows that reasoning
failures and knowledge gaps co-occur in over 85\% of cases, while diversity
analysis reveals a clear dichotomy: retrieval tasks benefit from solution
variety, whereas reasoning tasks favor consensus. Together, these findings
demonstrate how implicit augmentation and structured refinement overcome the
inefficiencies of explicit tool use and uniform aggregation. Code is available
at: https://github.com/tangxiangru/Eigen-1.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆéšå¼æ£€ç´¢å’Œç»“æ„åŒ–åä½œçš„ç»Ÿä¸€æ¡†æ¶æ¥è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦æ¨ç†ä¸­çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡åŸºäºMonitorçš„æ£€ç´¢æ¨¡å—åœ¨tokençº§åˆ«é›†æˆå¤–éƒ¨çŸ¥è¯†ï¼Œå‡å°‘æ¨ç†ä¸­æ–­ï¼Œå¹¶é‡‡ç”¨åˆ†å±‚è§£å†³æ–¹æ¡ˆç²¾ç‚¼ï¼ˆHSRï¼‰å’Œè´¨é‡æ„ŸçŸ¥è¿­ä»£æ¨ç†ï¼ˆQAIRï¼‰æ¥ä¼˜åŒ–ç»“æœã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šé¡¹ä»»åŠ¡ä¸­å®ç°äº†æœ€é«˜å‡†ç¡®ç‡ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†tokenå’Œè®¡ç®—æ­¥éª¤çš„æ¶ˆè€—ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21188v1">Adoption, usability and perceived clinical value of a UK AI clinical reference platform (iatroX): a mixed-methods formative evaluation of real-world usage and a 1,223-respondent user survey</a></td><td><details><summary>å±•å¼€</summary>Clinicians face growing information overload from biomedical literature and
guidelines, hindering evidence-based care. Retrieval-augmented generation (RAG)
with large language models may provide fast, provenance-linked answers, but
requires real-world evaluation. We describe iatroX, a UK-centred RAG-based
clinical reference platform, and report early adoption, usability, and
perceived clinical value from a formative implementation evaluation. Methods
comprised a retrospective analysis of usage across web, iOS, and Android over
16 weeks (8 April-31 July 2025) and an in-product intercept survey. Usage
metrics were drawn from web and app analytics with bot filtering. A client-side
script randomized single-item prompts to approx. 10% of web sessions from a
predefined battery assessing usefulness, reliability, and adoption intent.
Proportions were summarized with Wilson 95% confidence intervals; free-text
comments underwent thematic content analysis. iatroX reached 19,269 unique web
users, 202,660 engagement events, and approx. 40,000 clinical queries. Mobile
uptake included 1,960 iOS downloads and Android growth (peak >750 daily active
users). The survey yielded 1,223 item-level responses: perceived usefulness
86.2% (95% CI 74.8-93.9%; 50/58); would use again 93.3% (95% CI 68.1-99.8%;
14/15); recommend to a colleague 88.4% (95% CI 75.1-95.9%; 38/43); perceived
accuracy 75.0% (95% CI 58.8-87.3%; 30/40); reliability 79.4% (95% CI
62.1-91.3%; 27/34). Themes highlighted speed, guideline-linked answers, and UK
specificity. Early real-world use suggests iatroX can mitigate information
overload and support timely answers for UK clinicians. Limitations include
small per-item samples and early-adopter bias; future work will include
accuracy audits and prospective studies on workflow and care quality.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« ä»‹ç»äº†åŸºäºRAGæŠ€æœ¯çš„ä¸´åºŠå‚è€ƒå¹³å°iatroXï¼Œæ—¨åœ¨è§£å†³ä¸´åºŠåŒ»ç”Ÿé¢ä¸´çš„ä¿¡æ¯è¿‡è½½é—®é¢˜ã€‚è¯¥å¹³å°é€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆæä¾›å¿«é€Ÿã€å¯æº¯æºçš„åŒ»ç–—ç­”æ¡ˆï¼Œå¹¶åœ¨è‹±å›½è¿›è¡Œå®é™…åº”ç”¨è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºæ—©æœŸç”¨æˆ·å¯¹å…¶æœ‰ç”¨æ€§ã€å‡†ç¡®æ€§å’Œå¯é æ€§æŒç§¯æè¯„ä»·ã€‚ç ”ç©¶è¿˜åˆ†æäº†å¹³å°çš„ä½¿ç”¨æ•°æ®ã€ç”¨æˆ·åé¦ˆåŠå±€é™æ€§ï¼Œå¹¶å±•æœ›äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.21035v1">CLAUSE: Agentic Neuro-Symbolic Knowledge Graph Reasoning via Dynamic Learnable Context Engineering</a></td><td><details><summary>å±•å¼€</summary>Knowledge graphs provide structured context for multi-hop question answering,
but deployed systems must balance answer accuracy with strict latency and cost
targets while preserving provenance. Static k-hop expansions and "think-longer"
prompting often over-retrieve, inflate context, and yield unpredictable
runtime. We introduce CLAUSE, an agentic three-agent neuro-symbolic framework
that treats context construction as a sequential decision process over
knowledge graphs, deciding what to expand, which paths to follow or backtrack,
what evidence to keep, and when to stop. Latency (interaction steps) and prompt
cost (selected tokens) are exposed as user-specified budgets or prices,
allowing per-query adaptation to trade-offs among accuracy, latency, and cost
without retraining. CLAUSE employs the proposed Lagrangian-Constrained
Multi-Agent Proximal Policy Optimization (LC-MAPPO) algorithm to coordinate
three agents: Subgraph Architect, Path Navigator, and Context Curator, so that
subgraph construction, reasoning-path discovery, and evidence selection are
jointly optimized under per-query resource budgets on edge edits, interaction
steps, and selected tokens. Across HotpotQA, MetaQA, and FactKG, CLAUSE yields
higher EM@1 while reducing subgraph growth and end-to-end latency at equal or
lower token budgets. On MetaQA-2-hop, relative to the strongest RAG baseline
(GraphRAG), CLAUSE achieves +39.3 EM@1 with 18.6% lower latency and 40.9% lower
edge growth. The resulting contexts are compact, provenance-preserving, and
deliver predictable performance under deployment constraints.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†CLAUSEï¼Œä¸€ç§åŸºäºæ™ºèƒ½ç¥ç»ç¬¦å·æ¡†æ¶çš„å¤šä»£ç†ç³»ç»Ÿï¼Œç”¨äºä¼˜åŒ–çŸ¥è¯†å›¾è°±ä¸Šçš„ä¸Šä¸‹æ–‡æ„å»ºè¿‡ç¨‹ï¼Œé€šè¿‡åŠ¨æ€å†³ç­–åœ¨å‡†ç¡®æ€§ã€å»¶è¿Ÿå’Œæˆæœ¬ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚CLAUSEåˆ©ç”¨LC-MAPPOç®—æ³•åè°ƒä¸‰ä¸ªä»£ç†ï¼ˆå­å›¾æ„å»ºã€è·¯å¾„å¯¼èˆªå’Œä¸Šä¸‹æ–‡ç®¡ç†ï¼‰ï¼Œåœ¨èµ„æºé™åˆ¶ä¸‹æå‡å¤šè·³é—®ç­”çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºä¼ ç»ŸRAGæ–¹æ³•ï¼ˆå¦‚GraphRAGï¼‰ï¼Œå®ƒåœ¨å‡å°‘å­å›¾å¢é•¿å’Œå»¶è¿Ÿçš„åŒæ—¶æ˜¾è‘—æé«˜äº†å‡†ç¡®ç‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.20953v1">Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM</a></td><td><details><summary>å±•å¼€</summary>We present an advanced approach to mobile app review analysis aimed at
addressing limitations inherent in traditional star-rating systems. Star
ratings, although intuitive and popular among users, often fail to capture the
nuanced feedback present in detailed review texts. Traditional NLP techniques
-- such as lexicon-based methods and classical machine learning classifiers --
struggle to interpret contextual nuances, domain-specific terminology, and
subtle linguistic features like sarcasm. To overcome these limitations, we
propose a modular framework leveraging large language models (LLMs) enhanced by
structured prompting techniques. Our method quantifies discrepancies between
numerical ratings and textual sentiment, extracts detailed, feature-level
insights, and supports interactive exploration of reviews through
retrieval-augmented conversational question answering (RAG-QA). Comprehensive
experiments conducted on three diverse datasets (AWARE, Google Play, and
Spotify) demonstrate that our LLM-driven approach significantly surpasses
baseline methods, yielding improved accuracy, robustness, and actionable
insights in challenging and context-rich review scenarios.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œç»“æ„åŒ–æç¤ºæŠ€æœ¯çš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºçš„å¯¹è¯é—®ç­”ï¼ˆRAG-QAï¼‰æ¥åˆ†æç§»åŠ¨åº”ç”¨è¯„è®ºï¼Œä»¥å…‹æœä¼ ç»Ÿæ˜Ÿçº§è¯„åˆ†å’Œéç»“æ„åŒ–NLPæ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶åœ¨å¤šæ•°æ®é›†å®éªŒä¸­å±•ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.20859v1">Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æ¢è®¨äº†åœ¨RAGé—®ç­”ç³»ç»Ÿä¸­ä¸ºLLMè¾“å‡ºç”Ÿæˆæ›´ç²¾ç¡®çš„å­å¥çº§åˆ«å¼•ç”¨ï¼ˆè€Œéä¼ ç»Ÿå¥å­æˆ–æ®µè½çº§ï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨æå‡å¼•ç”¨ä¿¡æ¯çš„ç®€æ´æ€§å’Œå……åˆ†æ€§ï¼Œå‡å°‘ç”¨æˆ·éªŒè¯æˆæœ¬ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç»“åˆè‡ªåŠ¨æ ‡æ³¨å’Œæ•°æ®è¿‡æ»¤çš„å½’å› æ¡†æ¶ï¼Œé€šè¿‡å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.20769v1">Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems</a></td><td><details><summary>å±•å¼€</summary>In this work, we present a retrieval-augmented generation (RAG)-based system
for provenance analysis of archaeological artifacts, designed to support expert
reasoning by integrating multimodal retrieval and large vision-language models
(VLMs). The system constructs a dual-modal knowledge base from reference texts
and images, enabling raw visual, edge-enhanced, and semantic retrieval to
identify stylistically similar objects. Retrieved candidates are synthesized by
the VLM to generate structured inferences, including chronological,
geographical, and cultural attributions, alongside interpretive justifications.
We evaluate the system on a set of Eastern Eurasian Bronze Age artifacts from
the British Museum. Expert evaluation demonstrates that the system produces
meaningful and interpretable outputs, offering scholars concrete starting
points for analysis and significantly alleviating the cognitive burden of
navigating vast comparative corpora.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„ç³»ç»Ÿï¼Œç”¨äºè€ƒå¤æ–‡ç‰©æ¥æºåˆ†æï¼Œé€šè¿‡æ•´åˆå¤šæ¨¡æ€æ£€ç´¢å’Œå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ï¼Œæ„å»ºåŒæ¨¡æ€çŸ¥è¯†åº“ä»¥æ£€ç´¢é£æ ¼ç›¸ä¼¼çš„æ–‡ç‰©ï¼Œå¹¶ç”Ÿæˆç»“æ„åŒ–æ¨æ–­ï¼ˆå¦‚å¹´ä»£ã€åœ°ç†å’Œæ–‡åŒ–å±æ€§ï¼‰åŠè§£é‡Šæ€§ç†ç”±ï¼Œç»å¤§è‹±åšç‰©é¦†çš„æ¬§äºšé’é“œå™¨æ–‡ç‰©éªŒè¯ï¼Œä¸“å®¶è¯„ä¼°è¡¨æ˜ç³»ç»Ÿèƒ½æœ‰æ•ˆæ”¯æŒå­¦æœ¯åˆ†æå¹¶å‡è½»è®¤çŸ¥è´Ÿæ‹…ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.20707v1">An Automated Retrieval-Augmented Generation LLaMA-4 109B-based System for Evaluating Radiotherapy Treatment Plans</a></td><td><details><summary>å±•å¼€</summary>Purpose: To develop a retrieval-augmented generation (RAG) system powered by
LLaMA-4 109B for automated, protocol-aware, and interpretable evaluation of
radiotherapy treatment plans.
  Methods and Materials: We curated a multi-protocol dataset of 614
radiotherapy plans across four disease sites and constructed a knowledge base
containing normalized dose metrics and protocol-defined constraints. The RAG
system integrates three core modules: a retrieval engine optimized across five
SentenceTransformer backbones, a percentile prediction component based on
cohort similarity, and a clinical constraint checker. These tools are directed
by a large language model (LLM) using a multi-step prompt-driven reasoning
pipeline to produce concise, grounded evaluations.
  Results: Retrieval hyperparameters were optimized using Gaussian Process on a
scalarized loss function combining root mean squared error (RMSE), mean
absolute error (MAE), and clinically motivated accuracy thresholds. The best
configuration, based on all-MiniLM-L6-v2, achieved perfect nearest-neighbor
accuracy within a 5-percentile-point margin and a sub-2pt MAE. When tested
end-to-end, the RAG system achieved 100% agreement with the computed values by
standalone retrieval and constraint-checking modules on both percentile
estimates and constraint identification, confirming reliable execution of all
retrieval, prediction and checking steps.
  Conclusion: Our findings highlight the feasibility of combining structured
population-based scoring with modular tool-augmented reasoning for transparent,
scalable plan evaluation in radiation therapy. The system offers traceable
outputs, minimizes hallucination, and demonstrates robustness across protocols.
Future directions include clinician-led validation, and improved domain-adapted
retrieval models to enhance real-world integration.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ç§åŸºäºLLaMA-4 109Bçš„RAGç³»ç»Ÿï¼Œç”¨äºæ”¾å°„æ²»ç–—è®¡åˆ’çš„è‡ªåŠ¨åŒ–ã€åè®®æ„ŸçŸ¥å’Œå¯è§£é‡Šæ€§è¯„ä¼°ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ•´åˆæ£€ç´¢å¼•æ“ã€ç™¾åˆ†ä½æ•°é¢„æµ‹ç»„ä»¶å’Œä¸´åºŠçº¦æŸæ£€æŸ¥å™¨ï¼Œåˆ©ç”¨å¤šæ­¥æç¤ºé©±åŠ¨çš„æ¨ç†æµç¨‹ç”Ÿæˆç²¾ç¡®è¯„ä¼°ï¼Œå¹¶åœ¨å®éªŒä¸­å±•ç°äº†é«˜å‡†ç¡®æ€§å’Œå¯é æ€§ï¼ŒåŒæ—¶å‡å°‘äº†å¹»è§‰è¾“å‡ºã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-24
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.20324v1">RAG Security and Privacy: Formalizing the Threat Model and Attack Surface</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) is an emerging approach in natural
language processing that combines large language models (LLMs) with external
document retrieval to produce more accurate and grounded responses. While RAG
has shown strong potential in reducing hallucinations and improving factual
consistency, it also introduces new privacy and security challenges that differ
from those faced by traditional LLMs. Existing research has demonstrated that
LLMs can leak sensitive information through training data memorization or
adversarial prompts, and RAG systems inherit many of these vulnerabilities. At
the same time, reliance of RAG on an external knowledge base opens new attack
surfaces, including the potential for leaking information about the presence or
content of retrieved documents, or for injecting malicious content to
manipulate model behavior. Despite these risks, there is currently no formal
framework that defines the threat landscape for RAG systems. In this paper, we
address a critical gap in the literature by proposing, to the best of our
knowledge, the first formal threat model for retrieval-RAG systems. We
introduce a structured taxonomy of adversary types based on their access to
model components and data, and we formally define key threat vectors such as
document-level membership inference and data poisoning, which pose serious
privacy and integrity risks in real-world deployments. By establishing formal
definitions and attack models, our work lays the foundation for a more rigorous
and principled understanding of privacy and security in RAG systems.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿåœ¨éšç§å’Œå®‰å…¨æ–¹é¢çš„æ–°æŒ‘æˆ˜ï¼Œæå‡ºäº†é¦–ä¸ªé’ˆå¯¹RAGç³»ç»Ÿçš„æ­£å¼å¨èƒæ¨¡å‹ï¼Œå¹¶å®šä¹‰äº†åŒ…æ‹¬æ–‡æ¡£çº§æˆå‘˜æ¨æ–­å’Œæ•°æ®æŠ•æ¯’åœ¨å†…çš„å…³é”®å¨èƒå‘é‡ï¼Œä¸ºç†è§£å’Œåº”å¯¹RAGç³»ç»Ÿçš„å®‰å…¨é£é™©æä¾›äº†ç†è®ºåŸºç¡€ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.20190v1">STAF: Leveraging LLMs for Automated Attack Tree-Based Security Test Generation</a></td><td><details><summary>å±•å¼€</summary>In modern automotive development, security testing is critical for
safeguarding systems against increasingly advanced threats. Attack trees are
widely used to systematically represent potential attack vectors, but
generating comprehensive test cases from these trees remains a labor-intensive,
error-prone task that has seen limited automation in the context of testing
vehicular systems. This paper introduces STAF (Security Test Automation
Framework), a novel approach to automating security test case generation.
Leveraging Large Language Models (LLMs) and a four-step self-corrective
Retrieval-Augmented Generation (RAG) framework, STAF automates the generation
of executable security test cases from attack trees, providing an end-to-end
solution that encompasses the entire attack surface. We particularly show the
elements and processes needed to provide an LLM to actually produce sensible
and executable automotive security test suites, along with the integration with
an automated testing framework. We further compare our tailored approach with
general purpose (vanilla) LLMs and the performance of different LLMs (namely
GPT-4.1 and DeepSeek) using our approach. We also demonstrate the method of our
operation step-by-step in a concrete case study. Our results show significant
improvements in efficiency, accuracy, scalability, and easy integration in any
workflow, marking a substantial advancement in automating automotive security
testing methodologies. Using TARAs as an input for verfication tests, we create
synergies by connecting two vital elements of a secure automotive development
process.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†STAFæ¡†æ¶ï¼Œåˆ©ç”¨LLMå’Œå››æ­¥è‡ªæ ¡æ­£RAGæŠ€æœ¯ï¼Œè‡ªåŠ¨åŒ–ç”Ÿæˆæ±½è½¦å®‰å…¨æµ‹è¯•ç”¨ä¾‹ï¼Œæ˜¾è‘—æå‡äº†æµ‹è¯•æ•ˆç‡ã€å‡†ç¡®æ€§åŠå¯æ‰©å±•æ€§ï¼Œå¹¶å¯¹æ¯”äº†ä¸åŒLLMï¼ˆå¦‚GPT-4.1å’ŒDeepSeekï¼‰çš„æ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.19980v1">RAD: Towards Trustworthy Retrieval-Augmented Multi-modal Clinical Diagnosis</a></td><td><details><summary>å±•å¼€</summary>Clinical diagnosis is a highly specialized discipline requiring both domain
expertise and strict adherence to rigorous guidelines. While current AI-driven
medical research predominantly focuses on knowledge graphs or natural text
pretraining paradigms to incorporate medical knowledge, these approaches
primarily rely on implicitly encoded knowledge within model parameters,
neglecting task-specific knowledge required by diverse downstream tasks. To
address this limitation, we propose Retrieval-Augmented Diagnosis (RAD), a
novel framework that explicitly injects external knowledge into multimodal
models directly on downstream tasks. Specifically, RAD operates through three
key mechanisms: retrieval and refinement of disease-centered knowledge from
multiple medical sources, a guideline-enhanced contrastive loss that constrains
the latent distance between multi-modal features and guideline knowledge, and
the dual transformer decoder that employs guidelines as queries to steer
cross-modal fusion, aligning the models with clinical diagnostic workflows from
guideline acquisition to feature extraction and decision-making. Moreover,
recognizing the lack of quantitative evaluation of interpretability for
multimodal diagnostic models, we introduce a set of criteria to assess the
interpretability from both image and text perspectives. Extensive evaluations
across four datasets with different anatomies demonstrate RAD's
generalizability, achieving state-of-the-art performance. Furthermore, RAD
enables the model to concentrate more precisely on abnormal regions and
critical indicators, ensuring evidence-based, trustworthy diagnosis. Our code
is available at https://github.com/tdlhl/RAD.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºâ€œRetrieval-Augmented Diagnosis (RAD)â€çš„æ–°æ¡†æ¶ï¼Œé€šè¿‡æ£€ç´¢å’Œæ•´åˆå¤šæºåŒ»å­¦çŸ¥è¯†ï¼ˆå¦‚ç–¾ç—…æŒ‡å—ï¼‰ï¼Œç»“åˆå¯¹æ¯”æŸå¤±å’ŒåŒTransformerè§£ç å™¨ç­‰æœºåˆ¶ï¼Œæ˜¾å¼åœ°å°†å¤–éƒ¨çŸ¥è¯†æ³¨å…¥å¤šæ¨¡æ€æ¨¡å‹ï¼Œä»¥æå‡ä¸´åºŠè¯Šæ–­çš„å‡†ç¡®æ€§ã€å¯è§£é‡Šæ€§åŠä¸å·¥ä½œæµç¨‹çš„å¥‘åˆåº¦ï¼Œå¹¶è®¾è®¡äº†å®šé‡è¯„ä¼°æŒ‡æ ‡ã€‚è¯¥æ¡†æ¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå±äºRAGæŠ€æœ¯åœ¨åŒ»ç–—è¯Šæ–­é¢†åŸŸçš„æ‰©å±•åº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.19952v1">When Words Can't Capture It All: Towards Video-Based User Complaint Text Generation with Multimodal Video Complaint Dataset</a></td><td><details><summary>å±•å¼€</summary>While there exists a lot of work on explainable complaint mining,
articulating user concerns through text or video remains a significant
challenge, often leaving issues unresolved. Users frequently struggle to
express their complaints clearly in text but can easily upload videos depicting
product defects (e.g., vague text such as `worst product' paired with a
5-second video depicting a broken headphone with the right earcup). This paper
formulates a new task in the field of complaint mining to aid the common users'
need to write an expressive complaint, which is Complaint Description from
Videos (CoD-V) (e.g., to help the above user articulate her complaint about the
defective right earcup). To this end, we introduce ComVID, a video complaint
dataset containing 1,175 complaint videos and the corresponding descriptions,
also annotated with the emotional state of the complainer. Additionally, we
present a new complaint retention (CR) evaluation metric that discriminates the
proposed (CoD-V) task against standard video summary generation and description
tasks. To strengthen this initiative, we introduce a multimodal
Retrieval-Augmented Generation (RAG) embedded VideoLLaMA2-7b model, designed to
generate complaints while accounting for the user's emotional state. We conduct
a comprehensive evaluation of several Video Language Models on several tasks
(pre-trained and fine-tuned versions) with a range of established evaluation
metrics, including METEOR, perplexity, and the Coleman-Liau readability score,
among others. Our study lays the foundation for a new research direction to
provide a platform for users to express complaints through video. Dataset and
resources are available at: https://github.com/sarmistha-D/CoD-V.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æŠ•è¯‰æŒ–æ˜ä»»åŠ¡â€”â€”è§†é¢‘æŠ•è¯‰æè¿°ï¼ˆCoD-Vï¼‰ï¼Œæ—¨åœ¨å¸®åŠ©ç”¨æˆ·é€šè¿‡è§†é¢‘è¡¨è¾¾æŠ•è¯‰å†…å®¹ï¼Œå¹¶å¼•å…¥äº†ä¸€ä¸ªåŒ…å«1175æ¡æŠ•è¯‰è§†é¢‘åŠå¯¹åº”æè¿°çš„æ•°æ®é›†ComVIDã€‚ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡CRï¼Œå¹¶å¼€å‘äº†ä¸€ç§åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„å¤šæ¨¡æ€æ¨¡å‹VideoLLaMA2-7bï¼Œç”¨äºç”Ÿæˆè€ƒè™‘ç”¨æˆ·æƒ…æ„ŸçŠ¶æ€çš„æŠ•è¯‰æè¿°ã€‚ç ”ç©¶é€šè¿‡å¤šç§è¯„ä¼°æŒ‡æ ‡å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡Œäº†å…¨é¢éªŒè¯ï¼Œä¸ºè¯¥é¢†åŸŸçš„æ–°ç ”ç©¶æ–¹å‘å¥ å®šäº†åŸºç¡€ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.19931v1">Documentation Retrieval Improves Planning Language Generation</a></td><td><details><summary>å±•å¼€</summary>Certain strong LLMs have shown promise for zero-shot formal planning by
generating planning languages like PDDL. Yet, performance of most open-source
models under 50B parameters has been reported to be close to zero due to the
low-resource nature of these languages. We significantly improve their
performance via a series of lightweight pipelines that integrates documentation
retrieval with modular code generation and error refinement. With models like
Llama-4-Maverick, our best pipeline improves plan correctness from 0\% to over
80\% on the common BlocksWorld domain. However, while syntactic errors are
substantially reduced, semantic errors persist in more challenging domains,
revealing fundamental limitations in current models' reasoning
capabilities.\footnote{Our code and data can be found at
https://github.com/Nangxxxxx/PDDL-RAG</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§é€šè¿‡æ•´åˆæ–‡æ¡£æ£€ç´¢ã€æ¨¡å—åŒ–ä»£ç ç”Ÿæˆå’Œé”™è¯¯ä¿®æ­£çš„è½»é‡çº§æµç¨‹ï¼Œæ˜¾è‘—æå‡äº†ä¸­å°å‹å¼€æºLLMsåœ¨é›¶æ ·æœ¬å½¢å¼åŒ–è§„åˆ’ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼ˆå¦‚ç”ŸæˆPDDLè§„åˆ’è¯­è¨€ï¼‰ï¼Œå°¤å…¶åœ¨BlocksWorldé¢†åŸŸå°†æ­£ç¡®ç‡ä»0%æå‡è‡³80%ä»¥ä¸Šï¼Œä½†æŒ‡å‡ºæ¨¡å‹åœ¨å¤æ‚é¢†åŸŸçš„è¯­ä¹‰æ¨ç†ä»å­˜åœ¨æ ¹æœ¬æ€§å±€é™ã€‚å…¶æ–¹æ³•æ ¸å¿ƒæ¶‰åŠæ£€ç´¢å¢å¼ºæŠ€æœ¯ï¼ˆä»£ç åº“æ ‡æ³¨äº†PDDL-RAGï¼‰ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-23
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.19218v1">HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus</a></td><td><details><summary>å±•å¼€</summary>Evaluation of hydrocephalus in children is challenging, and the related
research is limited by a lack of publicly available, expert-annotated datasets,
particularly those with segmentation of the choroid plexus. To address this, we
present HyKid, an open-source dataset from 48 pediatric patients with
hydrocephalus. 3D MRIs were provided with 1mm isotropic resolution, which was
reconstructed from routine low-resolution images using a slice-to-volume
algorithm. Manually corrected segmentations of brain tissues, including white
matter, grey matter, lateral ventricle, external CSF, and the choroid plexus,
were provided by an experienced neurologist. Additionally, structured data was
extracted from clinical radiology reports using a Retrieval-Augmented
Generation framework. The strong correlation between choroid plexus volume and
total CSF volume provided a potential biomarker for hydrocephalus evaluation,
achieving excellent performance in a predictive model (AUC = 0.87). The
proposed HyKid dataset provided a high-quality benchmark for neuroimaging
algorithms development, and it revealed the choroid plexus-related features in
hydrocephalus assessments. Our datasets are publicly available at
https://www.synapse.org/Synapse:syn68544889.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†HyKidæ•°æ®é›†ï¼Œä¸€ä¸ªé’ˆå¯¹å„¿ç«¥è„‘ç§¯æ°´çš„å¼€æºæ•°æ®é›†ï¼ŒåŒ…å«é«˜åˆ†è¾¨ç‡3D MRIå›¾åƒå’Œä¸“å®¶æ‰‹åŠ¨æ ¡æ­£çš„åˆ†å‰²æ ‡æ³¨ã€‚ç ”ç©¶åˆ©ç”¨RAGæ¡†æ¶ä»ä¸´åºŠæ”¾å°„å­¦æŠ¥å‘Šä¸­æå–ç»“æ„åŒ–æ•°æ®ï¼Œå¹¶å‘ç°äº†è„‰ç»œä¸›ä½“ç§¯ä¸è„‘è„Šæ¶²æ€»é‡çš„ç›¸å…³æ€§å¯ä½œä¸ºè„‘ç§¯æ°´è¯„ä¼°çš„ç”Ÿç‰©æ ‡å¿—ç‰©ï¼Œé¢„æµ‹æ¨¡å‹è¡¨ç°ä¼˜å¼‚ï¼ˆAUC=0.87ï¼‰ã€‚è¯¥æ•°æ®é›†ä¸ºç¥ç»å½±åƒç®—æ³•å¼€å‘æä¾›äº†é«˜è´¨é‡åŸºå‡†ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.19209v1">A Knowledge Graph and a Tripartite Evaluation Framework Make Retrieval-Augmented Generation Scalable and Transparent</a></td><td><details><summary>å±•å¼€</summary>Large Language Models (LLMs) have significantly enhanced conversational
Artificial Intelligence(AI) chatbots; however, domain-specific accuracy and the
avoidance of factual inconsistencies remain pressing challenges, particularly
for large datasets. Designing an effective chatbot with appropriate methods and
evaluating its effectiveness is among the challenges in this domain. This study
presents a Retrieval Augmented Generation (RAG) chatbot that harnesses a
knowledge graph and vector search retrieval to deliver precise, context-rich
responses in an exemplary use case from over high-volume engineering
project-related emails, thereby minimising the need for document chunking. A
central innovation of this work is the introduction of RAG Evaluation
(RAG-Eval), a novel chain-of-thought LLM-based tripartite evaluation framework
specifically developed to assess RAG applications. This framework operates in
parallel with the chatbot, jointly assessing the user's query, the retrieved
document, and the generated response, enabling a holistic evaluation across
multiple quality metrics like query relevance, factual accuracy, coverage,
coherence and fluency. The resulting scoring system is provided directly to
users as a confidence score (1 to 100%), enabling quick identification of
possible misaligned or incomplete answers. This proposed approach promotes
transparency and rapid verification by incorporating metadata email IDs,
timestamps into responses. Experimental comparisons against BERTScore and
G-EVAL for summarisation evaluation tasks confirm its effectiveness, and
empirical analysis also shows RAG-Eval reliably detects factual gaps and query
mismatches, thereby fostering trust in high demand, data centric environments.
These findings highlight a scalable path for developing accurate,
user-verifiable chatbots that bridge the gap between high-level conversational
fluency and factual accuracy.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„èŠå¤©æœºå™¨äººï¼Œç»“åˆçŸ¥è¯†å›¾è°±å’Œå‘é‡æœç´¢æ£€ç´¢æŠ€æœ¯ï¼Œä»å¤§è§„æ¨¡å·¥ç¨‹ç›¸å…³é‚®ä»¶æ•°æ®ä¸­ç”Ÿæˆç²¾å‡†ä¸”ä¸Šä¸‹æ–‡ä¸°å¯Œçš„å›ç­”ï¼Œå‡å°‘æ–‡æ¡£åˆ†å—çš„éœ€æ±‚ã€‚è®ºæ–‡è¿˜åˆ›æ–°åœ°å¼•å…¥äº†RAG-Evalï¼Œä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä¸‰æ–¹è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è¯„ä¼°RAGåº”ç”¨çš„æŸ¥è¯¢ç›¸å…³æ€§ã€äº‹å®å‡†ç¡®æ€§ã€è¦†ç›–èŒƒå›´ç­‰è´¨é‡æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡ç½®ä¿¡åº¦åˆ†æ•°å’Œå…ƒæ•°æ®å¢å¼ºé€æ˜åº¦ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨é«˜æ•ˆæ€§å’Œå¯ä¿¡åº¦ä¸Šä¼˜äºBERTScoreå’ŒG-EVALã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.18868v1">Memory in Large Language Models: Mechanisms, Evaluation and Evolution</a></td><td><details><summary>å±•å¼€</summary>Under a unified operational definition, we define LLM memory as a persistent
state written during pretraining, finetuning, or inference that can later be
addressed and that stably influences outputs. We propose a four-part taxonomy
(parametric, contextual, external, procedural/episodic) and a memory quadruple
(location, persistence, write/access path, controllability). We link mechanism,
evaluation, and governance via the chain write -> read -> inhibit/update. To
avoid distorted comparisons across heterogeneous setups, we adopt a
three-setting protocol (parametric only, offline retrieval, online retrieval)
that decouples capability from information availability on the same data and
timeline. On this basis we build a layered evaluation: parametric (closed-book
recall, edit differential, memorization/privacy), contextual (position curves
and the mid-sequence drop), external (answer correctness vs snippet
attribution/faithfulness), and procedural/episodic (cross-session consistency
and timeline replay, E MARS+). The framework integrates temporal governance and
leakage auditing (freshness hits, outdated answers, refusal slices) and
uncertainty reporting via inter-rater agreement plus paired tests with
multiple-comparison correction. For updating and forgetting, we present DMM
Gov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC),
and RAG to form an auditable loop covering admission thresholds, rollout,
monitoring, rollback, and change audits, with specs for timeliness, conflict
handling, and long-horizon consistency. Finally, we give four testable
propositions: minimum identifiability; a minimal evaluation card; causally
constrained editing with verifiable forgetting; and when retrieval with
small-window replay outperforms ultra-long-context reading. This yields a
reproducible, comparable, and governable coordinate system for research and
deployment.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå…³äºLLMè®°å¿†çš„ç»Ÿä¸€æ“ä½œå®šä¹‰å’Œå››éƒ¨åˆ†åˆ†ç±»æ³•ï¼ˆå‚æ•°åŒ–ã€ä¸Šä¸‹æ–‡ã€å¤–éƒ¨ã€è¿‡ç¨‹/æƒ…æ™¯ï¼‰ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªè¯„ä¼°æ¡†æ¶ï¼Œå…¶ä¸­åŒ…æ‹¬å¤–éƒ¨è®°å¿†ï¼ˆä¸RAGç›¸å…³ï¼‰çš„è¯„ä¼°æ ‡å‡†ï¼Œå¦‚ç­”æ¡ˆæ­£ç¡®æ€§ä¸ç‰‡æ®µå½’å› /å¿ å®æ€§ã€‚è®ºæ–‡è¿˜è®¨è®ºäº†DMM Govæ¡†æ¶ï¼Œåè°ƒåŒ…æ‹¬RAGåœ¨å†…çš„å¤šç§æŠ€æœ¯å½¢æˆä¸€ä¸ªå¯å®¡è®¡çš„å¾ªç¯ï¼Œç”¨äºæ›´æ–°å’Œé—å¿˜ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.18667v1">TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>Graph-based Retrieval-augmented generation (RAG) has become a widely studied
approach for improving the reasoning, accuracy, and factuality of Large
Language Models. However, many existing graph-based RAG systems overlook the
high cost associated with LLM token usage during graph construction, hindering
large-scale adoption. To address this, we propose TERAG, a simple yet effective
framework designed to build informative graphs at a significantly lower cost.
Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the
retrieval phase, and we achieve at least 80% of the accuracy of widely used
graph-based RAG methods while consuming only 3%-11% of the output tokens.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºTERAGçš„ä½æˆæœ¬å›¾ç»“æ„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆä¸ªæ€§åŒ–PageRankï¼ˆPPRï¼‰ä¼˜åŒ–æ£€ç´¢é˜¶æ®µï¼Œå¤§å¹…å‡å°‘LLMå»ºå›¾æ—¶çš„tokenæ¶ˆè€—ï¼ˆé™è‡³3%-11%ï¼‰ï¼ŒåŒæ—¶ä¿æŒä¸»æµå›¾åŸºRAGæ–¹æ³•80%ä»¥ä¸Šçš„å‡†ç¡®æ€§ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-22
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.18054v1">A Knowledge Graph-based Retrieval-Augmented Generation Framework for Algorithm Selection in the Facility Layout Problem</a></td><td><details><summary>å±•å¼€</summary>Selecting a solution algorithm for the Facility Layout Problem (FLP), an
NP-hard optimization problem with a multiobjective trade-off, is a complex task
that requires deep expert knowledge. The performance of a given algorithm
depends on specific problem characteristics such as its scale, objectives, and
constraints. This creates a need for a data-driven recommendation method to
guide algorithm selection in automated design systems. This paper introduces a
new recommendation method to make such expertise accessible, based on a
Knowledge Graph-based Retrieval-Augmented Generation (KG RAG) framework. To
address this, a domain-specific knowledge graph is constructed from published
literature. The method then employs a multi-faceted retrieval mechanism to
gather relevant evidence from this knowledge graph using three distinct
approaches, which include a precise graph-based search, flexible vector-based
search, and high-level cluster-based search. The retrieved evidence is utilized
by a Large Language Model (LLM) to generate algorithm recommendations with
data-driven reasoning. The proposed KG-RAG method is compared against a
commercial LLM chatbot with access to the knowledge base as a table, across a
series of diverse, real-world FLP test cases. Based on recommendation accuracy
and reasoning capability, the proposed method performed significantly better
than the commercial LLM chatbot.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆKG-RAGï¼‰æ¡†æ¶ï¼Œç”¨äºä¸ºè®¾æ–½å¸ƒå±€é—®é¢˜ï¼ˆFLPï¼‰æ¨èåˆé€‚çš„ç®—æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡æ„å»ºé¢†åŸŸç‰¹å®šçš„çŸ¥è¯†å›¾è°±ï¼Œç»“åˆå¤šæ–¹é¢çš„æ£€ç´¢æœºåˆ¶ï¼ˆåŒ…æ‹¬åŸºäºå›¾çš„ç²¾ç¡®æœç´¢ã€åŸºäºå‘é‡çš„çµæ´»æœç´¢å’ŒåŸºäºèšç±»çš„é«˜çº§æœç´¢ï¼‰ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆç®—æ³•æ¨èï¼Œå¹¶åœ¨çœŸå®FLPæ¡ˆä¾‹ä¸­éªŒè¯äº†å…¶ä¼˜äºå•†ç”¨LLMèŠå¤©æœºå™¨äººçš„æ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.17788v1">One Agent to Serve All: a Lite-Adaptive Stylized AI Assistant for Millions of Multi-Style Official Accounts</a></td><td><details><summary>å±•å¼€</summary>Conversational agents deployed in industrial-scale official account platforms
must generate responses that are both contextually grounded and stylistically
aligned-requirements that existing methods struggle to meet. Chain-of-thought
(CoT) prompting induces significant latency due to multi-turn reasoning;
per-account fine-tuning is computationally prohibitive; and long prompt-based
methods degrade the model's ability to grasp injected context and style. In
this paper, we propose WeStar, a lite-adaptive framework for stylized
contextual question answering that scales to millions of official accounts.
WeStar combines context-grounded generation via RAG with style-aware generation
using Parametric RAG (PRAG), where LoRA modules are dynamically activated per
style cluster. Our contributions are fourfold: (1) We introduce WeStar, a
unified framework capable of serving large volumes of official accounts with
minimal overhead. (2) We propose a multi-dimensional, cluster-based parameter
sharing scheme that enables compact style representation while preserving
stylistic diversity. (3) We develop a style-enhanced Direct Preference
Optimization (SeDPO) method to optimize each style cluster's parameters for
improved generation quality. (4) Experiments on a large-scale industrial
dataset validate the effectiveness and efficiency of WeStar, underscoring its
pracitical value in real-world deployment.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†WeStaræ¡†æ¶ï¼Œç»“åˆRAGå’ŒParametric RAGï¼ˆPRAGï¼‰æŠ€æœ¯ï¼Œé€šè¿‡åŠ¨æ€æ¿€æ´»LoRAæ¨¡å—å®ç°é£æ ¼åŒ–ä¸Šä¸‹æ–‡é—®ç­”ï¼Œæ—¨åœ¨ä¸ºæµ·é‡å®˜æ–¹è´¦å·æä¾›ä½å»¶è¿Ÿã€é«˜é€‚åº”æ€§çš„ç”Ÿæˆè§£å†³æ–¹æ¡ˆã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.17671v1">Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications</a></td><td><details><summary>å±•å¼€</summary>The widespread adoption of Large Language Models (LLMs) has been hindered by
their tendency to hallucinate, generating plausible but factually incorrect
information. While Retrieval-Augmented Generation (RAG) systems attempt to
address this issue by grounding responses in external knowledge, hallucination
remains a persistent challenge, particularly for morphologically complex,
low-resource languages like Turkish. This paper introduces Turk-LettuceDetect,
the first suite of hallucination detection models specifically designed for
Turkish RAG applications. Building on the LettuceDetect framework, we formulate
hallucination detection as a token-level classification task and fine-tune
three distinct encoder architectures: a Turkish-specific ModernBERT,
TurkEmbed4STS, and multilingual EuroBERT. These models were trained on a
machine-translated version of the RAGTruth benchmark dataset containing 17,790
instances across question answering, data-to-text generation, and summarization
tasks. Our experimental results show that the ModernBERT-based model achieves
an F1-score of 0.7266 on the complete test set, with particularly strong
performance on structured tasks. The models maintain computational efficiency
while supporting long contexts up to 8,192 tokens, making them suitable for
real-time deployment. Comparative analysis reveals that while state-of-the-art
LLMs demonstrate high recall, they suffer from low precision due to
over-generation of hallucinated content, underscoring the necessity of
specialized detection mechanisms. By releasing our models and translated
dataset, this work addresses a critical gap in multilingual NLP and establishes
a foundation for developing more reliable and trustworthy AI applications for
Turkish and other languages.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡é’ˆå¯¹åœŸè€³å…¶è¯­ç­‰ä½èµ„æºè¯­è¨€ä¸­RAGç³»ç»Ÿçš„å¹»è§‰é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªåœŸè€³å…¶è¯­ä¸“ç”¨å¹»è§‰æ£€æµ‹æ¨¡å‹å¥—ä»¶Turk-LettuceDetectã€‚é€šè¿‡å¾®è°ƒä¸‰ç§ç¼–ç å™¨æ¶æ„å¹¶ä½¿ç”¨æœºå™¨ç¿»è¯‘çš„åŸºå‡†æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œé‡ç‚¹è§£å†³äº†é—®ç­”ã€æ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆå’Œæ‘˜è¦ä»»åŠ¡ä¸­çš„å¹»è§‰æ£€æµ‹é—®é¢˜ï¼Œå®éªŒè¡¨æ˜å…¶æ¨¡å‹åœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶æœ‰æ•ˆæå‡äº†æ£€æµ‹æ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.17544v1">A Multimodal Conversational Assistant for the Characterization of Agricultural Plots from Geospatial Open Data</a></td><td><details><summary>å±•å¼€</summary>The increasing availability of open Earth Observation (EO) and agricultural
datasets holds great potential for supporting sustainable land management.
However, their high technical entry barrier limits accessibility for non-expert
users. This study presents an open-source conversational assistant that
integrates multimodal retrieval and large language models (LLMs) to enable
natural language interaction with heterogeneous agricultural and geospatial
data. The proposed architecture combines orthophotos, Sentinel-2 vegetation
indices, and user-provided documents through retrieval-augmented generation
(RAG), allowing the system to flexibly determine whether to rely on multimodal
evidence, textual knowledge, or both in formulating an answer. To assess
response quality, we adopt an LLM-as-a-judge methodology using Qwen3-32B in a
zero-shot, unsupervised setting, applying direct scoring in a multi-dimensional
quantitative evaluation framework. Preliminary results show that the system is
capable of generating clear, relevant, and context-aware responses to
agricultural queries, while remaining reproducible and scalable across
geographic regions. The primary contributions of this work include an
architecture for fusing multimodal EO and textual knowledge sources, a
demonstration of lowering the barrier to access specialized agricultural
information through natural language interaction, and an open and reproducible
design.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆå¤šæ¨¡æ€æ£€ç´¢ä¸å¤§è¯­è¨€æ¨¡å‹çš„å¼€æºå¯¹è¯åŠ©æ‰‹ï¼Œåˆ©ç”¨RAGæŠ€æœ¯æ•´åˆå†œä¸šä¸åœ°ç†ç©ºé—´æ•°æ®ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’é™ä½éä¸“å®¶ç”¨æˆ·ä½¿ç”¨é—¨æ§›ï¼Œå¹¶é‡‡ç”¨LLMè¯„ä¼°æ–¹æ³•éªŒè¯å“åº”è´¨é‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.17486v1">AttnComp: Attention-Guided Adaptive Context Compression for Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>Retrieval-augmented generation improves the factual accuracy of Large
Language Models (LLMs) by incorporating external context, but often suffers
from irrelevant retrieved content that hinders effectiveness. Context
compression addresses this issue by filtering out irrelevant information from
context before LLM generation. However, existing methods struggle to adaptively
adjust compression rates for different context, maintain low latency and
integrate information across multiple documents. To overcome these limitations,
We introduce AttnComp, an adaptive, efficient and context-aware compression
framework. By leveraging the attention mechanism of LLMs to identify relevant
information, AttnComp employs a Top-P compression algorithm to retain the
minimal set of documents whose cumulative attention weights exceeds a
predefined threshold. In addition to compression, AttnComp estimates response
confidence by assessing the overall relevance of the retrieved content,
enabling users to gauge response reliability. Experiments demonstrate that
AttnComp outperforms existing compression methods and uncompressed baselines,
achieving higher accuracy with substantial compression rates and lower latency.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºAttnCompçš„è‡ªé€‚åº”ã€é«˜æ•ˆä¸”ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å‹ç¼©æ¡†æ¶ï¼Œç”¨äºè§£å†³RAGä¸­æ£€ç´¢å†…å®¹å¯èƒ½æ— å…³å¯¼è‡´æ•ˆæœä¸‹é™çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„æ³¨æ„åŠ›æœºåˆ¶è¯†åˆ«ç›¸å…³ä¿¡æ¯ï¼Œå¹¶é€šè¿‡Top-På‹ç¼©ç®—æ³•ä¿ç•™å…³é”®æ–‡æ¡£ï¼ŒåŒæ—¶è¿˜èƒ½è¯„ä¼°å“åº”ç½®ä¿¡åº¦ä»¥æå‡å¯é æ€§ï¼Œå®éªŒè¯æ˜å…¶æ€§èƒ½ä¼˜äºç°æœ‰å‹ç¼©æ–¹æ³•å’Œæœªå‹ç¼©åŸºçº¿ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.17395v1">FinDebate: Multi-Agent Collaborative Intelligence for Financial Analysis</a></td><td><details><summary>å±•å¼€</summary>We introduce FinDebate, a multi-agent framework for financial analysis,
integrating collaborative debate with domain-specific Retrieval-Augmented
Generation (RAG). Five specialized agents, covering earnings, market,
sentiment, valuation, and risk, run in parallel to synthesize evidence into
multi-dimensional insights. To mitigate overconfidence and improve reliability,
we introduce a safe debate protocol that enables agents to challenge and refine
initial conclusions while preserving coherent recommendations. Experimental
results, based on both LLM-based and human evaluations, demonstrate the
framework's efficacy in producing high-quality analysis with calibrated
confidence levels and actionable investment strategies across multiple time
horizons.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ä¸ªåä¸ºFinDebateçš„å¤šä»£ç†æ¡†æ¶ï¼Œç”¨äºé‡‘èåˆ†æï¼Œç»“åˆäº†åä½œè¾©è®ºå’Œç‰¹å®šé¢†åŸŸçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€‚äº”ä¸ªä¸“ä¸šä»£ç†å¹¶è¡Œå·¥ä½œï¼Œå°†è¯æ®åˆæˆä¸ºå¤šç»´åº¦çš„è§è§£ï¼Œå¹¶é€šè¿‡å®‰å…¨è¾©è®ºåè®®å‡å°‘è¿‡åº¦è‡ªä¿¡å¹¶æé«˜å¯é æ€§ã€‚å®éªŒç»“æœè¡¨æ˜è¯¥æ¡†æ¶èƒ½ç”Ÿæˆé«˜è´¨é‡çš„åˆ†æå’Œå¯æ“ä½œçš„æŠ•èµ„ç­–ç•¥ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-21
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.17197v1">SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing</a></td><td><details><summary>å±•å¼€</summary>Modern signal processing (SP) pipelines, whether model-based or data-driven,
often constrained by complex and fragmented workflow, rely heavily on expert
knowledge and manual engineering, and struggle with adaptability and
generalization under limited data. In contrast, Large Language Models (LLMs)
offer strong reasoning capabilities, broad general-purpose knowledge,
in-context learning, and cross-modal transfer abilities, positioning them as
powerful tools for automating and generalizing SP workflows. Motivated by these
potentials, we introduce SignalLLM, the first general-purpose LLM-based agent
framework for general SP tasks. Unlike prior LLM-based SP approaches that are
limited to narrow applications or tricky prompting, SignalLLM introduces a
principled, modular architecture. It decomposes high-level SP goals into
structured subtasks via in-context learning and domain-specific retrieval,
followed by hierarchical planning through adaptive retrieval-augmented
generation (RAG) and refinement; these subtasks are then executed through
prompt-based reasoning, cross-modal reasoning, code synthesis, model
invocation, or data-driven LLM-assisted modeling. Its generalizable design
enables the flexible selection of problem solving strategies across different
signal modalities, task types, and data conditions. We demonstrate the
versatility and effectiveness of SignalLLM through five representative tasks in
communication and sensing, such as radar target detection, human activity
recognition, and text compression. Experimental results show superior
performance over traditional and existing LLM-based methods, particularly in
few-shot and zero-shot settings.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†SignalLLMï¼Œä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é€šç”¨ä¿¡å·å¤„ç†ï¼ˆSPï¼‰ä»£ç†æ¡†æ¶ï¼Œå®ƒé€šè¿‡å¼•å…¥æ¨¡å—åŒ–æ¶æ„å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ï¼Œå°†é«˜å±‚SPç›®æ ‡åˆ†è§£ä¸ºç»“æ„åŒ–çš„å­ä»»åŠ¡ï¼Œå¹¶ç»“åˆé¢†åŸŸç‰¹å®šæ£€ç´¢ã€åˆ†å±‚è§„åˆ’å’Œå¤šæ¨¡æ€æ¨ç†ï¼Œå®ç°äº†è·¨ä¿¡å·æ¨¡æ€å’Œä»»åŠ¡ç±»å‹çš„çµæ´»é—®é¢˜è§£å†³ã€‚å®éªŒè¯æ˜å…¶åœ¨å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬è®¾å®šä¸‹çš„ä¼˜è¶Šæ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.17066v1">RALLM-POI: Retrieval-Augmented LLM for Zero-shot Next POI Recommendation with Geographical Reranking</a></td><td><details><summary>å±•å¼€</summary>Next point-of-interest (POI) recommendation predicts a user's next
destination from historical movements. Traditional models require intensive
training, while LLMs offer flexible and generalizable zero-shot solutions but
often generate generic or geographically irrelevant results due to missing
trajectory and spatial context. To address these issues, we propose RALLM-POI,
a framework that couples LLMs with retrieval-augmented generation and
self-rectification. We first propose a Historical Trajectory Retriever (HTR)
that retrieves relevant past trajectories to serve as contextual references,
which are then reranked by a Geographical Distance Reranker (GDR) for
prioritizing spatially relevant trajectories. Lastly, an Agentic LLM Rectifier
(ALR) is designed to refine outputs through self-reflection. Without additional
training, RALLM-POI achieves substantial accuracy gains across three real-world
Foursquare datasets, outperforming both conventional and LLM-based baselines.
Code is released at https://github.com/LKRcrocodile/RALLM-POI.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºRALLM-POIæ¡†æ¶ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œè‡ªçŸ«æ­£æŠ€æœ¯æ”¹è¿›åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸‹ä¸€ä¸ªå…´è¶£ç‚¹ï¼ˆPOIï¼‰æ¨èã€‚æ¡†æ¶åŒ…å«å†å²è½¨è¿¹æ£€ç´¢å™¨ï¼ˆHTRï¼‰ã€åœ°ç†è·ç¦»é‡æ’åºå™¨ï¼ˆGDRï¼‰å’ŒLLMä»£ç†çŸ«æ­£å™¨ï¼ˆALRï¼‰ï¼Œåˆ©ç”¨ç›¸å…³è½¨è¿¹ä½œä¸ºä¸Šä¸‹æ–‡è¾“å…¥LLMå¹¶è‡ªæˆ‘ä¼˜åŒ–è¾“å‡ºï¼Œæ— éœ€é¢å¤–è®­ç»ƒå³æ˜¾è‘—æå‡æ¨èå‡†ç¡®æ€§ï¼Œåœ¨Foursquareæ•°æ®é›†ä¸Šè¶…è¶Šä¼ ç»Ÿå’ŒLLMåŸºçº¿æ–¹æ³•ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-20
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.16780v1">Comparing RAG and GraphRAG for Page-Level Retrieval Question Answering on Math Textbook</a></td><td><details><summary>å±•å¼€</summary>Technology-enhanced learning environments often help students retrieve
relevant learning content for questions arising during self-paced study. Large
language models (LLMs) have emerged as novel aids for information retrieval
during learning. While LLMs are effective for general-purpose
question-answering, they typically lack alignment with the domain knowledge of
specific course materials such as textbooks and slides. We investigate
Retrieval-Augmented Generation (RAG) and GraphRAG, a knowledge graph-enhanced
RAG approach, for page-level question answering in an undergraduate mathematics
textbook. While RAG has been effective for retrieving discrete, contextually
relevant passages, GraphRAG may excel in modeling interconnected concepts and
hierarchical knowledge structures. We curate a dataset of 477 question-answer
pairs, each tied to a distinct textbook page. We then compare the standard
embedding-based RAG methods to GraphRAG for evaluating both retrieval
accuracy-whether the correct page is retrieved-and generated answer quality via
F1 scores. Our findings show that embedding-based RAG achieves higher retrieval
accuracy and better F1 scores compared to GraphRAG, which tends to retrieve
excessive and sometimes irrelevant content due to its entity-based structure.
We also explored re-ranking the retrieved pages with LLM and observed mixed
results, including performance drop and hallucinations when dealing with larger
context windows. Overall, this study highlights both the promises and
challenges of page-level retrieval systems in educational contexts, emphasizing
the need for more refined retrieval methods to build reliable AI tutoring
solutions in providing reference page numbers.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ç ”ç©¶äº†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’ŒçŸ¥è¯†å›¾è°±å¢å¼ºçš„GraphRAGæ–¹æ³•åœ¨æœ¬ç§‘æ•°å­¦æ•™ç§‘ä¹¦é¡µçº§é—®ç­”ä¸­çš„åº”ç”¨ï¼Œæ¯”è¾ƒäº†å®ƒä»¬åœ¨æ£€ç´¢å‡†ç¡®æ€§å’Œç”Ÿæˆç­”æ¡ˆè´¨é‡ä¸Šçš„è¡¨ç°ï¼Œå‘ç°åŸºäºåµŒå…¥çš„RAGä¼˜äºGraphRAGï¼Œå¹¶æ¢è®¨äº†æ•™è‚²åœºæ™¯ä¸­æ£€ç´¢ç³»ç»Ÿçš„æ½œåŠ›ä¸æŒ‘æˆ˜ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.16584v1">From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) have demonstrated promising performance on
medical benchmarks; however, their ability to perform medical calculations, a
crucial aspect of clinical decision-making, remains underexplored and poorly
evaluated. Existing benchmarks often assess only the final answer with a wide
numerical tolerance, overlooking systematic reasoning failures and potentially
causing serious clinical misjudgments. In this work, we revisit medical
calculation evaluation with a stronger focus on clinical trustworthiness.
First, we clean and restructure the MedCalc-Bench dataset and propose a new
step-by-step evaluation pipeline that independently assesses formula selection,
entity extraction, and arithmetic computation. Under this granular framework,
the accuracy of GPT-4o drops from 62.7% to 43.6%, revealing errors masked by
prior evaluations. Second, we introduce an automatic error analysis framework
that generates structured attribution for each failure mode. Human evaluation
confirms its alignment with expert judgment, enabling scalable and explainable
diagnostics. Finally, we propose a modular agentic pipeline, MedRaC, that
combines retrieval-augmented generation and Python-based code execution.
Without any fine-tuning, MedRaC improves the accuracy of different LLMs from
16.35% up to 53.19%. Our work highlights the limitations of current benchmark
practices and proposes a more clinically faithful methodology. By enabling
transparent and transferable reasoning evaluation, we move closer to making
LLM-based systems trustworthy for real-world medical applications.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åŒ»å­¦è®¡ç®—ä»»åŠ¡ä¸­çš„æ€§èƒ½é—®é¢˜ï¼Œæå‡ºæ”¹è¿›è¯„ä¼°æ–¹æ³•ï¼ˆMedCalc-Benchæ•°æ®é›†å’Œåˆ†æ­¥è¯„ä¼°æµç¨‹ï¼‰ï¼Œå‘ç°ç°æœ‰è¯„æµ‹æ©ç›–ç³»ç»Ÿæ€§é”™è¯¯ï¼ˆå¦‚GPT-4oå‡†ç¡®ç‡ä»62.7%é™è‡³43.6%ï¼‰ã€‚ä½œè€…å¼€å‘äº†è‡ªåŠ¨é”™è¯¯åˆ†ææ¡†æ¶ï¼Œå¹¶æå‡ºç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’ŒPythonä»£ç æ‰§è¡Œçš„æ¨¡å—åŒ–æµç¨‹MedRaCï¼Œæ˜¾è‘—æå‡ä¸åŒLLMçš„å‡†ç¡®ç‡ï¼ˆæœ€é«˜è¾¾53.19%ï¼‰ã€‚ç ”ç©¶å¼ºè°ƒä¸´åºŠå¯ä¿¡åº¦è¯„ä¼°çš„é‡è¦æ€§ï¼Œæ¨åŠ¨LLMåœ¨çœŸå®åŒ»ç–—åœºæ™¯çš„å¯é åº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.16508v1">Federated Learning with Ad-hoc Adapter Insertions: The Case of Soft-Embeddings for Training Classifier-as-Retriever</a></td><td><details><summary>å±•å¼€</summary>When existing retrieval-augmented generation (RAG) solutions are intended to
be used for new knowledge domains, it is necessary to update their encoders,
which are taken to be pretrained large language models (LLMs). However, fully
finetuning these large models is compute- and memory-intensive, and even
infeasible when deployed on resource-constrained edge devices. We propose a
novel encoder architecture in this work that addresses this limitation by using
a frozen small language model (SLM), which satisfies the memory constraints of
edge devices, and inserting a small adapter network before the transformer
blocks of the SLM. The trainable adapter takes the token embeddings of the new
corpus and learns to produce enhanced soft embeddings for it, while requiring
significantly less compute power to update than full fine-tuning. We further
propose a novel retrieval mechanism by attaching a classifier head to the SLM
encoder, which is trained to learn a similarity mapping of the input embeddings
to their corresponding documents. Finally, to enable the online fine-tuning of
both (i) the encoder soft embeddings and (ii) the classifier-as-retriever on
edge devices, we adopt federated learning (FL) and differential privacy (DP) to
achieve an efficient, privacy-preserving, and product-grade training solution.
We conduct a theoretical analysis of our methodology, establishing convergence
guarantees under mild assumptions on gradient variance when deployed for
general smooth nonconvex loss functions. Through extensive numerical
experiments, we demonstrate (i) the efficacy of obtaining soft embeddings to
enhance the encoder, (ii) training a classifier to improve the retriever, and
(iii) the role of FL in achieving speedup.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡æå‡ºäº†ä¸€ç§é€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡çš„æ–°å‹RAGç¼–ç å™¨æ¶æ„ï¼Œé‡‡ç”¨å†»ç»“çš„å°è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰å’Œé€‚é…å™¨ç½‘ç»œæ¥å‡å°‘è®¡ç®—å’Œå†…å­˜éœ€æ±‚ï¼ŒåŒæ—¶å¼•å…¥åŸºäºåˆ†ç±»å™¨çš„æ£€ç´¢æœºåˆ¶å’Œè”é‚¦å­¦ä¹ ï¼ˆFLï¼‰è¿›è¡Œéšç§ä¿æŠ¤å’Œé«˜æ•ˆåœ¨çº¿å¾®è°ƒï¼Œç†è®ºåˆ†æå’Œå®éªŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.16502v1">GRIL: Knowledge Graph Retrieval-Integrated Learning with Large Language Models</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) has significantly mitigated the
hallucinations of Large Language Models (LLMs) by grounding the generation with
external knowledge. Recent extensions of RAG to graph-based retrieval offer a
promising direction, leveraging the structural knowledge for multi-hop
reasoning. However, existing graph RAG typically decouples retrieval and
reasoning processes, which prevents the retriever from adapting to the
reasoning needs of the LLM. They also struggle with scalability when performing
multi-hop expansion over large-scale graphs, or depend heavily on annotated
ground-truth entities, which are often unavailable in open-domain settings. To
address these challenges, we propose a novel graph retriever trained end-to-end
with LLM, which features an attention-based growing and pruning mechanism,
adaptively navigating multi-hop relevant entities while filtering out noise.
Within the extracted subgraph, structural knowledge and semantic features are
encoded via soft tokens and the verbalized graph, respectively, which are
infused into the LLM together, thereby enhancing its reasoning capability and
facilitating interactive joint training of the graph retriever and the LLM
reasoner. Experimental results across three QA benchmarks show that our
approach consistently achieves state-of-the-art performance, validating the
strength of joint graph-LLM optimization for complex reasoning tasks. Notably,
our framework eliminates the need for predefined ground-truth entities by
directly optimizing the retriever using LLM logits as implicit feedback, making
it especially effective in open-domain settings.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç«¯åˆ°ç«¯è®­ç»ƒæ–¹æ³•ï¼Œå°†åŸºäºå›¾çš„æ£€ç´¢å™¨ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è”åˆä¼˜åŒ–ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€å¯¼èˆªå¤šè·³ç›¸å…³å®ä½“å¹¶è¿‡æ»¤å™ªå£°ï¼ŒåŒæ—¶èåˆç»“æ„çŸ¥è¯†å’Œè¯­ä¹‰ç‰¹å¾ä»¥å¢å¼ºLLMçš„æ¨ç†èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†å¼€æ”¾é¢†åŸŸå¤æ‚é—®ç­”ä»»åŠ¡çš„è¡¨ç°ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-19
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.16112v1">CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion</a></td><td><details><summary>å±•å¼€</summary>Repository-level code completion automatically predicts the unfinished code
based on the broader information from the repository. Recent strides in Code
Large Language Models (code LLMs) have spurred the development of
repository-level code completion methods, yielding promising results.
Nevertheless, they suffer from issues such as inappropriate query construction,
single-path code retrieval, and misalignment between code retriever and code
LLM. To address these problems, we introduce CodeRAG, a framework tailored to
identify relevant and necessary knowledge for retrieval-augmented
repository-level code completion. Its core components include log probability
guided query construction, multi-path code retrieval, and preference-aligned
BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval
demonstrate that CodeRAG significantly and consistently outperforms
state-of-the-art methods. The implementation of CodeRAG is available at
https://github.com/KDEGroup/CodeRAG.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºCodeRAGçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ä»“åº“çº§ä»£ç è¡¥å…¨æ–¹æ³•ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œå¦‚ä¸æ°å½“çš„æŸ¥è¯¢æ„å»ºã€å•ä¸€è·¯å¾„çš„ä»£ç æ£€ç´¢ä»¥åŠä»£ç æ£€ç´¢å™¨ä¸å¤§è¯­è¨€æ¨¡å‹ä¹‹é—´çš„ä¸å¯¹é½ã€‚CodeRAGé€šè¿‡æ¦‚ç‡å¼•å¯¼çš„æŸ¥è¯¢æ„å»ºã€å¤šè·¯å¾„ä»£ç æ£€ç´¢å’Œåå¥½å¯¹é½çš„BestFité‡æ’åºç­‰æ ¸å¿ƒç»„ä»¶ï¼Œæå‡äº†æ£€ç´¢å¢å¼ºçš„ä»“åº“çº§ä»£ç è¡¥å…¨çš„æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼ŒCodeRAGåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.15883v1">RACap: Relation-Aware Prompting for Lightweight Retrieval-Augmented Image Captioning</a></td><td><details><summary>å±•å¼€</summary>Recent retrieval-augmented image captioning methods incorporate external
knowledge to compensate for the limitations in comprehending complex scenes.
However, current approaches face challenges in relation modeling: (1) the
representation of semantic prompts is too coarse-grained to capture
fine-grained relationships; (2) these methods lack explicit modeling of image
objects and their semantic relationships. To address these limitations, we
propose RACap, a relation-aware retrieval-augmented model for image captioning,
which not only mines structured relation semantics from retrieval captions, but
also identifies heterogeneous objects from the image. RACap effectively
retrieves structured relation features that contain heterogeneous visual
information to enhance the semantic consistency and relational expressiveness.
Experimental results show that RACap, with only 10.8M trainable parameters,
achieves superior performance compared to previous lightweight captioning
models.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºRACapçš„å…³ç³»æ„ŸçŸ¥æ£€ç´¢å¢å¼ºå›¾åƒæè¿°ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡ä»æ£€ç´¢åˆ°çš„æè¿°ä¸­æŒ–æ˜ç»“æ„åŒ–å…³ç³»è¯­ä¹‰å¹¶è¯†åˆ«å›¾åƒä¸­çš„å¼‚æ„å¯¹è±¡ï¼Œä»¥æå‡è¯­ä¹‰ä¸€è‡´æ€§å’Œå…³ç³»è¡¨è¾¾èƒ½åŠ›ï¼Œå®éªŒæ˜¾ç¤ºå…¶åœ¨è½»é‡çº§æ¨¡å‹ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.15577v1">Relevance to Utility: Process-Supervised Rewrite for RAG</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation systems often suffer from a gap between
optimizing retrieval relevance and generative utility: retrieved documents may
be topically relevant but still lack the content needed for effective reasoning
during generation. While existing "bridge" modules attempt to rewrite the
retrieved text for better generation, we show how they fail to capture true
document utility. In this work, we propose R2U, with a key distinction of
directly optimizing to maximize the probability of generating a correct answer
through process supervision. As such direct observation is expensive, we also
propose approximating an efficient distillation pipeline by scaling the
supervision from LLMs, which helps the smaller rewriter model generalize
better. We evaluate our method across multiple open-domain question-answering
benchmarks. The empirical results demonstrate consistent improvements over
strong bridging baselines.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºR2Uçš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³RAGç³»ç»Ÿä¸­æ£€ç´¢ç›¸å…³æ€§ä¸ç”Ÿæˆæ•ˆç”¨ä¹‹é—´çš„ä¸ä¸€è‡´é—®é¢˜ã€‚é€šè¿‡ç›´æ¥ä¼˜åŒ–ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆçš„æ¦‚ç‡ï¼Œå¹¶åˆ©ç”¨LLMçš„ç›‘ç£ä¿¡å·æ¥é«˜æ•ˆè®­ç»ƒè¾ƒå°çš„é‡å†™æ¨¡å‹ï¼Œè®ºæ–‡åœ¨å¤šä¸ªå¼€æ”¾åŸŸé—®ç­”åŸºå‡†æµ‹è¯•ä¸­å±•ç¤ºäº†ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•çš„æ€§èƒ½ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-18
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.15211v1">What's the Best Way to Retrieve Slides? A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques</a></td><td><details><summary>å±•å¼€</summary>Slide decks, serving as digital reports that bridge the gap between
presentation slides and written documents, are a prevalent medium for conveying
information in both academic and corporate settings. Their multimodal nature,
combining text, images, and charts, presents challenges for retrieval-augmented
generation systems, where the quality of retrieval directly impacts downstream
performance. Traditional approaches to slide retrieval often involve separate
indexing of modalities, which can increase complexity and lose contextual
information. This paper investigates various methodologies for effective slide
retrieval, including visual late-interaction embedding models like ColPali, the
use of visual rerankers, and hybrid retrieval techniques that combine dense
retrieval with BM25, further enhanced by textual rerankers and fusion methods
like Reciprocal Rank Fusion. A novel Vision-Language Models-based captioning
pipeline is also evaluated, demonstrating significantly reduced embedding
storage requirements compared to visual late-interaction techniques, alongside
comparable retrieval performance. Our analysis extends to the practical aspects
of these methods, evaluating their runtime performance and storage demands
alongside retrieval efficacy, thus offering practical guidance for the
selection and development of efficient and robust slide retrieval systems for
real-world applications.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¹»ç¯ç‰‡ï¼ˆåŒ…å«æ–‡æœ¬ã€å›¾åƒå’Œå›¾è¡¨ï¼‰çš„é«˜æ•ˆæ£€ç´¢æ–¹æ³•ï¼Œæ¢è®¨äº†è§†è§‰å»¶è¿Ÿäº¤äº’åµŒå…¥æ¨¡å‹ã€è§†è§‰é‡æ’åºå™¨ã€æ··åˆæ£€ç´¢æŠ€æœ¯ï¼ˆç»“åˆç¨ å¯†æ£€ç´¢ä¸BM25ï¼‰ç­‰æ–¹æ¡ˆï¼Œå¹¶æå‡ºåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„æ ‡é¢˜ç”Ÿæˆæµç¨‹ï¼Œåœ¨ä¿è¯æ£€ç´¢æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½å­˜å‚¨éœ€æ±‚ï¼Œä¸ºRAGç³»ç»Ÿä¸­å¹»ç¯ç‰‡æ£€ç´¢çš„å®é™…åº”ç”¨æä¾›æ•ˆèƒ½è¯„ä¼°ä¸å¼€å‘æŒ‡å¯¼ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.15159v1">AIP: Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
retrieving relevant documents from external sources to improve factual accuracy
and verifiability. However, this reliance introduces new attack surfaces within
the retrieval pipeline, beyond the LLM itself. While prior RAG attacks have
exposed such vulnerabilities, they largely rely on manipulating user queries,
which is often infeasible in practice due to fixed or protected user inputs.
This narrow focus overlooks a more realistic and stealthy vector: instructional
prompts, which are widely reused, publicly shared, and rarely audited. Their
implicit trust makes them a compelling target for adversaries to manipulate RAG
behavior covertly.
  We introduce a novel attack for Adversarial Instructional Prompt (AIP) that
exploits adversarial instructional prompts to manipulate RAG outputs by subtly
altering retrieval behavior. By shifting the attack surface to the
instructional prompts, AIP reveals how trusted yet seemingly benign interface
components can be weaponized to degrade system integrity. The attack is crafted
to achieve three goals: (1) naturalness, to evade user detection; (2) utility,
to encourage use of prompts; and (3) robustness, to remain effective across
diverse query variations. We propose a diverse query generation strategy that
simulates realistic linguistic variation in user queries, enabling the
discovery of prompts that generalize across paraphrases and rephrasings.
Building on this, a genetic algorithm-based joint optimization is developed to
evolve adversarial prompts by balancing attack success, clean-task utility, and
stealthiness. Experimental results show that AIP achieves up to 95.23% ASR
while preserving benign functionality. These findings uncover a critical and
previously overlooked vulnerability in RAG systems, emphasizing the need to
reassess the shared instructional prompts.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†RAGç³»ç»Ÿä¸­çš„æ–°å‹æ”»å‡»æ–¹å¼Adversarial Instructional Prompt (AIP)ï¼Œé€šè¿‡æ“çºµå¹¿æ³›å¤ç”¨ä¸”æœªè¢«å®¡è®¡çš„æŒ‡ä»¤æç¤ºï¼ˆè€Œéç›´æ¥ç¯¡æ”¹ç”¨æˆ·æŸ¥è¯¢ï¼‰ï¼Œéšç§˜åœ°æ”¹å˜æ£€ç´¢è¡Œä¸ºä»¥æ“æ§è¾“å‡ºã€‚ç ”ç©¶æå‡ºåŸºäºç”Ÿæˆå¤šæ ·æŸ¥è¯¢å’Œé—ä¼ ç®—æ³•çš„è”åˆä¼˜åŒ–æ–¹æ³•ï¼Œæ­ç¤ºRAGä¸­åŸºäºæŒ‡ä»¤æç¤ºçš„å®‰å…¨æ¼æ´ï¼Œå®éªŒæ˜¾ç¤ºAIPæ”»å‡»æˆåŠŸç‡é«˜è¾¾95.23%ä¸”ä¿æŒæ­£å¸¸åŠŸèƒ½ï¼Œå¼ºè°ƒäº†é‡æ–°è¯„ä¼°å…±äº«æç¤ºé£é™©çš„å¿…è¦æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14956v1">Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems</a></td><td><details><summary>å±•å¼€</summary>This paper proposes a novel architectural framework aimed at enhancing
security and reliability in multi-agent systems (MAS). A central component of
this framework is a network of Sentinel Agents, functioning as a distributed
security layer that integrates techniques such as semantic analysis via large
language models (LLMs), behavioral analytics, retrieval-augmented verification,
and cross-agent anomaly detection. Such agents can potentially oversee
inter-agent communications, identify potential threats, enforce privacy and
access controls, and maintain comprehensive audit records. Complementary to the
idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator
Agent supervises policy implementation, and manages agent participation. In
addition, the Coordinator also ingests alerts from Sentinel Agents. Based on
these alerts, it can adapt policies, isolate or quarantine misbehaving agents,
and contain threats to maintain the integrity of the MAS ecosystem. This
dual-layered security approach, combining the continuous monitoring of Sentinel
Agents with the governance functions of Coordinator Agents, supports dynamic
and adaptive defense mechanisms against a range of threats, including prompt
injection, collusive agent behavior, hallucinations generated by LLMs, privacy
breaches, and coordinated multi-agent attacks. In addition to the architectural
design, we present a simulation study where 162 synthetic attacks of different
families (prompt injection, hallucination, and data exfiltration) were injected
into a multi-agent conversational environment. The Sentinel Agents successfully
detected the attack attempts, confirming the practical feasibility of the
proposed monitoring approach. The framework also offers enhanced system
observability, supports regulatory compliance, and enables policy evolution
over time.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§å¢å¼ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰å®‰å…¨æ€§å’Œå¯é æ€§çš„æ–°å‹æ¶æ„æ¡†æ¶ï¼Œå…¶ä¸­åŒ…å«åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œè¯­ä¹‰åˆ†æã€æ£€ç´¢å¢å¼ºéªŒè¯ç­‰æŠ€æœ¯ã€‚Sentinel Agentsä½œä¸ºåˆ†å¸ƒå¼å®‰å…¨å±‚ç›‘æ§é€šä¿¡å¹¶è¯†åˆ«å¨èƒï¼ŒCoordinator Agentåˆ™å®æ–½ç­–ç•¥ç®¡ç†å’Œå¨èƒå“åº”ï¼Œå¹¶é€šè¿‡ä»¿çœŸéªŒè¯äº†è¯¥æ¡†æ¶å¯¹æŠ—å¤šç§æ”»å‡»ï¼ˆå¦‚æç¤ºæ³¨å…¥ã€å¹»è§‰ç”Ÿæˆï¼‰çš„æœ‰æ•ˆæ€§ã€‚å…¶æ£€ç´¢å¢å¼ºéªŒè¯ï¼ˆretrieval-augmented verificationï¼‰æŠ€æœ¯æ˜ç¡®ä½“ç°äº†RAGçš„åº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14750v1">Enhancing Retrieval Augmentation via Adversarial Collaboration</a></td><td><details><summary>å±•å¼€</summary>Retrieval-augmented Generation (RAG) is a prevalent approach for
domain-specific LLMs, yet it is often plagued by "Retrieval Hallucinations"--a
phenomenon where fine-tuned models fail to recognize and act upon poor-quality
retrieved documents, thus undermining performance. To address this, we propose
the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two
heterogeneous agents: a generalist Detector that identifies knowledge gaps, and
a domain-specialized Resolver that provides precise solutions. Guided by a
moderator, these agents engage in an adversarial collaboration, where the
Detector's persistent questioning challenges the Resolver's expertise. This
dynamic process allows for iterative problem dissection and refined knowledge
retrieval. Extensive experiments show that AC-RAG significantly improves
retrieval accuracy and outperforms state-of-the-art RAG methods across various
vertical domains.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºä¸€ç§åä¸ºAC-RAGçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥å¯¹æŠ—æ€§åä½œæœºåˆ¶ï¼ˆåŒ…å«é€šç”¨æ£€æµ‹å™¨å’Œé¢†åŸŸä¸“å®¶è§£æå™¨ä¸¤ä¸ªå¼‚æ„ä»£ç†ï¼‰ï¼Œæœ‰æ•ˆè§£å†³RAGä¸­å­˜åœ¨çš„"æ£€ç´¢å¹»è§‰"é—®é¢˜ï¼Œå³æ¨¡å‹æ— æ³•è¯†åˆ«ä½è´¨é‡æ£€ç´¢æ–‡æ¡£çš„ç¼ºé™·ã€‚å®éªŒè¡¨æ˜AC-RAGåœ¨æ£€ç´¢å‡†ç¡®æ€§å’Œå‚ç›´é¢†åŸŸæ€§èƒ½ä¸Šè¶…è¶Šç°æœ‰å…ˆè¿›æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14623v1">Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language</a></td><td><details><summary>å±•å¼€</summary>Dynamic energy systems and controls require advanced modeling frameworks to
design and test supervisory and fault tolerant strategies. Modelica is a widely
used equation based language, but developing control modules is labor intensive
and requires specialized expertise. This paper examines the use of large
language models (LLMs) to automate the generation of Control Description
Language modules in the Building Modelica Library as a case study. We developed
a structured workflow that combines standardized prompt scaffolds, library
aware grounding, automated compilation with OpenModelica, and human in the loop
evaluation. Experiments were carried out on four basic logic tasks (And, Or,
Not, and Switch) and five control modules (chiller enable/disable, bypass valve
control, cooling tower fan speed, plant requests, and relief damper control).
The results showed that GPT 4o failed to produce executable Modelica code in
zero shot mode, while Claude Sonnet 4 achieved up to full success for basic
logic blocks with carefully engineered prompts. For control modules, success
rates reached 83 percent, and failed outputs required medium level human repair
(estimated one to eight hours). Retrieval augmented generation often produced
mismatches in module selection (for example, And retrieved as Or), while a
deterministic hard rule search strategy avoided these errors. Human evaluation
also outperformed AI evaluation, since current LLMs cannot assess simulation
results or validate behavioral correctness. Despite these limitations, the LLM
assisted workflow reduced the average development time from 10 to 20 hours down
to 4 to 6 hours per module, corresponding to 40 to 60 percent time savings.
These results highlight both the potential and current limitations of LLM
assisted Modelica generation, and point to future research in pre simulation
validation, stronger grounding, and closed loop evaluation.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯è‡ªåŠ¨åŒ–ç”ŸæˆModelicaæ§åˆ¶æ¨¡å—çš„æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆæ ‡å‡†åŒ–æç¤ºæ¡†æ¶ã€åº“æ„ŸçŸ¥åŸºç¡€ã€è‡ªåŠ¨ç¼–è¯‘å’Œäººå·¥è¯„ä¼°ï¼Œæ˜¾è‘—å‡å°‘äº†å¼€å‘æ—¶é—´ï¼ŒåŒæ—¶æŒ‡å‡ºäº†RAGåœ¨æ¨¡å—é€‰æ‹©ä¸Šçš„å±€é™æ€§ä»¥åŠæœªæ¥æ”¹è¿›æ–¹å‘ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14622v1">Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection</a></td><td><details><summary>å±•å¼€</summary>With the deployment of Large Language Models (LLMs) in interactive
applications, online malicious intent detection has become increasingly
critical. However, existing approaches fall short of handling diverse and
complex user queries in real time. To address these challenges, we introduce
ADRAG (Adversarial Distilled Retrieval-Augmented Guard), a two-stage framework
for robust and efficient online malicious intent detection. In the training
stage, a high-capacity teacher model is trained on adversarially perturbed,
retrieval-augmented inputs to learn robust decision boundaries over diverse and
complex user queries. In the inference stage, a distillation scheduler
transfers the teacher's knowledge into a compact student model, with a
continually updated knowledge base collected online. At deployment, the compact
student model leverages top-K similar safety exemplars retrieved from the
online-updated knowledge base to enable both online and real-time malicious
query detection. Evaluations across ten safety benchmarks demonstrate that
ADRAG, with a 149M-parameter model, achieves 98.5% of WildGuard-7B's
performance, surpasses GPT-4 by 3.3% and Llama-Guard-3-8B by 9.5% on
out-of-distribution detection, while simultaneously delivering up to 5.6x lower
latency at 300 queries per second (QPS) in real-time applications.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ADRAGï¼ˆAdversarial Distilled Retrieval-Augmented Guardï¼‰ï¼Œä¸€ç§ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œå¯¹æŠ—è’¸é¦çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œç”¨äºå®æ—¶åœ¨çº¿æ¶æ„æ„å›¾æ£€æµ‹ã€‚é€šè¿‡è®­ç»ƒé˜¶æ®µåˆ©ç”¨æ£€ç´¢å¢å¼ºçš„å¯¹æŠ—æ‰°åŠ¨è¾“å…¥è®­ç»ƒæ•™å¸ˆæ¨¡å‹ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µå°†çŸ¥è¯†è’¸é¦åˆ°è½»é‡çº§å­¦ç”Ÿæ¨¡å‹ä¸­ï¼Œå…¶åœ¨çº¿æ›´æ–°çš„çŸ¥è¯†åº“æ”¯æŒå®æ—¶æ£€ç´¢Top-Kç›¸ä¼¼å®‰å…¨ç¤ºä¾‹ï¼Œæ˜¾è‘—æå‡äº†æ¶æ„æŸ¥è¯¢æ£€æµ‹çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14608v1">Enterprise AI Must Enforce Participant-Aware Access Control</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) are increasingly deployed in enterprise settings
where they interact with multiple users and are trained or fine-tuned on
sensitive internal data. While fine-tuning enhances performance by
internalizing domain knowledge, it also introduces a critical security risk:
leakage of confidential training data to unauthorized users. These risks are
exacerbated when LLMs are combined with Retrieval-Augmented Generation (RAG)
pipelines that dynamically fetch contextual documents at inference time.
  We demonstrate data exfiltration attacks on AI assistants where adversaries
can exploit current fine-tuning and RAG architectures to leak sensitive
information by leveraging the lack of access control enforcement. We show that
existing defenses, including prompt sanitization, output filtering, system
isolation, and training-level privacy mechanisms, are fundamentally
probabilistic and fail to offer robust protection against such attacks.
  We take the position that only a deterministic and rigorous enforcement of
fine-grained access control during both fine-tuning and RAG-based inference can
reliably prevent the leakage of sensitive data to unauthorized recipients.
  We introduce a framework centered on the principle that any content used in
training, retrieval, or generation by an LLM is explicitly authorized for
\emph{all users involved in the interaction}. Our approach offers a simple yet
powerful paradigm shift for building secure multi-user LLM systems that are
grounded in classical access control but adapted to the unique challenges of
modern AI workflows. Our solution has been deployed in Microsoft Copilot
Tuning, a product offering that enables organizations to fine-tune models using
their own enterprise-specific data.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« æ¢è®¨äº†åœ¨ä¼ä¸šç¯å¢ƒä¸­éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç®¡é“æ—¶é¢ä¸´çš„æ•°æ®å®‰å…¨é£é™©ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç»†ç²’åº¦è®¿é—®æ§åˆ¶çš„æ¡†æ¶ï¼Œä»¥é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ç»™æœªç»æˆæƒçš„ç”¨æˆ·ï¼Œå¹¶å·²åœ¨Microsoft Copilot Tuningä¸­éƒ¨ç½²åº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14507v1">DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction</a></td><td><details><summary>å±•å¼€</summary>Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that
simplifies database access for non-technical users by converting natural
language queries into SQL commands. Recent advancements, particularly those
integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)
reasoning, have made significant strides in enhancing NL2SQL performance.
However, challenges such as inaccurate task decomposition and keyword
extraction by LLMs remain major bottlenecks, often leading to errors in SQL
generation. While existing datasets aim to mitigate these issues by fine-tuning
models, they struggle with over-fragmentation of tasks and lack of
domain-specific keyword annotations, limiting their effectiveness. To address
these limitations, we present DeKeyNLU, a novel dataset which contains 1,500
meticulously annotated QA pairs aimed at refining task decomposition and
enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with
DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three
distinct modules for user question understanding, entity retrieval, and
generation to improve SQL generation accuracy. We benchmarked multiple model
configurations within DeKeySQL RAG pipeline. Experimental results demonstrate
that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy
on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºDeKeyNLUæ•°æ®é›†å’ŒDeKeySQLç®¡é“ï¼Œé€šè¿‡æ”¹è¿›ä»»åŠ¡åˆ†è§£å’Œå…³é”®è¯æå–å¢å¼ºRAGåœ¨è‡ªç„¶è¯­è¨€è½¬SQLï¼ˆNL2SQLï¼‰ä¸­çš„æ€§èƒ½ï¼Œå®éªŒæ˜¾ç¤ºå…¶æ˜¾è‘—æå‡äº†BIRDå’ŒSpideræ•°æ®é›†ä¸Šçš„SQLç”Ÿæˆå‡†ç¡®ç‡ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-17
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.14436v1">When Content is Goliath and Algorithm is David: The Style and Semantic Effects of Generative Search Engine</a></td><td><details><summary>å±•å¼€</summary>Generative search engines (GEs) leverage large language models (LLMs) to
deliver AI-generated summaries with website citations, establishing novel
traffic acquisition channels while fundamentally altering the search engine
optimization landscape. To investigate the distinctive characteristics of GEs,
we collect data through interactions with Google's generative and conventional
search platforms, compiling a dataset of approximately ten thousand websites
across both channels. Our empirical analysis reveals that GEs exhibit
preferences for citing content characterized by significantly higher
predictability for underlying LLMs and greater semantic similarity among
selected sources. Through controlled experiments utilizing retrieval augmented
generation (RAG) APIs, we demonstrate that these citation preferences emerge
from intrinsic LLM tendencies to favor content aligned with their generative
expression patterns. Motivated by applications of LLMs to optimize website
content, we conduct additional experimentation to explore how LLM-based content
polishing by website proprietors alters AI summaries, finding that such
polishing paradoxically enhances information diversity within AI summaries.
Finally, to assess the user-end impact of LLM-induced information increases, we
design a generative search engine and recruit Prolific participants to conduct
a randomized controlled experiment involving an information-seeking and writing
task. We find that higher-educated users exhibit minimal changes in their final
outputs' information diversity but demonstrate significantly reduced task
completion time when original sites undergo polishing. Conversely,
lower-educated users primarily benefit through enhanced information density in
their task outputs while maintaining similar completion times across
experimental groups.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡ç ”ç©¶ç”Ÿæˆå¼æœç´¢å¼•æ“ï¼ˆGEsï¼‰çš„ç‰¹ç‚¹åŠå…¶å¼•ç”¨åå¥½ï¼Œå‘ç°GEså€¾å‘äºå¼•ç”¨ä¸åº•å±‚LLMç”Ÿæˆè¡¨è¾¾æ¨¡å¼ä¸€è‡´çš„å†…å®¹ï¼Œå¹¶é€šè¿‡RAG APIå®éªŒéªŒè¯äº†è¿™ä¸€åå¥½æºè‡ªLLMçš„å†…åœ¨å€¾å‘ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢è®¨äº†ç½‘ç«™æ‰€æœ‰è€…é€šè¿‡LLMä¼˜åŒ–å†…å®¹å¯¹AIæ‘˜è¦çš„å½±å“ï¼Œå¹¶è¯„ä¼°äº†ä¸åŒæ•™è‚²èƒŒæ™¯ç”¨æˆ·åœ¨ä½¿ç”¨GEsæ—¶çš„è¡¨ç°å·®å¼‚ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14435v1">Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) have transformed natural language processing
(NLP), enabling diverse applications by integrating large-scale pre-trained
knowledge. However, their static knowledge limits dynamic reasoning over
external information, especially in knowledge-intensive domains.
Retrieval-Augmented Generation (RAG) addresses this challenge by combining
retrieval mechanisms with generative modeling to improve contextual
understanding. Traditional RAG systems suffer from disrupted contextual
integrity due to text chunking and over-reliance on semantic similarity for
retrieval, often resulting in shallow and less accurate responses. We propose
Causal-Counterfactual RAG, a novel framework that integrates explicit causal
graphs representing cause-effect relationships into the retrieval process and
incorporates counterfactual reasoning grounded on the causal structure. Unlike
conventional methods, our framework evaluates not only direct causal evidence
but also the counterfactuality of associated causes, combining results from
both to generate more robust, accurate, and interpretable answers. By
leveraging causal pathways and associated hypothetical scenarios,
Causal-Counterfactual RAG preserves contextual coherence, reduces
hallucination, and enhances reasoning fidelity.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºCausal-Counterfactual RAGçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡å°†æ˜¾å¼å› æœå›¾æ•´åˆåˆ°æ£€ç´¢è¿‡ç¨‹ä¸­å¹¶å¼•å…¥åŸºäºå› æœç»“æ„çš„åäº‹å®æ¨ç†ï¼Œè§£å†³äº†ä¼ ç»ŸRAGç³»ç»Ÿå› æ–‡æœ¬åˆ†å—å’Œè¿‡åº¦ä¾èµ–è¯­ä¹‰ç›¸ä¼¼æ€§è€Œå¯¼è‡´çš„ä¸Šä¸‹æ–‡ä¸è¿è´¯å’Œå›ç­”æµ…æ˜¾çš„é—®é¢˜ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®ã€é²æ£’ä¸”å¯è§£é‡Šçš„ç­”æ¡ˆã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13978v1">LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology</a></td><td><details><summary>å±•å¼€</summary>Modern scientific discovery increasingly relies on workflows that process
data across the Edge, Cloud, and High Performance Computing (HPC) continuum.
Comprehensive and in-depth analyses of these data are critical for hypothesis
validation, anomaly detection, reproducibility, and impactful findings.
Although workflow provenance techniques support such analyses, at large scale,
the provenance data become complex and difficult to analyze. Existing systems
depend on custom scripts, structured queries, or static dashboards, limiting
data interaction. In this work, we introduce an evaluation methodology,
reference architecture, and open-source implementation that leverages
interactive Large Language Model (LLM) agents for runtime data analysis. Our
approach uses a lightweight, metadata-driven design that translates natural
language into structured provenance queries. Evaluations across LLaMA, GPT,
Gemini, and Claude, covering diverse query classes and a real-world chemistry
workflow, show that modular design, prompt tuning, and Retrieval-Augmented
Generation (RAG) enable accurate and insightful LLM agent responses beyond
recorded provenance.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨äº¤äº’å¼å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†è¿›è¡Œè¿è¡Œæ—¶æ•°æ®åˆ†æçš„æ–¹æ³•ï¼Œé‡‡ç”¨è½»é‡çº§ã€ä»¥å…ƒæ•°æ®é©±åŠ¨çš„è®¾è®¡å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºç»“æ„åŒ–çš„æº¯æºæŸ¥è¯¢ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å®éªŒï¼ˆæ¶µç›–å¤šç§LLMæ¨¡å‹åŠå®é™…åŒ–å­¦å·¥ä½œæµï¼‰è¯æ˜ï¼Œå…¶æ¨¡å—åŒ–è®¾è®¡ã€æç¤ºè°ƒä¼˜åŠæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯èƒ½æ˜¾è‘—æå‡LLMä»£ç†å“åº”çš„å‡†ç¡®æ€§å’Œæ´å¯ŸåŠ›ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿè®°å½•çš„æº¯æºæ•°æ®èƒ½åŠ›ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13930v1">Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG</a></td><td><details><summary>å±•å¼€</summary>Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡ç ”ç©¶å¤šè¯­è¨€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆmRAGï¼‰ç³»ç»Ÿä¸­è¯­è¨€åå¥½å¯¹ç”Ÿæˆå’Œå¼•ç”¨çš„å½±å“ï¼Œå‘ç°æ¨¡å‹å€¾å‘äºå¼•ç”¨è‹±æ–‡æ¥æºï¼Œä¸”å¯èƒ½ç‰ºç‰²æ–‡æ¡£ç›¸å…³æ€§è€Œé€‰æ‹©è¯­è¨€åå¥½ï¼Œæ­ç¤ºäº†è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€è¯­å¢ƒä¸­çš„å¼•ç”¨è¡Œä¸ºç‰¹ç‚¹ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13772v1">Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) integrates external knowledge into large
language models to improve response quality. However, recent work has shown
that RAG systems are highly vulnerable to poisoning attacks, where malicious
texts are inserted into the knowledge database to influence model outputs.
While several defenses have been proposed, they are often circumvented by more
adaptive or sophisticated attacks.
  This paper presents RAGOrigin, a black-box responsibility attribution
framework designed to identify which texts in the knowledge database are
responsible for misleading or incorrect generations. Our method constructs a
focused attribution scope tailored to each misgeneration event and assigns a
responsibility score to each candidate text by evaluating its retrieval
ranking, semantic relevance, and influence on the generated response. The
system then isolates poisoned texts using an unsupervised clustering method. We
evaluate RAGOrigin across seven datasets and fifteen poisoning attacks,
including newly developed adaptive poisoning strategies and multi-attacker
scenarios. Our approach outperforms existing baselines in identifying poisoned
content and remains robust under dynamic and noisy conditions. These results
suggest that RAGOrigin provides a practical and effective solution for tracing
the origins of corrupted knowledge in RAG systems.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡æå‡ºRAGOriginæ¡†æ¶ï¼Œé’ˆå¯¹RAGç³»ç»Ÿä¸­çŸ¥è¯†åº“ä¸­æ¯’æ”»å‡»å¯¼è‡´é”™è¯¯ç”Ÿæˆçš„é—®é¢˜ï¼Œé€šè¿‡é»‘ç›’è´£ä»»æº¯æºæ–¹æ³•åˆ†ææ£€ç´¢æ’åºã€è¯­ä¹‰ç›¸å…³æ€§å’Œç”Ÿæˆå“åº”å½±å“ï¼Œè¯†åˆ«å’Œéš”ç¦»æ¶æ„æ–‡æœ¬ï¼Œå¹¶åœ¨å¤šæ•°æ®é›†å’Œæ”»å‡»åœºæ™¯ä¸‹éªŒè¯å…¶ä¼˜äºç°æœ‰åŸºçº¿ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13702v1">DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models</a></td><td><details><summary>å±•å¼€</summary>Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºDSCC-HSçš„æ–°å‹ä¸»åŠ¨å¼æ¡†æ¶ï¼Œé€šè¿‡åŠ¨æ€è‡ªæˆ‘å¼ºåŒ–æ ¡å‡†æ¥æŠ‘åˆ¶LLMçš„å¹»è§‰é—®é¢˜ï¼Œé‡‡ç”¨åŒä»£ç†æ¨¡å‹ï¼ˆFAPå’ŒHDPï¼‰åœ¨è‡ªå›å½’è§£ç è¿‡ç¨‹ä¸­å®æ—¶ä¿®æ­£ç›®æ ‡æ¨¡å‹çš„è¾“å‡ºã€‚å°½ç®¡å±äºRAGç›¸å…³ç ”ç©¶ï¼ˆæåˆ°RAGä½œä¸ºç°æœ‰æ–¹æ³•å¯¹æ¯”ï¼‰ï¼Œä½†å…¶æ ¸å¿ƒåˆ›æ–°ç‚¹åœ¨äºä¸ä¾èµ–å¤–éƒ¨æ£€ç´¢çš„ä¸»åŠ¨å¹²é¢„æœºåˆ¶ï¼Œå®éªŒè¯æ˜åœ¨TruthfulQAå’ŒBioGENåŸºå‡†ä¸­æ˜¾è‘—æå‡äº†ç”Ÿæˆå†…å®¹çš„çœŸå®æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13683v1">Improving Context Fidelity via Native Retrieval-Augmented Reasoning</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†CAREæ¡†æ¶ï¼Œé€šè¿‡è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ˜¾å¼æ•´åˆä¸Šä¸‹æ–‡è¯æ®å¹¶ç»“åˆè‡ªèº«æ£€ç´¢èƒ½åŠ›ï¼Œæ”¹è¿›äº†ä¼ ç»Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢å‡†ç¡®æ€§å’Œç­”æ¡ˆç”Ÿæˆæ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šé¡¹QAåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºç›‘ç£å¾®è°ƒå’Œå¤–éƒ¨æ£€ç´¢æ–¹æ¡ˆï¼Œå¢å¼ºäº†LLMsåœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13626v1">Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval</a></td><td><details><summary>å±•å¼€</summary>Access to reliable mental health information is vital for early help-seeking,
yet expanding knowledge bases is resource-intensive and often misaligned with
user needs. This results in poor performance of retrieval systems when
presented concerns are not covered or expressed in informal or contextualized
language. We present an AI-based gap-informed framework for corpus augmentation
that authentically identifies underrepresented topics (gaps) by overlaying
naturalistic user data such as forum posts in order to prioritize expansions
based on coverage and usefulness. In a case study, we compare Directed
(gap-informed augmentations) with Non-Directed augmentation (random additions),
evaluating the relevance and usefulness of retrieved information across four
retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved
near-optimal performance with modest expansions--requiring only a 42% increase
for Query Transformation, 74% for Reranking and Hierarchical, and 318% for
Baseline--to reach ~95% of the performance of an exhaustive reference corpus.
In contrast, Non-Directed augmentation required substantially larger and thus
practically infeasible expansions to achieve comparable performance (232%,
318%, 403%, and 763%, respectively). These results show that strategically
targeted corpus growth can reduce content creation demands while sustaining
high retrieval and provision quality, offering a scalable approach for building
trusted health information repositories and supporting generative AI
applications in high-stakes domains.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºAIçš„æ¡†æ¶ï¼Œé€šè¿‡è¯†åˆ«æœªå……åˆ†è¦†ç›–çš„ä¸»é¢˜ï¼ˆç¼ºå£ï¼‰æ¥å¢å¼ºè¯­æ–™åº“ï¼Œå¹¶è¯„ä¼°äº†å…¶åœ¨å››ç§æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç®¡é“ä¸­çš„æ•ˆæœï¼Œç»“æœæ˜¾ç¤ºå®šå‘å¢å¼ºèƒ½ä»¥è¾ƒå°çš„æ‰©å±•è¾¾åˆ°æ¥è¿‘æœ€ä¼˜çš„æ£€ç´¢æ€§èƒ½ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-16
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.12765v1">InfoGain-RAG: Boosting Retrieval-Augmented Generation via Document Information Gain-based Reranking and Filtering</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
address key limitations of Large Language Models (LLMs), such as hallucination,
outdated knowledge, and lacking reference. However, current RAG frameworks
often struggle with identifying whether retrieved documents meaningfully
contribute to answer generation. This shortcoming makes it difficult to filter
out irrelevant or even misleading content, which notably impacts the final
performance. In this paper, we propose Document Information Gain (DIG), a novel
metric designed to quantify the contribution of retrieved documents to correct
answer generation. DIG measures a document's value by computing the difference
of LLM's generation confidence with and without the document augmented.
Further, we introduce InfoGain-RAG, a framework that leverages DIG scores to
train a specialized reranker, which prioritizes each retrieved document from
exact distinguishing and accurate sorting perspectives. This approach can
effectively filter out irrelevant documents and select the most valuable ones
for better answer generation. Extensive experiments across various models and
benchmarks demonstrate that InfoGain-RAG can significantly outperform existing
approaches, on both single and multiple retrievers paradigm. Specifically on
NaturalQA, it achieves the improvements of 17.9%, 4.5%, 12.5% in exact match
accuracy against naive RAG, self-reflective RAG and modern ranking-based RAG
respectively, and even an average of 15.3% increment on advanced proprietary
model GPT-4o across all datasets. These results demonstrate the feasibility of
InfoGain-RAG as it can offer a reliable solution for RAG in multiple
applications.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œæ–‡æ¡£ä¿¡æ¯å¢ç›Šï¼ˆDIGï¼‰â€çš„æ–°æŒ‡æ ‡ï¼Œç”¨äºé‡åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£å¯¹ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆçš„è´¡çŒ®ï¼Œå¹¶è¿›ä¸€æ­¥ä»‹ç»äº†åŸºäºDIGçš„InfoGain-RAGæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡è®­ç»ƒä¸“é—¨çš„é‡æ–°æ’åºæ¨¡å‹æ¥ä¼˜å…ˆé€‰æ‹©æœ€æœ‰ä»·å€¼çš„æ–‡æ¡£ï¼Œæ˜¾è‘—æå‡äº†RAGçš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12743v1">Zero-shot Graph Reasoning via Retrieval Augmented Framework with LLMs</a></td><td><details><summary>å±•å¼€</summary>We propose a new, training-free method, Graph Reasoning via Retrieval
Augmented Framework (GRRAF), that harnesses retrieval-augmented generation
(RAG) alongside the code-generation capabilities of large language models
(LLMs) to address a wide range of graph reasoning tasks. In GRRAF, the target
graph is stored in a graph database, and the LLM is prompted to generate
executable code queries that retrieve the necessary information. This approach
circumvents the limitations of existing methods that require extensive
finetuning or depend on predefined algorithms, and it incorporates an error
feedback loop with a time-out mechanism to ensure both correctness and
efficiency. Experimental evaluations on the GraphInstruct dataset reveal that
GRRAF achieves 100% accuracy on most graph reasoning tasks, including cycle
detection, bipartite graph checks, shortest path computation, and maximum flow,
while maintaining consistent token costs regardless of graph sizes. Imperfect
but still very high performance is observed on subgraph matching. Notably,
GRRAF scales effectively to large graphs with up to 10,000 nodes.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºGRRAFçš„æ–°å‹å…è®­ç»ƒæ–¹æ³•ï¼Œåˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä»£ç ç”Ÿæˆèƒ½åŠ›æ¥è§£å†³å¹¿æ³›çš„å›¾æ¨ç†ä»»åŠ¡ã€‚GRRAFé€šè¿‡å°†ç›®æ ‡å›¾å­˜å‚¨åœ¨å›¾å½¢æ•°æ®åº“ä¸­ï¼Œå¹¶æç¤ºLLMç”Ÿæˆå¯æ‰§è¡Œçš„ä»£ç æŸ¥è¯¢æ¥æ£€ç´¢å¿…è¦ä¿¡æ¯ï¼Œä»è€Œé¿å…äº†ç°æœ‰æ–¹æ³•éœ€è¦å¤§é‡å¾®è°ƒæˆ–ä¾èµ–é¢„å®šä¹‰ç®—æ³•çš„é™åˆ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGRRAFåœ¨å¤§å¤šæ•°å›¾æ¨ç†ä»»åŠ¡ä¸Šå®ç°äº†100%çš„å‡†ç¡®ç‡ï¼Œå¹¶èƒ½æœ‰æ•ˆæ‰©å±•åˆ°åŒ…å«å¤šè¾¾10,000ä¸ªèŠ‚ç‚¹çš„å¤§å‹å›¾ä¸­ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12653v1">Beyond Artificial Misalignment: Detecting and Grounding Semantic-Coordinated Multimodal Manipulations</a></td><td><details><summary>å±•å¼€</summary>The detection and grounding of manipulated content in multimodal data has
emerged as a critical challenge in media forensics. While existing benchmarks
demonstrate technical progress, they suffer from misalignment artifacts that
poorly reflect real-world manipulation patterns: practical attacks typically
maintain semantic consistency across modalities, whereas current datasets
artificially disrupt cross-modal alignment, creating easily detectable
anomalies. To bridge this gap, we pioneer the detection of
semantically-coordinated manipulations where visual edits are systematically
paired with semantically consistent textual descriptions. Our approach begins
with constructing the first Semantic-Aligned Multimodal Manipulation (SAMM)
dataset, generated through a two-stage pipeline: 1) applying state-of-the-art
image manipulations, followed by 2) generation of contextually-plausible
textual narratives that reinforce the visual deception. Building on this
foundation, we propose a Retrieval-Augmented Manipulation Detection and
Grounding (RamDG) framework. RamDG commences by harnessing external knowledge
repositories to retrieve contextual evidence, which serves as the auxiliary
texts and encoded together with the inputs through our image forgery grounding
and deep manipulation detection modules to trace all manipulations. Extensive
experiments demonstrate our framework significantly outperforms existing
methods, achieving 2.06\% higher detection accuracy on SAMM compared to
state-of-the-art approaches. The dataset and code are publicly available at
https://github.com/shen8424/SAMM-RamDG-CAP.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºRAMDGçš„æ£€ç´¢å¢å¼ºå¤šæ¨¡æ€ç¯¡æ”¹æ£€æµ‹ä¸å®šä½æ¡†æ¶ï¼Œé€šè¿‡æ„å»ºè¯­ä¹‰å¯¹é½çš„å¤šæ¨¡æ€ç¯¡æ”¹æ•°æ®é›†ï¼ˆSAMMï¼‰å¹¶åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢è¾…åŠ©è¯æ®ï¼Œæ˜¾è‘—æå‡äº†ç¯¡æ”¹æ£€æµ‹çš„å‡†ç¡®ç‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12589v1">Redefining CX with Agentic AI: Minerva CQ Case Study</a></td><td><details><summary>å±•å¼€</summary>Despite advances in AI for contact centers, customer experience (CX)
continues to suffer from high average handling time (AHT), low first-call
resolution, and poor customer satisfaction (CSAT). A key driver is the
cognitive load on agents, who must navigate fragmented systems, troubleshoot
manually, and frequently place customers on hold. Existing AI-powered
agent-assist tools are often reactive driven by static rules, simple prompting,
or retrieval-augmented generation (RAG) without deeper contextual reasoning. We
introduce Agentic AI goal-driven, autonomous, tool-using systems that
proactively support agents in real time. Unlike conventional approaches,
Agentic AI identifies customer intent, triggers modular workflows, maintains
evolving context, and adapts dynamically to conversation state. This paper
presents a case study of Minerva CQ, a real-time Agent Assist product deployed
in voice-based customer support. Minerva CQ integrates real-time transcription,
intent and sentiment detection, entity recognition, contextual retrieval,
dynamic customer profiling, and partial conversational summaries enabling
proactive workflows and continuous context-building. Deployed in live
production, Minerva CQ acts as an AI co-pilot, delivering measurable
improvements in agent efficiency and customer experience across multiple
deployments.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†Agentic AIåœ¨å®¢æœä¸­å¿ƒçš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯Minerva CQäº§å“ï¼Œå®ƒç»“åˆäº†å®æ—¶è½¬å½•ã€æ„å›¾è¯†åˆ«å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­‰æŠ€æœ¯ï¼Œé€šè¿‡åŠ¨æ€ä¸Šä¸‹æ–‡å’Œå·¥ä½œæµæå‡å®¢æœä»£ç†æ•ˆç‡åŠå®¢æˆ·ä½“éªŒã€‚å°½ç®¡RAGæ˜¯ç°æœ‰æŠ€æœ¯ä¹‹ä¸€ï¼Œä½†æ–‡ç« é‡ç‚¹å¼ºè°ƒå…¶è¶…è¶Šä¼ ç»ŸRAGçš„è‡ªä¸»æ€§å’Œå®æ—¶æ€§èƒ½åŠ›ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-15
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.12382v1">LLM-as-a-Judge: Rapid Evaluation of Legal Document Recommendation for Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>The evaluation bottleneck in recommendation systems has become particularly
acute with the rise of Generative AI, where traditional metrics fall short of
capturing nuanced quality dimensions that matter in specialized domains like
legal research. Can we trust Large Language Models to serve as reliable judges
of their own kind? This paper investigates LLM-as-a-Judge as a principled
approach to evaluating Retrieval-Augmented Generation systems in legal
contexts, where the stakes of recommendation quality are exceptionally high.
  We tackle two fundamental questions that determine practical viability: which
inter-rater reliability metrics best capture the alignment between LLM and
human assessments, and how do we conduct statistically sound comparisons
between competing systems? Through systematic experimentation, we discover that
traditional agreement metrics like Krippendorff's alpha can be misleading in
the skewed distributions typical of AI system evaluations. Instead, Gwet's AC2
and rank correlation coefficients emerge as more robust indicators for judge
selection, while the Wilcoxon Signed-Rank Test with Benjamini-Hochberg
corrections provides the statistical rigor needed for reliable system
comparisons.
  Our findings suggest a path toward scalable, cost-effective evaluation that
maintains the precision demanded by legal applications, transforming what was
once a human-intensive bottleneck into an automated, yet statistically
principled, evaluation framework.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†åœ¨æ¨èç³»ç»Ÿä¸­åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè¯„ä¼°å·¥å…·çš„å¯è¡Œæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ³•å¾‹æ£€ç´¢ä¸ç”Ÿæˆï¼ˆRAGï¼‰é¢†åŸŸã€‚ç ”ç©¶é‡ç‚¹å…³æ³¨å¦‚ä½•é€‰æ‹©å¯ä¿¡çš„æŒ‡æ ‡ï¼ˆå¦‚Gwet's AC2å’Œç§©ç›¸å…³ç³»æ•°ï¼‰å’Œç»Ÿè®¡æ–¹æ³•ï¼ˆå¦‚Wilcoxon Signed-Rank Testï¼‰æ¥å¯¹é½LLMä¸äººç±»è¯„ä¼°ç»“æœï¼Œä»è€Œä¸ºé«˜é£é™©çš„RAGç³»ç»Ÿæä¾›å¯æ‰©å±•ä¸”ç²¾å‡†çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12168v1">RAGs to Riches: RAG-like Few-shot Learning for Large Language Model Role-playing</a></td><td><details><summary>å±•å¼€</summary>Role-playing Large language models (LLMs) are increasingly deployed in
high-stakes domains such as healthcare, education, and governance, where
failures can directly impact user trust and well-being. A cost effective
paradigm for LLM role-playing is few-shot learning, but existing approaches
often cause models to break character in unexpected and potentially harmful
ways, especially when interacting with hostile users. Inspired by
Retrieval-Augmented Generation (RAG), we reformulate LLM role-playing into a
text retrieval problem and propose a new prompting framework called
RAGs-to-Riches, which leverages curated reference demonstrations to condition
LLM responses. We evaluate our framework with LLM-as-a-judge preference voting
and introduce two novel token-level ROUGE metrics: Intersection over Output
(IOO) to quantity how much an LLM improvises and Intersection over References
(IOR) to measure few-shot demonstrations utilization rate during the evaluation
tasks. When simulating interactions with a hostile user, our prompting strategy
incorporates in its responses during inference an average of 35% more tokens
from the reference demonstrations. As a result, across 453 role-playing
interactions, our models are consistently judged as being more authentic, and
remain in-character more often than zero-shot and in-context Learning (ICL)
methods. Our method presents a scalable strategy for building robust,
human-aligned LLM role-playing frameworks.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºRAGs-to-Richesçš„æç¤ºæ¡†æ¶ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è§’è‰²æ‰®æ¼”é‡æ–°æ„å»ºä¸ºæ–‡æœ¬æ£€ç´¢é—®é¢˜ï¼Œé€šè¿‡åˆ©ç”¨ç²¾å¿ƒç­–åˆ’çš„å‚è€ƒæ¼”ç¤ºæ¥è°ƒèŠ‚LLMçš„å“åº”ã€‚è¯¥æ¡†æ¶åœ¨å¯¹æŠ—æ€§ç”¨æˆ·äº’åŠ¨ä¸­è¡¨ç°æ›´ä¼˜ï¼Œèƒ½æ›´æœ‰æ•ˆåœ°åˆ©ç”¨å‚è€ƒæ¼”ç¤ºï¼Œæé«˜è§’è‰²çš„çœŸå®æ€§å’Œä¸€è‡´æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12086v1">SAQ: Pushing the Limits of Vector Quantization through Code Adjustment and Dimension Segmentation</a></td><td><details><summary>å±•å¼€</summary>Approximate Nearest Neighbor Search (ANNS) plays a critical role in
applications such as search engines, recommender systems, and RAG for LLMs.
Vector quantization (VQ), a crucial technique for ANNS, is commonly used to
reduce space overhead and accelerate distance computations. However, despite
significant research advances, state-of-the-art VQ methods still face
challenges in balancing encoding efficiency and quantization accuracy. To
address these limitations, we propose a novel VQ method called SAQ. To improve
accuracy, SAQ employs a new dimension segmentation technique to strategically
partition PCA-projected vectors into segments along their dimensions. By
prioritizing leading dimension segments with larger magnitudes, SAQ allocates
more bits to high-impact segments, optimizing the use of the available space
quota. An efficient dynamic programming algorithm is developed to optimize
dimension segmentation and bit allocation, ensuring minimal quantization error.
To speed up vector encoding, SAQ devises a code adjustment technique to first
quantize each dimension independently and then progressively refine quantized
vectors using a coordinate-descent-like approach to avoid exhaustive
enumeration. Extensive experiments demonstrate SAQ's superiority over classical
methods (e.g., PQ, PCA) and recent state-of-the-art approaches (e.g., LVQ,
Extended RabitQ). SAQ achieves up to 80% reduction in quantization error and
accelerates encoding speed by over 80x compared to Extended RabitQ.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºSAQçš„æ–°å‹å‘é‡é‡åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨æ”¹è¿›è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ï¼ˆANNSï¼‰ä¸­çš„ç¼–ç æ•ˆç‡å’Œé‡åŒ–ç²¾åº¦å¹³è¡¡é—®é¢˜ï¼Œé€šè¿‡ç»´åº¦åˆ†å‰²å’ŒåŠ¨æ€ç¼–ç¨‹ä¼˜åŒ–æŠ€æœ¯æ˜¾è‘—é™ä½é‡åŒ–è¯¯å·®å¹¶åŠ é€Ÿç¼–ç é€Ÿåº¦ï¼Œç›´æ¥å…³è”å¹¶ä¼˜åŒ–äº†RAGæŠ€æœ¯ä¸­æ£€ç´¢ç¯èŠ‚çš„æ ¸å¿ƒæ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12042v1">FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval</a></td><td><details><summary>å±•å¼€</summary>Financial disclosures such as 10-K filings present challenging retrieval
problems due to their length, regulatory section hierarchy, and domain-specific
language, which standard retrieval-augmented generation (RAG) models underuse.
We introduce FinGEAR (Financial Mapping-Guided Enhanced Answer Retrieval), a
retrieval framework tailored to financial documents. FinGEAR combines a finance
lexicon for Item-level guidance (FLAM), dual hierarchical indices for
within-Item search (Summary Tree and Question Tree), and a two-stage
cross-encoder reranker. This design aligns retrieval with disclosure structure
and terminology, enabling fine-grained, query-aware context selection.
Evaluated on full 10-Ks with queries aligned to the FinQA dataset, FinGEAR
delivers consistent gains in precision, recall, F1, and relevancy, improving F1
by up to 56.7% over flat RAG, 12.5% over graph-based RAGs, and 217.6% over
prior tree-based systems, while also increasing downstream answer accuracy with
a fixed reader. By jointly modeling section hierarchy and domain lexicon
signals, FinGEAR improves retrieval fidelity and provides a practical
foundation for high-stakes financial analysis.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†FinGEARï¼Œä¸€ä¸ªé’ˆå¯¹é‡‘èæ–‡æ¡£ï¼ˆå¦‚10-Kæ–‡ä»¶ï¼‰ä¼˜åŒ–çš„æ£€ç´¢æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆé‡‘èè¯æ±‡è¡¨ï¼ˆFLAMï¼‰ã€åŒé‡å±‚æ¬¡ç´¢å¼•å’Œä¸¤é˜¶æ®µäº¤å‰ç¼–ç å™¨é‡æ’å™¨ï¼Œæ”¹è¿›äº†ä¼ ç»ŸRAGæ¨¡å‹åœ¨é‡‘èé¢†åŸŸçš„æ£€ç´¢æ•ˆæœï¼Œæ˜¾è‘—æå‡äº†ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œä¸‹æ¸¸ç­”æ¡ˆå‡†ç¡®æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11947v1">A GPU-Accelerated RAG-Based Telegram Assistant for Supporting Parallel Processing Students</a></td><td><details><summary>å±•å¼€</summary>This project addresses a critical pedagogical need: offering students
continuous, on-demand academic assistance beyond conventional reception hours.
I present a domain-specific Retrieval-Augmented Generation (RAG) system powered
by a quantized Mistral-7B Instruct model and deployed as a Telegram bot. The
assistant enhances learning by delivering real-time, personalized responses
aligned with the "Introduction to Parallel Processing" course materials. GPU
acceleration significantly improves inference latency, enabling practical
deployment on consumer hardware. This approach demonstrates how consumer GPUs
can enable affordable, private, and effective AI tutoring for HPC education.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªé¢å‘æ•™è‚²é¢†åŸŸçš„RAGç³»ç»Ÿï¼ŒåŸºäºé‡åŒ–ç‰ˆMistral-7B Instructæ¨¡å‹æ„å»ºï¼Œé€šè¿‡Telegramæœºå™¨äººæä¾›å¹¶è¡Œå¤„ç†è¯¾ç¨‹çš„å®æ—¶ä¸ªæ€§åŒ–å­¦ä¹ æ”¯æŒï¼Œåˆ©ç”¨GPUåŠ é€Ÿå®ç°æ¶ˆè´¹çº§ç¡¬ä»¶éƒ¨ç½²ï¼Œå±•ç¤ºäº†ä½æˆæœ¬é«˜æ•ˆçš„AIè¾…å¯¼æ–¹æ¡ˆã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11937v1">MMORE: Massive Multimodal Open RAG & Extraction</a></td><td><details><summary>å±•å¼€</summary>We introduce MMORE, an open-source pipeline for Massive Multimodal Open
RetrievalAugmented Generation and Extraction, designed to ingest, transform,
and retrieve knowledge from heterogeneous document formats at scale. MMORE
supports more than fifteen file types, including text, tables, images, emails,
audio, and video, and processes them into a unified format to enable downstream
applications for LLMs. The architecture offers modular, distributed processing,
enabling scalable parallelization across CPUs and GPUs. On processing
benchmarks, MMORE demonstrates a 3.8-fold speedup over single-node baselines
and 40% higher accuracy than Docling on scanned PDFs. The pipeline integrates
hybrid dense-sparse retrieval and supports both interactive APIs and batch RAG
endpoints. Evaluated on PubMedQA, MMORE-augmented medical LLMs improve
biomedical QA accuracy with increasing retrieval depth. MMORE provides a
robust, extensible foundation for deploying task-agnostic RAG systems on
diverse, real-world multimodal data. The codebase is available at
https://github.com/swiss-ai/mmore.</details></td><td><details><summary>å±•å¼€</summary>MMOREæ˜¯ä¸€ä¸ªå¼€æºçš„å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿï¼Œæ”¯æŒå¤„ç†å¤šç§æ–‡æ¡£æ ¼å¼ï¼ˆå¦‚æ–‡æœ¬ã€è¡¨æ ¼ã€å›¾åƒç­‰ï¼‰ï¼Œå¹¶å°†å…¶ç»Ÿä¸€å¤„ç†ä»¥ä¾›å¤§è¯­è¨€æ¨¡å‹ä½¿ç”¨ã€‚è¯¥ç³»ç»Ÿé€šè¿‡åˆ†å¸ƒå¼å¤„ç†æé«˜äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œé›†æˆäº†æ··åˆæ£€ç´¢æ–¹æ³•ï¼Œå¹¶åœ¨åŒ»ç–—QAä»»åŠ¡ä¸­å±•ç°äº†æ€§èƒ½æå‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11687v1">A Dynamic Knowledge Update-Driven Model with Large Language Models for Fake News Detection</a></td><td><details><summary>å±•å¼€</summary>As the Internet and social media evolve rapidly, distinguishing credible news
from a vast amount of complex information poses a significant challenge. Due to
the suddenness and instability of news events, the authenticity labels of news
can potentially shift as events develop, making it crucial for fake news
detection to obtain the latest event updates. Existing methods employ
retrieval-augmented generation to fill knowledge gaps, but they suffer from
issues such as insufficient credibility of retrieved content and interference
from noisy information. We propose a dynamic knowledge update-driven model for
fake news detection (DYNAMO), which leverages knowledge graphs to achieve
continuous updating of new knowledge and integrates with large language models
to fulfill dual functions: news authenticity detection and verification of new
knowledge correctness, solving the two key problems of ensuring the
authenticity of new knowledge and deeply mining news semantics. Specifically,
we first construct a news-domain-specific knowledge graph. Then, we use Monte
Carlo Tree Search to decompose complex news and verify them step by step.
Finally, we extract and update new knowledge from verified real news texts and
reasoning paths. Experimental results demonstrate that DYNAMO achieves the best
performance on two real-world datasets.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºDYNAMOçš„å‡æ–°é—»æ£€æµ‹æ¨¡å‹ï¼Œé€šè¿‡ç»“åˆçŸ¥è¯†å›¾è°±çš„åŠ¨æ€æ›´æ–°ä¸å¤§è¯­è¨€æ¨¡å‹ï¼Œè§£å†³äº†ç°æœ‰æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•ä¸­æ£€ç´¢å†…å®¹å¯ä¿¡åº¦ä¸è¶³å’Œå™ªå£°å¹²æ‰°çš„é—®é¢˜ã€‚æ¨¡å‹åˆ©ç”¨æ–°é—»é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†å›¾è°±ï¼Œé€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢é€æ­¥åˆ†è§£å’ŒéªŒè¯å¤æ‚æ–°é—»ï¼ŒåŒæ—¶ä»å·²éªŒè¯çš„çœŸå®æ–°é—»ä¸­æå–å’Œæ›´æ–°çŸ¥è¯†ï¼Œå®ç°äº†æ–°é—»çœŸå®æ€§æ£€æµ‹ä¸æ–°çŸ¥è¯†æ­£ç¡®æ€§éªŒè¯çš„åŒé‡åŠŸèƒ½ã€‚å®éªŒç»“æœè¡¨æ˜DYNAMOåœ¨ä¸¤ä¸ªçœŸå®æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11645v1">Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self-Management: A Divide and Conquer Framework</a></td><td><details><summary>å±•å¼€</summary>This study presents the first comprehensive evaluation of Multimodal Large
Language Models (MLLMs) for Adolescent Idiopathic Scoliosis (AIS)
self-management. We constructed a database of approximately 3,000
anteroposterior X-rays with diagnostic texts and evaluated five MLLMs through a
`Divide and Conquer' framework consisting of a visual question-answering task,
a domain knowledge assessment task, and a patient education counseling
assessment task. Our investigation revealed limitations of MLLMs' ability in
interpreting complex spinal radiographs and comprehending AIS care knowledge.
To address these, we pioneered enhancing MLLMs with spinal keypoint prompting
and compiled an AIS knowledge base for retrieval augmented generation (RAG),
respectively. Results showed varying effectiveness of visual prompting across
different architectures, while RAG substantially improved models' performances
on the knowledge assessment task. Our findings indicate current MLLMs are far
from capable in realizing personalized assistant in AIS care. The greatest
challenge lies in their abilities to obtain accurate detections of spinal
deformity locations (best accuracy: 0.55) and directions (best accuracy: 0.13).</details></td><td><details><summary>å±•å¼€</summary>è¯¥ç ”ç©¶è¯„ä¼°äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨é’å°‘å¹´ç‰¹å‘æ€§è„ŠæŸ±ä¾§å‡¸(AIS)è‡ªæˆ‘ç®¡ç†ä¸­çš„åº”ç”¨ï¼Œå‘ç°æ¨¡å‹åœ¨è§£è¯»å¤æ‚è„ŠæŸ±Xå…‰ç‰‡å’Œç†è§£AISæŠ¤ç†çŸ¥è¯†æ–¹é¢å­˜åœ¨å±€é™ï¼Œå¹¶é€šè¿‡å¼•å…¥è„ŠæŸ±å…³é”®ç‚¹æç¤ºå’Œæ„å»ºAISçŸ¥è¯†åº“ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯æ¥æå‡æ¨¡å‹æ€§èƒ½ï¼Œç»“æœæ˜¾ç¤ºRAGæ˜¾è‘—æ”¹å–„äº†æ¨¡å‹çš„çŸ¥è¯†è¯„ä¼°ä»»åŠ¡è¡¨ç°ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14267v1">Graph-Enhanced Retrieval-Augmented Question Answering for E-Commerce Customer Support</a></td><td><details><summary>å±•å¼€</summary>E-Commerce customer support requires quick and accurate answers grounded in
product data and past support cases. This paper develops a novel
retrieval-augmented generation (RAG) framework that uses knowledge graphs (KGs)
to improve the relevance of the answer and the factual grounding. We examine
recent advances in knowledge-augmented RAG and chatbots based on large language
models (LLM) in customer support, including Microsoft's GraphRAG and hybrid
retrieval architectures. We then propose a new answer synthesis algorithm that
combines structured subgraphs from a domain-specific KG with text documents
retrieved from support archives, producing more coherent and grounded
responses. We detail the architecture and knowledge flow of our system, provide
comprehensive experimental evaluation, and justify its design in real-time
support settings. Our implementation demonstrates 23\% improvement in factual
accuracy and 89\% user satisfaction in e-Commerce QA scenarios.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºçŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰çš„RAGæ¡†æ¶ï¼Œæ—¨åœ¨æå‡ç”µå­å•†åŠ¡å®¢æœå›ç­”çš„ç›¸å…³æ€§å’Œäº‹å®ä¾æ®ï¼Œé€šè¿‡ç»“åˆç»“æ„åŒ–å­å›¾å’Œæ–‡æœ¬æ£€ç´¢ç”Ÿæˆæ›´è¿è´¯çš„å“åº”ï¼Œå®éªŒè¡¨æ˜å…¶å®ç°23%çš„äº‹å®å‡†ç¡®æ€§æå‡å’Œ89%çš„ç”¨æˆ·æ»¡æ„åº¦ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11552v2">HiChunk: Evaluating and Enhancing Retrieval-Augmented Generation with Hierarchical Chunking</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) enhances the response capabilities of
language models by integrating external knowledge sources. However, document
chunking as an important part of RAG system often lacks effective evaluation
tools. This paper first analyzes why existing RAG evaluation benchmarks are
inadequate for assessing document chunking quality, specifically due to
evidence sparsity. Based on this conclusion, we propose HiCBench, which
includes manually annotated multi-level document chunking points, synthesized
evidence-dense quetion answer(QA) pairs, and their corresponding evidence
sources. Additionally, we introduce the HiChunk framework, a multi-level
document structuring framework based on fine-tuned LLMs, combined with the
Auto-Merge retrieval algorithm to improve retrieval quality. Experiments
demonstrate that HiCBench effectively evaluates the impact of different
chunking methods across the entire RAG pipeline. Moreover, HiChunk achieves
better chunking quality within reasonable time consumption, thereby enhancing
the overall performance of RAG systems.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡èšç„¦äºRAGç³»ç»Ÿä¸­æ–‡æ¡£åˆ†å—ï¼ˆchunkingï¼‰è¯„ä¼°çš„ä¸è¶³ï¼Œæå‡ºå¸¦æœ‰æ‰‹åŠ¨æ ‡æ³¨å¤šçº§åˆ†å—ç‚¹çš„è¯„ä¼°åŸºå‡†HiCBenchå’Œè¯æ®å¯†é›†å‹QAæ•°æ®é›†ï¼ŒåŒæ—¶è®¾è®¡äº†åŸºäºå¾®è°ƒLLMsçš„å¤šçº§æ–‡æ¡£ç»“æ„åŒ–æ¡†æ¶HiChunkåŠAuto-Mergeæ£€ç´¢ç®—æ³•ï¼Œå®éªŒè¯æ˜å…¶èƒ½æœ‰æ•ˆæå‡åˆ†å—è´¨é‡å’ŒRAGæ•´ä½“æ€§èƒ½ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-14
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.11376v1">Intelligent Reservoir Decision Support: An Integrated Framework Combining Large Language Models, Advanced Prompt Engineering, and Multimodal Data Fusion for Real-Time Petroleum Operations</a></td><td><details><summary>å±•å¼€</summary>The petroleum industry faces unprecedented challenges in reservoir
management, requiring rapid integration of complex multimodal datasets for
real-time decision support. This study presents a novel integrated framework
combining state-of-the-art large language models (GPT-4o, Claude 4 Sonnet,
Gemini 2.5 Pro) with advanced prompt engineering techniques and multimodal data
fusion for comprehensive reservoir analysis. The framework implements
domain-specific retrieval-augmented generation (RAG) with over 50,000 petroleum
engineering documents, chain-of-thought reasoning, and few-shot learning for
rapid field adaptation. Multimodal integration processes seismic
interpretations, well logs, and production data through specialized AI models
with vision transformers. Field validation across 15 diverse reservoir
environments demonstrates exceptional performance: 94.2% reservoir
characterization accuracy, 87.6% production forecasting precision, and 91.4%
well placement optimization success rate. The system achieves sub-second
response times while maintaining 96.2% safety reliability with no high-risk
incidents during evaluation. Economic analysis reveals 62-78% cost reductions
(mean 72%) relative to traditional methods with 8-month payback period.
Few-shot learning reduces field adaptation time by 72%, while automated prompt
optimization achieves 89% improvement in reasoning quality. The framework
processed real-time data streams with 96.2% anomaly detection accuracy and
reduced environmental incidents by 45%. We provide detailed experimental
protocols, baseline comparisons, ablation studies, and statistical significance
testing to ensure reproducibility. This research demonstrates practical
integration of cutting-edge AI technologies with petroleum domain expertise for
enhanced operational efficiency, safety, and economic performance.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ã€å¤šæ¨¡æ€æ•°æ®èåˆå’Œé¢†åŸŸç‰¹å®šæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯çš„é›†æˆæ¡†æ¶ï¼Œç”¨äºçŸ³æ²¹è¡Œä¸šçš„å‚¨å±‚ç®¡ç†ã€‚é€šè¿‡æ•´åˆè¶…è¿‡50,000ä»½çŸ³æ²¹å·¥ç¨‹æ–‡æ¡£çš„RAGç³»ç»Ÿã€å¤šæ¨¡æ€æ•°æ®å¤„ç†ï¼ˆå¦‚åœ°éœ‡è§£é‡Šã€æµ‹äº•æ•°æ®å’Œç”Ÿäº§æ•°æ®ï¼‰ä»¥åŠé“¾å¼æ¨ç†å’Œå°‘æ ·æœ¬å­¦ä¹ ï¼Œæ˜¾è‘—æé«˜äº†å‚¨å±‚è¡¨å¾ã€äº§é‡é¢„æµ‹å’Œäº•ä½ä¼˜åŒ–çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼ŒåŒæ—¶é™ä½äº†æˆæœ¬å’Œå®‰å…¨é£é™©ã€‚å®è¯ç»“æœè¡¨æ˜è¯¥ç³»ç»Ÿåœ¨å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šè¡¨ç°å“è¶Šã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14265v1">Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models</a></td><td><details><summary>å±•å¼€</summary>Automated kernel design is critical for overcoming software ecosystem
barriers in emerging hardware platforms like RISC-V. While large language
models (LLMs) have shown promise for automated kernel optimization,
demonstrating success in CUDA domains with comprehensive technical documents
and mature codebases, their effectiveness remains unproven for reference-scarce
domains like RISC-V. We present Evolution of Kernels (EoK), a novel LLM-based
evolutionary program search framework that automates kernel design for domains
with limited reference material. EoK mitigates reference scarcity by mining and
formalizing reusable optimization ideas (general design principles + actionable
thoughts) from established kernel libraries' development histories; it then
guides parallel LLM explorations using these ideas, enriched via
Retrieval-Augmented Generation (RAG) with RISC-V-specific context, prioritizing
historically effective techniques. Empirically, EoK achieves a median 1.27x
speedup, surpassing human experts on all 80 evaluated kernel design tasks and
improving upon prior LLM-based automated kernel design methods by 20%. These
results underscore the viability of incorporating human experience into
emerging domains and highlight the immense potential of LLM-based automated
kernel optimization.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºEoKï¼ˆEvolution of Kernelsï¼‰çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è¿›åŒ–ç¨‹åºæœç´¢æ¡†æ¶ï¼Œç”¨äºåœ¨RISC-Vç­‰å‚è€ƒèµ„æºç¨€ç¼ºçš„é¢†åŸŸè‡ªåŠ¨åŒ–å†…æ ¸è®¾è®¡ã€‚EoKé€šè¿‡ä»å·²æœ‰å†…æ ¸åº“çš„å¼€å‘å†å²ä¸­æŒ–æ˜å’Œå½¢å¼åŒ–å¯é‡ç”¨çš„ä¼˜åŒ–æ€æƒ³ï¼Œå¹¶åˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç»“åˆRISC-Vç‰¹å®šä¸Šä¸‹æ–‡æ¥æŒ‡å¯¼å¹¶è¡Œçš„å¤§è¯­è¨€æ¨¡å‹æ¢ç´¢ï¼Œä»è€Œåœ¨80é¡¹å†…æ ¸è®¾è®¡ä»»åŠ¡ä¸­å®ç°äº†ä¸­ä½æ•°1.27å€çš„åŠ é€Ÿï¼Œè¶…è¶Šäººç±»ä¸“å®¶å’Œå…ˆå‰åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ã€‚</details></td></tr></tbody></table>
